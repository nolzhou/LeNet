#IR entry      : @1_construct_wrapper.536
#attrs         :
training : 1
#Total params  : 20

%para1_inputs0 : <Tensor[Float32], (32, 1, 32, 32)>
%para2_inputs1 : <Tensor[Int32], (32)>
%para3_conv1.weight : <Ref[Tensor(F32)], (6, 1, 5, 5)>
%para4_conv2.weight : <Ref[Tensor(F32)], (16, 6, 5, 5)>
%para5_fc1.weight : <Ref[Tensor(F32)], (120, 400)>
%para6_fc1.bias : <Ref[Tensor(F32)], (120)>
%para7_fc2.weight : <Ref[Tensor(F32)], (84, 120)>
%para8_fc2.bias : <Ref[Tensor(F32)], (84)>
%para9_fc3.weight : <Ref[Tensor(F32)], (10, 84)>
%para10_fc3.bias : <Ref[Tensor(F32)], (10)>
%para11_moments.conv1.weight : <Ref[Tensor(F32)], (6, 1, 5, 5)>
%para12_moments.conv2.weight : <Ref[Tensor(F32)], (16, 6, 5, 5)>
%para13_moments.fc1.weight : <Ref[Tensor(F32)], (120, 400)>
%para14_moments.fc1.bias : <Ref[Tensor(F32)], (120)>
%para15_moments.fc2.weight : <Ref[Tensor(F32)], (84, 120)>
%para16_moments.fc2.bias : <Ref[Tensor(F32)], (84)>
%para17_moments.fc3.weight : <Ref[Tensor(F32)], (10, 84)>
%para18_moments.fc3.bias : <Ref[Tensor(F32)], (10)>
%para19_momentum : <Ref[Tensor(F32)], ()>
%para20_learning_rate : <Ref[Tensor(F32)], ()>

#Total subgraph : 128

subgraph attr:
core : 1
Undeterminate : 0
subgraph @2_UnpackCall.780(%para21_542, %para22_538, %para23_u) {
  %0(537) = TupleGetItem(%para22_538, 0)
      : (<Tuple[Tensor[Float32],Tensor[Int32]], sequence_nodes={node={1_construct_wrapper.536:[CNode]539{[0]: ValueNode<Primitive> MakeTuple, [1]: inputs0, [2]: inputs1}, elements_use_flags: {ptr: 0x1599619fe50, value: [const vector][1, 1]}}}>, <Int64>) -> (<Tensor[Float32], (32, 1, 32, 32)>)
  %1(540) = TupleGetItem(%para22_538, 1)
      : (<Tuple[Tensor[Float32],Tensor[Int32]], sequence_nodes={node={1_construct_wrapper.536:[CNode]539{[0]: ValueNode<Primitive> MakeTuple, [1]: inputs0, [2]: inputs1}, elements_use_flags: {ptr: 0x1599619fe50, value: [const vector][1, 1]}}}>, <Int64>) -> (<Tensor[Int32], (32)>)
  %2(541) = 542[3_construct.543](%0, %1, %para23_u)
      : (<Tensor[Float32], (32, 1, 32, 32)>, <Tensor[Int32], (32)>, <UMonad>) -> (<Tensor[Float32], ()>)
  Return(%2)
      : (<Tensor[Float32], ()>)
}

subgraph attr:
core : 1
Undeterminate : 0
subgraph @4_UnpackCall.600(%para24_549, %para25_545, %para26_u) {
  %0(544) = TupleGetItem(%para25_545, 0)
      : (<Tuple[Tensor[Float32],Tensor[Int32]], sequence_nodes={node={3_construct.543:[CNode]546{[0]: ValueNode<Primitive> MakeTuple, [1]: inputs0, [2]: inputs1}, elements_use_flags: {ptr: 0x159961679b0, value: [const vector][1, 1]}}}>, <Int64>) -> (<Tensor[Float32], (32, 1, 32, 32)>)
  %1(547) = TupleGetItem(%para25_545, 1)
      : (<Tuple[Tensor[Float32],Tensor[Int32]], sequence_nodes={node={3_construct.543:[CNode]546{[0]: ValueNode<Primitive> MakeTuple, [1]: inputs0, [2]: inputs1}, elements_use_flags: {ptr: 0x159961679b0, value: [const vector][1, 1]}}}>, <Int64>) -> (<Tensor[Int32], (32)>)
  %2(548) = 549[5_construct.550](%0, %1, %para26_u)
      : (<Tensor[Float32], (32, 1, 32, 32)>, <Tensor[Int32], (32)>, <UMonad>) -> (<Tensor[Float32], ()>)
  Return(%2)
      : (<Tensor[Float32], ()>)
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @6_construct.551(%para27_Φlogits, %para28_labels) {
  %0([CNode]91) = Switch(true, @7_✓construct.553, DeadNode)
      : (<Bool>, <Func>, <unknown>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/
  %1([CNode]94) = %0[7_✓construct.553]()
      : () -> (<Tensor[Float32], ()>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/
  %2([CNode]95) = Depend(%1, (None, None)) primitive_attrs: {side_effect_propagate: 1} cnode_attrs: {topo_sort_rhs_first: true}
      : (<Tensor[Float32], ()>, <Tuple[kMetaTypeNone*2], sequence_nodes={node={construct.554:[CNode]37{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]35, [2]: [CNode]36}, elements_use_flags: {ptr: 0x15996641080, value: [const vector][1, 1]}}, node={ValueNode<ValueTuple> (None, None), elements_use_flags: {ptr: 0x15996641080, value: [const vector][1, 1]}}}>) -> (<Tensor[Float32], ()>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(111)/        return self._loss_fn(out, label)/
  Return(%2)
      : (<Tensor[Float32], ()>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @8_✓✓construct.552() {
  %0(x) = SparseSoftmaxCrossEntropyWithLogits($(@6_construct.551:para27_Φlogits), $(@6_construct.551:para28_labels)) {instance name: sparse_softmax_cross_entropy} primitive_attrs: {output_names: [output], input_names: [features, labels], sens: 1.000000, is_grad: false}
      : (<Tensor[Float32], (32, 10)>, <Tensor[Int32], (32)>) -> (<Tensor[Float32], ()>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(627)/                x = self.sparse_softmax_cross_entropy(logits, labels)/
  Return(%0)
      : (<Tensor[Float32], ()>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(628)/                return x/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @7_✓construct.553() {
  %0([CNode]86) = Switch(true, @8_✓✓construct.552, DeadNode)
      : (<Bool>, <Func>, <unknown>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/
  %1([CNode]89) = %0[8_✓✓construct.552]()
      : () -> (<Tensor[Float32], ()>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/
  Return(%1)
      : (<Tensor[Float32], ()>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/
}

subgraph attr:
after_block : 1
Undeterminate : 0
training : 1
subgraph @19_L-↓↓↓↓construct.555(%para29_Φx) {
  Return(%para29_Φx)
      : (<Tensor[Float32], (32, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(332)/        return x/
}

subgraph attr:
after_block : 1
Undeterminate : 0
training : 1
subgraph @17_L-↓↓↓construct.556(%para30_Φx) {
  %0([CNode]119) = Switch(false, DeadNode, @18_L-✗↓↓↓construct.557)
      : (<Bool>, <unknown>, <Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
  %1([CNode]122) = %0[18_L-✗↓↓↓construct.557]()
      : () -> (<Tensor[Float32], (32, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
  Return(%1)
      : (<Tensor[Float32], (32, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @18_L-✗↓↓↓construct.557() {
  %0([CNode]118) = call @19_L-↓↓↓↓construct.555($(@17_L-↓↓↓construct.556:para30_Φx))
      : (<Tensor[Float32], (32, 10)>) -> (<Tensor[Float32], (32, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
  Return(%0)
      : (<Tensor[Float32], (32, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
}

subgraph attr:
after_block : 1
Undeterminate : 0
training : 1
subgraph @15_L-↓↓construct.558(%para31_Φx) {
  %0([CNode]126) = Switch(false, DeadNode, @16_L-✗↓↓construct.559)
      : (<Bool>, <unknown>, <Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
  %1([CNode]129) = %0[16_L-✗↓↓construct.559]()
      : () -> (<Tensor[Float32], (32, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
  Return(%1)
      : (<Tensor[Float32], (32, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @16_L-✗↓↓construct.559() {
  %0([CNode]125) = call @17_L-↓↓↓construct.556($(@15_L-↓↓construct.558:para31_Φx))
      : (<Tensor[Float32], (32, 10)>) -> (<Tensor[Float32], (32, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
  Return(%0)
      : (<Tensor[Float32], (32, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
}

subgraph attr:
after_block : 1
Undeterminate : 0
training : 1
subgraph @13_L-↓construct.561(%para32_Φx, %para33_u) {
  %0([CNode]822) = Load($(@11_L-construct.560:para36_L-fc3.weight), %para33_u)
      : (<Ref[Tensor(F32)], (10, 84)>, <UMonad>) -> (<Tensor[Float32], (10, 84)>)
  %1(x) = MatMul(%para32_Φx, %0) {instance name: matmul} primitive_attrs: {output_names: [output], transpose_a: false, input_names: [x1, x2], transpose_x2: true, transpose_x1: false, transpose_b: true}
      : (<Tensor[Float32], (32, 84)>, <Tensor[Float32], (10, 84)>) -> (<Tensor[Float32], (32, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(324)/        x = self.matmul(x, self.weight)/
  %2([CNode]133) = Switch(true, @14_L-✓↓construct.562, DeadNode)
      : (<Bool>, <Func>, <unknown>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
  %3([CNode]825) = UpdateState(%para33_u, %0)
      : (<UMonad>, <Tensor[Float32], (10, 84)>) -> (<UMonad>)
  %4([CNode]136) = %2[14_L-✓↓construct.562](%3)
      : (<UMonad>) -> (<Tensor[Float32], (32, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
  %5([CNode]826) = UpdateState(%3, %4)
      : (<UMonad>, <Tensor[Float32], (32, 10)>) -> (<UMonad>)
  %6([CNode]136) = Depend(%4, %5) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], (32, 10)>, <UMonad>) -> (<Tensor[Float32], (32, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
  Return(%6)
      : (<Tensor[Float32], (32, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @11_L-construct.560(%para34_x, %para35_L-fc3.bias, %para36_L-fc3.weight, %para37_u) {
  %0([CNode]143) = Switch(false, DeadNode, @12_L-✗construct.563)
      : (<Bool>, <unknown>, <Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
  %1([CNode]146) = %0[12_L-✗construct.563](%para37_u)
      : (<UMonad>) -> (<Tensor[Float32], (32, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
  %2([CNode]147) = Depend(%1, None) primitive_attrs: {side_effect_propagate: 1} cnode_attrs: {topo_sort_rhs_first: true}
      : (<Tensor[Float32], (32, 10)>, <kMetaTypeNone>) -> (<Tensor[Float32], (32, 10)>)
      # In file D:\PythonCode\LeNet\lenet.py(52)/        x = self.fc3(x)/
  %3([CNode]827) = UpdateState(%para37_u, %1)
      : (<UMonad>, <Tensor[Float32], (32, 10)>) -> (<UMonad>)
  %4([CNode]147) = Depend(%2, %3) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], (32, 10)>, <UMonad>) -> (<Tensor[Float32], (32, 10)>)
      # In file D:\PythonCode\LeNet\lenet.py(52)/        x = self.fc3(x)/
  Return(%4)
      : (<Tensor[Float32], (32, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @14_L-✓↓construct.562(%para38_u) {
  %0([CNode]823) = Load($(@11_L-construct.560:para35_L-fc3.bias), %para38_u)
      : (<Ref[Tensor(F32)], (10)>, <UMonad>) -> (<Tensor[Float32], (10)>)
  %1(x) = BiasAdd($(@13_L-↓construct.561:x), %0) {instance name: bias_add} primitive_attrs: {output_names: [output], format: NCHW, input_names: [x, b]}
      : (<Tensor[Float32], (32, 10)>, <Tensor[Float32], (10)>) -> (<Tensor[Float32], (32, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(326)/            x = self.bias_add(x, self.bias)/
  %2([CNode]131) = call @15_L-↓↓construct.558(%1)
      : (<Tensor[Float32], (32, 10)>) -> (<Tensor[Float32], (32, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
  %3([CNode]824) = UpdateState(%para38_u, %0)
      : (<UMonad>, <Tensor[Float32], (10)>) -> (<UMonad>)
  %4([CNode]131) = Depend(%2, %3) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], (32, 10)>, <UMonad>) -> (<Tensor[Float32], (32, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
  Return(%4)
      : (<Tensor[Float32], (32, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @12_L-✗construct.563(%para39_u) {
  %0([CNode]142) = call @13_L-↓construct.561($(@11_L-construct.560:para34_x), %para39_u)
      : (<Tensor[Float32], (32, 84)>, <UMonad>) -> (<Tensor[Float32], (32, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
  Return(%0)
      : (<Tensor[Float32], (32, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @10_construct.598(%para40_x, %para41_u) {
  %0([CNode]521) = call @11_L-construct.560(%para40_x, $(@1_construct_wrapper.536:para10_fc3.bias), $(@1_construct_wrapper.536:para9_fc3.weight), %para41_u)
      : (<Tensor[Float32], (32, 84)>, <Ref[Tensor(F32)], (10)>, <Ref[Tensor(F32)], (10, 84)>, <UMonad>) -> (<Tensor[Float32], (32, 10)>)
  Return(%0)
      : (<Tensor[Float32], (32, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
}

subgraph attr:
training : 1
subgraph @1_construct_wrapper.536() {
  %0([CNode]539) = MakeTuple(%para1_inputs0, %para2_inputs1)
      : (<Tensor[Float32], (32, 1, 32, 32)>, <Tensor[Int32], (32)>) -> (<Tuple[Tensor[Float32],Tensor[Int32]], sequence_nodes={node={1_construct_wrapper.536:[CNode]539{[0]: ValueNode<Primitive> MakeTuple, [1]: inputs0, [2]: inputs1}, elements_use_flags: {ptr: 0x1599619fe50, value: [const vector][1, 1]}}}>)
  %1([CNode]20) = call @2_UnpackCall.780(@3_construct.543, %0, U)
      : (<Func>, <Tuple[Tensor[Float32],Tensor[Int32]], sequence_nodes={node={1_construct_wrapper.536:[CNode]539{[0]: ValueNode<Primitive> MakeTuple, [1]: inputs0, [2]: inputs1}, elements_use_flags: {ptr: 0x1599619fe50, value: [const vector][1, 1]}}}>, <UMonad>) -> (<Tensor[Float32], ()>)
  Return(%1)
      : (<Tensor[Float32], ()>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(366)/        return loss/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @20_construct.597(%para42_x) {
  %0([CNode]148) = ReLU(%para42_x) {instance name: relu} primitive_attrs: {output_names: [output], input_names: [x]}
      : (<Tensor[Float32], (32, 84)>) -> (<Tensor[Float32], (32, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(295)/        return self.relu(x)/
  Return(%0)
      : (<Tensor[Float32], (32, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(295)/        return self.relu(x)/
}

subgraph attr:
after_block : 1
Undeterminate : 0
training : 1
subgraph @30_L-↓↓↓↓construct.564(%para43_Φx) {
  Return(%para43_Φx)
      : (<Tensor[Float32], (32, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(332)/        return x/
}

subgraph attr:
after_block : 1
Undeterminate : 0
training : 1
subgraph @28_L-↓↓↓construct.565(%para44_Φx) {
  %0([CNode]119) = Switch(false, DeadNode, @29_L-✗↓↓↓construct.566)
      : (<Bool>, <unknown>, <Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
  %1([CNode]122) = %0[29_L-✗↓↓↓construct.566]()
      : () -> (<Tensor[Float32], (32, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
  Return(%1)
      : (<Tensor[Float32], (32, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @29_L-✗↓↓↓construct.566() {
  %0([CNode]118) = call @30_L-↓↓↓↓construct.564($(@28_L-↓↓↓construct.565:para44_Φx))
      : (<Tensor[Float32], (32, 84)>) -> (<Tensor[Float32], (32, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
  Return(%0)
      : (<Tensor[Float32], (32, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
}

subgraph attr:
after_block : 1
Undeterminate : 0
training : 1
subgraph @26_L-↓↓construct.567(%para45_Φx) {
  %0([CNode]126) = Switch(false, DeadNode, @27_L-✗↓↓construct.568)
      : (<Bool>, <unknown>, <Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
  %1([CNode]129) = %0[27_L-✗↓↓construct.568]()
      : () -> (<Tensor[Float32], (32, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
  Return(%1)
      : (<Tensor[Float32], (32, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @27_L-✗↓↓construct.568() {
  %0([CNode]125) = call @28_L-↓↓↓construct.565($(@26_L-↓↓construct.567:para45_Φx))
      : (<Tensor[Float32], (32, 84)>) -> (<Tensor[Float32], (32, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
  Return(%0)
      : (<Tensor[Float32], (32, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
}

subgraph attr:
after_block : 1
Undeterminate : 0
training : 1
subgraph @24_L-↓construct.570(%para46_Φx, %para47_u) {
  %0([CNode]828) = Load($(@22_L-construct.569:para50_L-fc3.weight), %para47_u)
      : (<Ref[Tensor(F32)], (84, 120)>, <UMonad>) -> (<Tensor[Float32], (84, 120)>)
  %1(x) = MatMul(%para46_Φx, %0) {instance name: matmul} primitive_attrs: {output_names: [output], transpose_a: false, input_names: [x1, x2], transpose_x2: true, transpose_x1: false, transpose_b: true}
      : (<Tensor[Float32], (32, 120)>, <Tensor[Float32], (84, 120)>) -> (<Tensor[Float32], (32, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(324)/        x = self.matmul(x, self.weight)/
  %2([CNode]133) = Switch(true, @25_L-✓↓construct.571, DeadNode)
      : (<Bool>, <Func>, <unknown>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
  %3([CNode]831) = UpdateState(%para47_u, %0)
      : (<UMonad>, <Tensor[Float32], (84, 120)>) -> (<UMonad>)
  %4([CNode]136) = %2[25_L-✓↓construct.571](%3)
      : (<UMonad>) -> (<Tensor[Float32], (32, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
  %5([CNode]832) = UpdateState(%3, %4)
      : (<UMonad>, <Tensor[Float32], (32, 84)>) -> (<UMonad>)
  %6([CNode]136) = Depend(%4, %5) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], (32, 84)>, <UMonad>) -> (<Tensor[Float32], (32, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
  Return(%6)
      : (<Tensor[Float32], (32, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @22_L-construct.569(%para48_x, %para49_L-fc3.bias, %para50_L-fc3.weight, %para51_u) {
  %0([CNode]143) = Switch(false, DeadNode, @23_L-✗construct.572)
      : (<Bool>, <unknown>, <Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
  %1([CNode]146) = %0[23_L-✗construct.572](%para51_u)
      : (<UMonad>) -> (<Tensor[Float32], (32, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
  %2([CNode]147) = Depend(%1, None) primitive_attrs: {side_effect_propagate: 1} cnode_attrs: {topo_sort_rhs_first: true}
      : (<Tensor[Float32], (32, 84)>, <kMetaTypeNone>) -> (<Tensor[Float32], (32, 84)>)
      # In file D:\PythonCode\LeNet\lenet.py(52)/        x = self.fc3(x)/
  %3([CNode]833) = UpdateState(%para51_u, %1)
      : (<UMonad>, <Tensor[Float32], (32, 84)>) -> (<UMonad>)
  %4([CNode]147) = Depend(%2, %3) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], (32, 84)>, <UMonad>) -> (<Tensor[Float32], (32, 84)>)
      # In file D:\PythonCode\LeNet\lenet.py(52)/        x = self.fc3(x)/
  Return(%4)
      : (<Tensor[Float32], (32, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @25_L-✓↓construct.571(%para52_u) {
  %0([CNode]829) = Load($(@22_L-construct.569:para49_L-fc3.bias), %para52_u)
      : (<Ref[Tensor(F32)], (84)>, <UMonad>) -> (<Tensor[Float32], (84)>)
  %1(x) = BiasAdd($(@24_L-↓construct.570:x), %0) {instance name: bias_add} primitive_attrs: {output_names: [output], format: NCHW, input_names: [x, b]}
      : (<Tensor[Float32], (32, 84)>, <Tensor[Float32], (84)>) -> (<Tensor[Float32], (32, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(326)/            x = self.bias_add(x, self.bias)/
  %2([CNode]131) = call @26_L-↓↓construct.567(%1)
      : (<Tensor[Float32], (32, 84)>) -> (<Tensor[Float32], (32, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
  %3([CNode]830) = UpdateState(%para52_u, %0)
      : (<UMonad>, <Tensor[Float32], (84)>) -> (<UMonad>)
  %4([CNode]131) = Depend(%2, %3) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], (32, 84)>, <UMonad>) -> (<Tensor[Float32], (32, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
  Return(%4)
      : (<Tensor[Float32], (32, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @23_L-✗construct.572(%para53_u) {
  %0([CNode]142) = call @24_L-↓construct.570($(@22_L-construct.569:para48_x), %para53_u)
      : (<Tensor[Float32], (32, 120)>, <UMonad>) -> (<Tensor[Float32], (32, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
  Return(%0)
      : (<Tensor[Float32], (32, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @21_construct.596(%para54_x, %para55_u) {
  %0([CNode]522) = call @22_L-construct.569(%para54_x, $(@1_construct_wrapper.536:para8_fc2.bias), $(@1_construct_wrapper.536:para7_fc2.weight), %para55_u)
      : (<Tensor[Float32], (32, 120)>, <Ref[Tensor(F32)], (84)>, <Ref[Tensor(F32)], (84, 120)>, <UMonad>) -> (<Tensor[Float32], (32, 84)>)
  Return(%0)
      : (<Tensor[Float32], (32, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @31_construct.595(%para56_x) {
  %0([CNode]148) = ReLU(%para56_x) {instance name: relu} primitive_attrs: {output_names: [output], input_names: [x]}
      : (<Tensor[Float32], (32, 120)>) -> (<Tensor[Float32], (32, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(295)/        return self.relu(x)/
  Return(%0)
      : (<Tensor[Float32], (32, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(295)/        return self.relu(x)/
}

subgraph attr:
after_block : 1
Undeterminate : 0
training : 1
subgraph @41_L-↓↓↓↓construct.573(%para57_Φx) {
  Return(%para57_Φx)
      : (<Tensor[Float32], (32, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(332)/        return x/
}

subgraph attr:
after_block : 1
Undeterminate : 0
training : 1
subgraph @39_L-↓↓↓construct.574(%para58_Φx) {
  %0([CNode]119) = Switch(false, DeadNode, @40_L-✗↓↓↓construct.575)
      : (<Bool>, <unknown>, <Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
  %1([CNode]122) = %0[40_L-✗↓↓↓construct.575]()
      : () -> (<Tensor[Float32], (32, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
  Return(%1)
      : (<Tensor[Float32], (32, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @40_L-✗↓↓↓construct.575() {
  %0([CNode]118) = call @41_L-↓↓↓↓construct.573($(@39_L-↓↓↓construct.574:para58_Φx))
      : (<Tensor[Float32], (32, 120)>) -> (<Tensor[Float32], (32, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
  Return(%0)
      : (<Tensor[Float32], (32, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
}

subgraph attr:
after_block : 1
Undeterminate : 0
training : 1
subgraph @37_L-↓↓construct.576(%para59_Φx) {
  %0([CNode]126) = Switch(false, DeadNode, @38_L-✗↓↓construct.577)
      : (<Bool>, <unknown>, <Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
  %1([CNode]129) = %0[38_L-✗↓↓construct.577]()
      : () -> (<Tensor[Float32], (32, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
  Return(%1)
      : (<Tensor[Float32], (32, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @38_L-✗↓↓construct.577() {
  %0([CNode]125) = call @39_L-↓↓↓construct.574($(@37_L-↓↓construct.576:para59_Φx))
      : (<Tensor[Float32], (32, 120)>) -> (<Tensor[Float32], (32, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
  Return(%0)
      : (<Tensor[Float32], (32, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
}

subgraph attr:
after_block : 1
Undeterminate : 0
training : 1
subgraph @35_L-↓construct.579(%para60_Φx, %para61_u) {
  %0([CNode]834) = Load($(@33_L-construct.578:para64_L-fc3.weight), %para61_u)
      : (<Ref[Tensor(F32)], (120, 400)>, <UMonad>) -> (<Tensor[Float32], (120, 400)>)
  %1(x) = MatMul(%para60_Φx, %0) {instance name: matmul} primitive_attrs: {output_names: [output], transpose_a: false, input_names: [x1, x2], transpose_x2: true, transpose_x1: false, transpose_b: true}
      : (<Tensor[Float32], (32, 400)>, <Tensor[Float32], (120, 400)>) -> (<Tensor[Float32], (32, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(324)/        x = self.matmul(x, self.weight)/
  %2([CNode]133) = Switch(true, @36_L-✓↓construct.580, DeadNode)
      : (<Bool>, <Func>, <unknown>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
  %3([CNode]837) = UpdateState(%para61_u, %0)
      : (<UMonad>, <Tensor[Float32], (120, 400)>) -> (<UMonad>)
  %4([CNode]136) = %2[36_L-✓↓construct.580](%3)
      : (<UMonad>) -> (<Tensor[Float32], (32, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
  %5([CNode]838) = UpdateState(%3, %4)
      : (<UMonad>, <Tensor[Float32], (32, 120)>) -> (<UMonad>)
  %6([CNode]136) = Depend(%4, %5) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], (32, 120)>, <UMonad>) -> (<Tensor[Float32], (32, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
  Return(%6)
      : (<Tensor[Float32], (32, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @33_L-construct.578(%para62_x, %para63_L-fc3.bias, %para64_L-fc3.weight, %para65_u) {
  %0([CNode]143) = Switch(false, DeadNode, @34_L-✗construct.581)
      : (<Bool>, <unknown>, <Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
  %1([CNode]146) = %0[34_L-✗construct.581](%para65_u)
      : (<UMonad>) -> (<Tensor[Float32], (32, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
  %2([CNode]147) = Depend(%1, None) primitive_attrs: {side_effect_propagate: 1} cnode_attrs: {topo_sort_rhs_first: true}
      : (<Tensor[Float32], (32, 120)>, <kMetaTypeNone>) -> (<Tensor[Float32], (32, 120)>)
      # In file D:\PythonCode\LeNet\lenet.py(52)/        x = self.fc3(x)/
  %3([CNode]839) = UpdateState(%para65_u, %1)
      : (<UMonad>, <Tensor[Float32], (32, 120)>) -> (<UMonad>)
  %4([CNode]147) = Depend(%2, %3) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], (32, 120)>, <UMonad>) -> (<Tensor[Float32], (32, 120)>)
      # In file D:\PythonCode\LeNet\lenet.py(52)/        x = self.fc3(x)/
  Return(%4)
      : (<Tensor[Float32], (32, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @36_L-✓↓construct.580(%para66_u) {
  %0([CNode]835) = Load($(@33_L-construct.578:para63_L-fc3.bias), %para66_u)
      : (<Ref[Tensor(F32)], (120)>, <UMonad>) -> (<Tensor[Float32], (120)>)
  %1(x) = BiasAdd($(@35_L-↓construct.579:x), %0) {instance name: bias_add} primitive_attrs: {output_names: [output], format: NCHW, input_names: [x, b]}
      : (<Tensor[Float32], (32, 120)>, <Tensor[Float32], (120)>) -> (<Tensor[Float32], (32, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(326)/            x = self.bias_add(x, self.bias)/
  %2([CNode]131) = call @37_L-↓↓construct.576(%1)
      : (<Tensor[Float32], (32, 120)>) -> (<Tensor[Float32], (32, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
  %3([CNode]836) = UpdateState(%para66_u, %0)
      : (<UMonad>, <Tensor[Float32], (120)>) -> (<UMonad>)
  %4([CNode]131) = Depend(%2, %3) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], (32, 120)>, <UMonad>) -> (<Tensor[Float32], (32, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
  Return(%4)
      : (<Tensor[Float32], (32, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @34_L-✗construct.581(%para67_u) {
  %0([CNode]142) = call @35_L-↓construct.579($(@33_L-construct.578:para62_x), %para67_u)
      : (<Tensor[Float32], (32, 400)>, <UMonad>) -> (<Tensor[Float32], (32, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
  Return(%0)
      : (<Tensor[Float32], (32, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @32_construct.594(%para68_x, %para69_u) {
  %0([CNode]523) = call @33_L-construct.578(%para68_x, $(@1_construct_wrapper.536:para6_fc1.bias), $(@1_construct_wrapper.536:para5_fc1.weight), %para69_u)
      : (<Tensor[Float32], (32, 400)>, <Ref[Tensor(F32)], (120)>, <Ref[Tensor(F32)], (120, 400)>, <UMonad>) -> (<Tensor[Float32], (32, 120)>)
  Return(%0)
      : (<Tensor[Float32], (32, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @42_construct.593(%para70_x) {
  %0([CNode]251) = Reshape(%para70_x, (32, -1)) primitive_attrs: {output_names: [output], input_names: [tensor, shape]}
      : (<Tensor[Float32], (32, 16, 5, 5)>, <Tuple[Int64*2], sequence_nodes={node={construct.582:[CNode]250{[0]: ValueNode<PrimitivePy> MakeTuple, [1]: [CNode]248, [2]: [CNode]249}, elements_use_flags: {ptr: 0x159961d2220, value: [const vector][1, 1]}}, node={ValueNode<ValueTuple> (32, -1), elements_use_flags: {ptr: 0x159961d2220, value: [const vector][1, 1]}}}>) -> (<Tensor[Float32], (32, 400)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(215)/        return F.reshape(x, (F.shape(x)[0], -1))/
  Return(%0)
      : (<Tensor[Float32], (32, 400)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(215)/        return F.reshape(x, (F.shape(x)[0], -1))/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @43_construct.592(%para71_x) {
  %0(out) = MaxPool(%para71_x) {instance name: max_pool} primitive_attrs: {pad_mode: 2, output_names: [output], kernel_size: (1, 1, 2, 2), format: NCHW, strides: (1, 1, 2, 2), input_names: [x]}
      : (<Tensor[Float32], (32, 16, 10, 10)>) -> (<Tensor[Float32], (32, 16, 5, 5)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\pooling.py(142)/        out = self.max_pool(x)/
  Return(%0)
      : (<Tensor[Float32], (32, 16, 5, 5)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\pooling.py(143)/        return out/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @44_construct.591(%para72_x) {
  %0([CNode]148) = ReLU(%para72_x) {instance name: relu} primitive_attrs: {output_names: [output], input_names: [x]}
      : (<Tensor[Float32], (32, 16, 10, 10)>) -> (<Tensor[Float32], (32, 16, 10, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(295)/        return self.relu(x)/
  Return(%0)
      : (<Tensor[Float32], (32, 16, 10, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(295)/        return self.relu(x)/
}

subgraph attr:
after_block : 1
Undeterminate : 0
training : 1
subgraph @47_↓construct.583(%para73_Φoutput) {
  Return(%para73_Φoutput)
      : (<Tensor[Float32], (32, 16, 10, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(269)/        return output/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @45_construct.584(%para74_x, %para75_u) {
  %0([CNode]840) = Load($(@1_construct_wrapper.536:para4_conv2.weight), %para75_u)
      : (<Ref[Tensor(F32)], (16, 6, 5, 5)>, <UMonad>) -> (<Tensor[Float32], (16, 6, 5, 5)>)
  %1(output) = Conv2D(%para74_x, %0) {instance name: conv2d} primitive_attrs: {kernel_size: (5, 5), mode: 1, out_channel: 16, input_names: [x, w], pad: (0, 0, 0, 0), pad_mode: 2, format: NCHW, pad_list: (0, 0, 0, 0), groups: 1, stride: (1, 1, 1, 1), group: 1, dilation: (1, 1, 1, 1), output_names: [output]}
      : (<Tensor[Float32], (32, 6, 14, 14)>, <Tensor[Float32], (16, 6, 5, 5)>) -> (<Tensor[Float32], (32, 16, 10, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(266)/        output = self.conv2d(x, self.weight)/
  %2([CNode]257) = Switch(false, DeadNode, @46_✗construct.585)
      : (<Bool>, <unknown>, <Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
  %3([CNode]841) = UpdateState(%para75_u, %0)
      : (<UMonad>, <Tensor[Float32], (16, 6, 5, 5)>) -> (<UMonad>)
  %4([CNode]260) = %2[46_✗construct.585](%3)
      : (<UMonad>) -> (<Tensor[Float32], (32, 16, 10, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
  %5([CNode]842) = UpdateState(%3, %4)
      : (<UMonad>, <Tensor[Float32], (32, 16, 10, 10)>) -> (<UMonad>)
  %6([CNode]260) = Depend(%4, %5) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], (32, 16, 10, 10)>, <UMonad>) -> (<Tensor[Float32], (32, 16, 10, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
  Return(%6)
      : (<Tensor[Float32], (32, 16, 10, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @46_✗construct.585(%para76_u) {
  %0([CNode]256) = call @47_↓construct.583($(@45_construct.584:output))
      : (<Tensor[Float32], (32, 16, 10, 10)>) -> (<Tensor[Float32], (32, 16, 10, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
  %1([CNode]256) = Depend(%0, %para76_u) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], (32, 16, 10, 10)>, <UMonad>) -> (<Tensor[Float32], (32, 16, 10, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
  Return(%1)
      : (<Tensor[Float32], (32, 16, 10, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @48_construct.590(%para77_x) {
  %0(out) = MaxPool(%para77_x) {instance name: max_pool} primitive_attrs: {pad_mode: 2, output_names: [output], kernel_size: (1, 1, 2, 2), format: NCHW, strides: (1, 1, 2, 2), input_names: [x]}
      : (<Tensor[Float32], (32, 6, 28, 28)>) -> (<Tensor[Float32], (32, 6, 14, 14)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\pooling.py(142)/        out = self.max_pool(x)/
  Return(%0)
      : (<Tensor[Float32], (32, 6, 14, 14)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\pooling.py(143)/        return out/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @49_construct.589(%para78_x) {
  %0([CNode]148) = ReLU(%para78_x) {instance name: relu} primitive_attrs: {output_names: [output], input_names: [x]}
      : (<Tensor[Float32], (32, 6, 28, 28)>) -> (<Tensor[Float32], (32, 6, 28, 28)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(295)/        return self.relu(x)/
  Return(%0)
      : (<Tensor[Float32], (32, 6, 28, 28)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(295)/        return self.relu(x)/
}

subgraph attr:
after_block : 1
Undeterminate : 0
training : 1
subgraph @52_↓construct.586(%para79_Φoutput) {
  Return(%para79_Φoutput)
      : (<Tensor[Float32], (32, 6, 28, 28)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(269)/        return output/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @50_construct.587(%para80_x, %para81_u) {
  %0([CNode]843) = Load($(@1_construct_wrapper.536:para3_conv1.weight), %para81_u)
      : (<Ref[Tensor(F32)], (6, 1, 5, 5)>, <UMonad>) -> (<Tensor[Float32], (6, 1, 5, 5)>)
  %1(output) = Conv2D(%para80_x, %0) {instance name: conv2d} primitive_attrs: {kernel_size: (5, 5), mode: 1, out_channel: 6, input_names: [x, w], pad: (0, 0, 0, 0), pad_mode: 2, format: NCHW, pad_list: (0, 0, 0, 0), groups: 1, stride: (1, 1, 1, 1), group: 1, dilation: (1, 1, 1, 1), output_names: [output]}
      : (<Tensor[Float32], (32, 1, 32, 32)>, <Tensor[Float32], (6, 1, 5, 5)>) -> (<Tensor[Float32], (32, 6, 28, 28)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(266)/        output = self.conv2d(x, self.weight)/
  %2([CNode]266) = Switch(false, DeadNode, @51_✗construct.588)
      : (<Bool>, <unknown>, <Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
  %3([CNode]844) = UpdateState(%para81_u, %0)
      : (<UMonad>, <Tensor[Float32], (6, 1, 5, 5)>) -> (<UMonad>)
  %4([CNode]269) = %2[51_✗construct.588](%3)
      : (<UMonad>) -> (<Tensor[Float32], (32, 6, 28, 28)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
  %5([CNode]845) = UpdateState(%3, %4)
      : (<UMonad>, <Tensor[Float32], (32, 6, 28, 28)>) -> (<UMonad>)
  %6([CNode]269) = Depend(%4, %5) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], (32, 6, 28, 28)>, <UMonad>) -> (<Tensor[Float32], (32, 6, 28, 28)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
  Return(%6)
      : (<Tensor[Float32], (32, 6, 28, 28)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @51_✗construct.588(%para82_u) {
  %0([CNode]265) = call @52_↓construct.586($(@50_construct.587:output))
      : (<Tensor[Float32], (32, 6, 28, 28)>) -> (<Tensor[Float32], (32, 6, 28, 28)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
  %1([CNode]265) = Depend(%0, %para82_u) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], (32, 6, 28, 28)>, <UMonad>) -> (<Tensor[Float32], (32, 6, 28, 28)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
  Return(%1)
      : (<Tensor[Float32], (32, 6, 28, 28)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @9_construct.599(%para83_x, %para84_u) {
  %0(x) = call @50_construct.587(%para83_x, %para84_u)
      : (<Tensor[Float32], (32, 1, 32, 32)>, <UMonad>) -> (<Tensor[Float32], (32, 6, 28, 28)>)
      # In file D:\PythonCode\LeNet\lenet.py(41)/        x = self.conv1(x)/
  %1(x) = call @49_construct.589(%0)
      : (<Tensor[Float32], (32, 6, 28, 28)>) -> (<Tensor[Float32], (32, 6, 28, 28)>)
      # In file D:\PythonCode\LeNet\lenet.py(42)/        x = self.relu(x)/
  %2(x) = call @48_construct.590(%1)
      : (<Tensor[Float32], (32, 6, 28, 28)>) -> (<Tensor[Float32], (32, 6, 14, 14)>)
      # In file D:\PythonCode\LeNet\lenet.py(43)/        x = self.max_pool2d(x)/
  %3([CNode]846) = UpdateState(%para84_u, %0)
      : (<UMonad>, <Tensor[Float32], (32, 6, 28, 28)>) -> (<UMonad>)
  %4(x) = call @45_construct.584(%2, %3)
      : (<Tensor[Float32], (32, 6, 14, 14)>, <UMonad>) -> (<Tensor[Float32], (32, 16, 10, 10)>)
      # In file D:\PythonCode\LeNet\lenet.py(44)/        x = self.conv2(x)/
  %5(x) = call @44_construct.591(%4)
      : (<Tensor[Float32], (32, 16, 10, 10)>) -> (<Tensor[Float32], (32, 16, 10, 10)>)
      # In file D:\PythonCode\LeNet\lenet.py(45)/        x = self.relu(x)/
  %6(x) = call @43_construct.592(%5)
      : (<Tensor[Float32], (32, 16, 10, 10)>) -> (<Tensor[Float32], (32, 16, 5, 5)>)
      # In file D:\PythonCode\LeNet\lenet.py(46)/        x = self.max_pool2d(x)/
  %7(x) = call @42_construct.593(%6)
      : (<Tensor[Float32], (32, 16, 5, 5)>) -> (<Tensor[Float32], (32, 400)>)
      # In file D:\PythonCode\LeNet\lenet.py(47)/        x = self.flatten(x)/
  %8([CNode]847) = UpdateState(%3, %4)
      : (<UMonad>, <Tensor[Float32], (32, 16, 10, 10)>) -> (<UMonad>)
  %9(x) = call @32_construct.594(%7, %8)
      : (<Tensor[Float32], (32, 400)>, <UMonad>) -> (<Tensor[Float32], (32, 120)>)
      # In file D:\PythonCode\LeNet\lenet.py(48)/        x = self.fc1(x)/
  %10(x) = call @31_construct.595(%9)
      : (<Tensor[Float32], (32, 120)>) -> (<Tensor[Float32], (32, 120)>)
      # In file D:\PythonCode\LeNet\lenet.py(49)/        x = self.relu(x)/
  %11([CNode]848) = UpdateState(%8, %9)
      : (<UMonad>, <Tensor[Float32], (32, 120)>) -> (<UMonad>)
  %12(x) = call @21_construct.596(%10, %11)
      : (<Tensor[Float32], (32, 120)>, <UMonad>) -> (<Tensor[Float32], (32, 84)>)
      # In file D:\PythonCode\LeNet\lenet.py(50)/        x = self.fc2(x)/
  %13(x) = call @20_construct.597(%12)
      : (<Tensor[Float32], (32, 84)>) -> (<Tensor[Float32], (32, 84)>)
      # In file D:\PythonCode\LeNet\lenet.py(51)/        x = self.relu(x)/
  %14([CNode]849) = UpdateState(%11, %12)
      : (<UMonad>, <Tensor[Float32], (32, 84)>) -> (<UMonad>)
  %15(x) = call @10_construct.598(%13, %14)
      : (<Tensor[Float32], (32, 84)>, <UMonad>) -> (<Tensor[Float32], (32, 10)>)
      # In file D:\PythonCode\LeNet\lenet.py(52)/        x = self.fc3(x)/
  %16([CNode]850) = UpdateState(%14, %15)
      : (<UMonad>, <Tensor[Float32], (32, 10)>) -> (<UMonad>)
  %17(x) = Depend(%15, %16) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], (32, 10)>, <UMonad>) -> (<Tensor[Float32], (32, 10)>)
      # In file D:\PythonCode\LeNet\lenet.py(52)/        x = self.fc3(x)/
  Return(%17)
      : (<Tensor[Float32], (32, 10)>)
      # In file D:\PythonCode\LeNet\lenet.py(53)/        return x/
}

subgraph attr:
defer_inline : 1
Undeterminate : 0
training : 1
subgraph @5_construct.550(%para85_data, %para86_label, %para87_u) {
  %0(out) = call @9_construct.599(%para85_data, %para87_u)
      : (<Tensor[Float32], (32, 1, 32, 32)>, <UMonad>) -> (<Tensor[Float32], (32, 10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(110)/        out = self._backbone(data)/
  %1([CNode]274) = call @6_construct.551(%0, %para86_label)
      : (<Tensor[Float32], (32, 10)>, <Tensor[Int32], (32)>) -> (<Tensor[Float32], ()>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(111)/        return self._loss_fn(out, label)/
  %2([CNode]851) = UpdateState(%para87_u, %0)
      : (<UMonad>, <Tensor[Float32], (32, 10)>) -> (<UMonad>)
  %3([CNode]274) = Depend(%1, %2) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], ()>, <UMonad>) -> (<Tensor[Float32], ()>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(111)/        return self._loss_fn(out, label)/
  Return(%3)
      : (<Tensor[Float32], ()>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(111)/        return self._loss_fn(out, label)/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @3_construct.543(%para88_inputs0, %para89_inputs1, %para90_u) {
  %0([CNode]546) = MakeTuple(%para88_inputs0, %para89_inputs1)
      : (<Tensor[Float32], (32, 1, 32, 32)>, <Tensor[Int32], (32)>) -> (<Tuple[Tensor[Float32],Tensor[Int32]], sequence_nodes={node={3_construct.543:[CNode]546{[0]: ValueNode<Primitive> MakeTuple, [1]: inputs0, [2]: inputs1}, elements_use_flags: {ptr: 0x159961679b0, value: [const vector][1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(360)/    def construct(self, *inputs):/
  %1(loss) = call @4_UnpackCall.600(@5_construct.550, %0, %para90_u)
      : (<Func>, <Tuple[Tensor[Float32],Tensor[Int32]], sequence_nodes={node={3_construct.543:[CNode]546{[0]: ValueNode<Primitive> MakeTuple, [1]: inputs0, [2]: inputs1}, elements_use_flags: {ptr: 0x159961679b0, value: [const vector][1, 1]}}}>, <UMonad>) -> (<Tensor[Float32], ()>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(361)/        loss = self.network(*inputs)/
  %2([CNode]394) = MakeTuple($(@1_construct_wrapper.536:para3_conv1.weight), $(@1_construct_wrapper.536:para4_conv2.weight), $(@1_construct_wrapper.536:para5_fc1.weight), $(@1_construct_wrapper.536:para6_fc1.bias), $(@1_construct_wrapper.536:para7_fc2.weight), $(@1_construct_wrapper.536:para8_fc2.bias), $(@1_construct_wrapper.536:para9_fc3.weight), $(@1_construct_wrapper.536:para10_fc3.bias))
      : (<Ref[Tensor(F32)], (6, 1, 5, 5)>, <Ref[Tensor(F32)], (16, 6, 5, 5)>, <Ref[Tensor(F32)], (120, 400)>, <Ref[Tensor(F32)], (120)>, <Ref[Tensor(F32)], (84, 120)>, <Ref[Tensor(F32)], (84)>, <Ref[Tensor(F32)], (10, 84)>, <Ref[Tensor(F32)], (10)>) -> (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={3_construct.543:[CNode]394{[0]: ValueNode<Primitive> MakeTuple, [1]: conv1.weight, [2]: conv2.weight, [3]: fc1.weight, [4]: fc1.bias, [5]: fc2.weight, [6]: fc2.bias, [7]: fc3.weight, [8]: fc3.bias}, elements_use_flags: {ptr: 0x15996645840, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/
  %3(grads) = call @110_construct.742(@5_construct.550, %2)
      : (<Func>, <Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={3_construct.543:[CNode]394{[0]: ValueNode<Primitive> MakeTuple, [1]: conv1.weight, [2]: conv2.weight, [3]: fc1.weight, [4]: fc1.bias, [5]: fc2.weight, [6]: fc2.bias, [7]: fc3.weight, [8]: fc3.bias}, elements_use_flags: {ptr: 0x15996645840, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/
  %4([CNode]895) = UpdateState(%para90_u, %1)
      : (<UMonad>, <Tensor[Float32], ()>) -> (<UMonad>)
  %5(grads) = call @109_UnpackCall.779(%3, %0, (Tensor(shape=[], dtype=Float32, value=1)), %4)
      : (<Func>, <Tuple[Tensor[Float32],Tensor[Int32]], sequence_nodes={node={3_construct.543:[CNode]546{[0]: ValueNode<Primitive> MakeTuple, [1]: inputs0, [2]: inputs1}, elements_use_flags: {ptr: 0x159961679b0, value: [const vector][1, 1]}}}>, <Tuple[Tensor[Float32]], sequence_nodes={node={ValueNode<ValueTuple> (Tensor(shape=[], dtype=Float32, value=1)), elements_use_flags: {ptr: 0x15996645200, value: [const vector][1]}}}>, <UMonad>) -> (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/
  %6(grads) = identity(%5) {instance name: grad_reducer} primitive_attrs: {side_effect_propagate: 1}
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>) -> (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(364)/        grads = self.grad_reducer(grads)/
  %7([CNode]896) = UpdateState(%4, %5)
      : (<UMonad>, <Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>) -> (<UMonad>)
  %8([CNode]19) = call @53_construct.621(%6, %7)
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <UMonad>) -> (<Tuple[Bool*8], sequence_nodes={node={62_hyper_map.601:success{[0]: ValueNode<Primitive> MakeTuple, [1]: success, [2]: success, [3]: success, [4]: success, [5]: success, [6]: success, [7]: success, [8]: success}, elements_use_flags: {ptr: 0x15996845170, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(365)/        loss = F.depend(loss, self.optimizer(grads))/
  %9(loss) = Depend(%1, %8) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], ()>, <Tuple[Bool*8], sequence_nodes={node={62_hyper_map.601:success{[0]: ValueNode<Primitive> MakeTuple, [1]: success, [2]: success, [3]: success, [4]: success, [5]: success, [6]: success, [7]: success, [8]: success}, elements_use_flags: {ptr: 0x15996845170, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>) -> (<Tensor[Float32], ()>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(365)/        loss = F.depend(loss, self.optimizer(grads))/
  %10([CNode]897) = UpdateState(%7, %8)
      : (<UMonad>, <Tuple[Bool*8], sequence_nodes={node={62_hyper_map.601:success{[0]: ValueNode<Primitive> MakeTuple, [1]: success, [2]: success, [3]: success, [4]: success, [5]: success, [6]: success, [7]: success, [8]: success}, elements_use_flags: {ptr: 0x15996845170, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>) -> (<UMonad>)
  %11(loss) = Depend(%9, %10) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], ()>, <UMonad>) -> (<Tensor[Float32], ()>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(365)/        loss = F.depend(loss, self.optimizer(grads))/
  Return(%11)
      : (<Tensor[Float32], ()>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(366)/        return loss/
}

subgraph attr:
after_block : 1
Undeterminate : 0
training : 1
subgraph @61_↓construct.733(%para91_Φsuccess) {
  Return(%para91_Φsuccess)
      : (<Tuple[Bool*8], sequence_nodes={node={62_hyper_map.601:success{[0]: ValueNode<Primitive> MakeTuple, [1]: success, [2]: success, [3]: success, [4]: success, [5]: success, [6]: success, [7]: success, [8]: success}, elements_use_flags: {ptr: 0x15996845170, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(183)/        return success/
}

subgraph attr:
after_block : 1
Undeterminate : 0
subgraph @67_↓_tensor_run_opt_ext.605(%para92_Φsuccess) {
  Return(%para92_Φsuccess)
      : (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(38)/    return success/
}

subgraph attr:
Undeterminate : 0
subgraph @65__tensor_run_opt_ext.603(%para93_opt, %para94_momentum, %para95_learning_rate, %para96_gradient, %para97_weight, %para98_moment, %para99_ps_parameter, %para100_cache_enable, %para101_u) {
  %0([CNode]606) = Switch(false, DeadNode, @66_✗_tensor_run_opt_ext.607)
      : (<Bool>, <unknown>, <Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  %1([CNode]608) = %0[66_✗_tensor_run_opt_ext.607](%para101_u)
      : (<UMonad>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  Return(%1)
      : (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
}

subgraph attr:
Undeterminate : 0
subgraph @66_✗_tensor_run_opt_ext.607(%para102_u) {
  %0([CNode]602) = ApplyMomentum($(@65__tensor_run_opt_ext.603:para97_weight), $(@65__tensor_run_opt_ext.603:para98_moment), $(@65__tensor_run_opt_ext.603:para95_learning_rate), $(@65__tensor_run_opt_ext.603:para96_gradient), $(@65__tensor_run_opt_ext.603:para94_momentum), %para102_u) {instance name: opt} primitive_attrs: {output_names: [output], side_effect_mem: true, use_nesterov: false, input_names: [variable, accumulation, learning_rate, gradient, momentum], use_locking: false, gradient_scale: 1.000000}
      : (<Ref[Tensor(F32)], (6, 1, 5, 5)>, <Ref[Tensor(F32)], (6, 1, 5, 5)>, <Ref[Tensor(F32)], ()>, <Tensor[Float32], (6, 1, 5, 5)>, <Ref[Tensor(F32)], ()>, <UMonad>) -> (<Tensor[Float32], (6, 1, 5, 5)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/
  %1(success) = Depend(true, %0) primitive_attrs: {side_effect_propagate: 1}
      : (<Bool>, <Tensor[Float32], (6, 1, 5, 5)>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/
  %2([CNode]604) = call @67_↓_tensor_run_opt_ext.605(%1)
      : (<Bool>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  %3([CNode]852) = UpdateState(%para102_u, %0)
      : (<UMonad>, <Tensor[Float32], (6, 1, 5, 5)>) -> (<UMonad>)
  %4([CNode]604) = Depend(%2, %3) primitive_attrs: {side_effect_propagate: 1}
      : (<Bool>, <UMonad>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  Return(%4)
      : (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
}

subgraph attr:
core : 1
Undeterminate : 0
subgraph @64_619.620(%para103_781, %para104_610, %para105_611, %para106_612, %para107_613, %para108_614, %para109_782, %para110_783, %para111_u) {
  %0([CNode]609) = call @65__tensor_run_opt_ext.603(PolyNode, %para104_610, %para105_611, %para106_612, %para107_613, %para108_614, false, false, %para111_u)
      : (<unknown>, <Ref[Tensor(F32)], ()>, <Ref[Tensor(F32)], ()>, <Tensor[Float32], (6, 1, 5, 5)>, <Ref[Tensor(F32)], (6, 1, 5, 5)>, <Ref[Tensor(F32)], (6, 1, 5, 5)>, <Bool>, <Bool>, <UMonad>) -> (<Bool>)
  Return(%0)
      : (<Bool>)
}

subgraph attr:
after_block : 1
Undeterminate : 0
training : 1
subgraph @60_↓get_lr.615(%para112_Φlr) {
  Return(%para112_Φlr)
      : (<Ref[Tensor(F32)], ()>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(597)/        return lr/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @59_✗get_lr.616() {
  %0([CNode]337) = call @60_↓get_lr.615($(@1_construct_wrapper.536:para20_learning_rate))
      : (<Ref[Tensor(F32)], ()>) -> (<Ref[Tensor(F32)], ()>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(587)/        if self.dynamic_lr:/
  Return(%0)
      : (<Ref[Tensor(F32)], ()>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(587)/        if self.dynamic_lr:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @58_get_lr.617() {
  %0([CNode]338) = Switch(false, DeadNode, @59_✗get_lr.616)
      : (<Bool>, <unknown>, <Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(587)/        if self.dynamic_lr:/
  %1([CNode]341) = %0[59_✗get_lr.616]()
      : () -> (<Ref[Tensor(F32)], ()>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(587)/        if self.dynamic_lr:/
  Return(%1)
      : (<Ref[Tensor(F32)], ()>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(587)/        if self.dynamic_lr:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @53_construct.621(%para113_gradients, %para114_u) {
  %0(lr) = call @58_get_lr.617()
      : () -> (<Ref[Tensor(F32)], ()>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(176)/        lr = self.get_lr()/
  %1(gradients) = call @106_decay_weight.731(%para113_gradients)
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>) -> (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(173)/        gradients = self.decay_weight(gradients)/
  %2(gradients) = call @103_gradients_centralization.728(%1)
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>) -> (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(174)/        gradients = self.gradients_centralization(gradients)/
  %3(gradients) = call @55_scale_grad.725(%2)
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>) -> (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(175)/        gradients = self.scale_grad(gradients)/
  %4([CNode]383) = MakeTuple($(@1_construct_wrapper.536:para3_conv1.weight), $(@1_construct_wrapper.536:para4_conv2.weight), $(@1_construct_wrapper.536:para5_fc1.weight), $(@1_construct_wrapper.536:para6_fc1.bias), $(@1_construct_wrapper.536:para7_fc2.weight), $(@1_construct_wrapper.536:para8_fc2.bias), $(@1_construct_wrapper.536:para9_fc3.weight), $(@1_construct_wrapper.536:para10_fc3.bias))
      : (<Ref[Tensor(F32)], (6, 1, 5, 5)>, <Ref[Tensor(F32)], (16, 6, 5, 5)>, <Ref[Tensor(F32)], (120, 400)>, <Ref[Tensor(F32)], (120)>, <Ref[Tensor(F32)], (84, 120)>, <Ref[Tensor(F32)], (84)>, <Ref[Tensor(F32)], (10, 84)>, <Ref[Tensor(F32)], (10)>) -> (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={53_construct.621:[CNode]383{[0]: ValueNode<Primitive> MakeTuple, [1]: conv1.weight, [2]: conv2.weight, [3]: fc1.weight, [4]: fc1.bias, [5]: fc2.weight, [6]: fc2.bias, [7]: fc3.weight, [8]: fc3.bias}, elements_use_flags: {ptr: 0x159966d07d0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(171)/        params = self.params/
  %5([CNode]384) = MakeTuple($(@1_construct_wrapper.536:para11_moments.conv1.weight), $(@1_construct_wrapper.536:para12_moments.conv2.weight), $(@1_construct_wrapper.536:para13_moments.fc1.weight), $(@1_construct_wrapper.536:para14_moments.fc1.bias), $(@1_construct_wrapper.536:para15_moments.fc2.weight), $(@1_construct_wrapper.536:para16_moments.fc2.bias), $(@1_construct_wrapper.536:para17_moments.fc3.weight), $(@1_construct_wrapper.536:para18_moments.fc3.bias))
      : (<Ref[Tensor(F32)], (6, 1, 5, 5)>, <Ref[Tensor(F32)], (16, 6, 5, 5)>, <Ref[Tensor(F32)], (120, 400)>, <Ref[Tensor(F32)], (120)>, <Ref[Tensor(F32)], (84, 120)>, <Ref[Tensor(F32)], (84)>, <Ref[Tensor(F32)], (10, 84)>, <Ref[Tensor(F32)], (10)>) -> (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={53_construct.621:[CNode]384{[0]: ValueNode<Primitive> MakeTuple, [1]: moments.conv1.weight, [2]: moments.conv2.weight, [3]: moments.fc1.weight, [4]: moments.fc1.bias, [5]: moments.fc2.weight, [6]: moments.fc2.bias, [7]: moments.fc3.weight, [8]: moments.fc3.bias}, elements_use_flags: {ptr: 0x159966d02d0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(172)/        moments = self.moments/
  %6([CNode]390) = Switch(false, DeadNode, @54_✗construct.734)
      : (<Bool>, <unknown>, <Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(177)/        if self.is_group_lr:/
  %7([CNode]393) = %6[54_✗construct.734](%para114_u)
      : (<UMonad>) -> (<Tuple[Bool*8], sequence_nodes={node={62_hyper_map.601:success{[0]: ValueNode<Primitive> MakeTuple, [1]: success, [2]: success, [3]: success, [4]: success, [5]: success, [6]: success, [7]: success, [8]: success}, elements_use_flags: {ptr: 0x15996845170, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(177)/        if self.is_group_lr:/
  Return(%7)
      : (<Tuple[Bool*8], sequence_nodes={node={62_hyper_map.601:success{[0]: ValueNode<Primitive> MakeTuple, [1]: success, [2]: success, [3]: success, [4]: success, [5]: success, [6]: success, [7]: success, [8]: success}, elements_use_flags: {ptr: 0x15996845170, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(177)/        if self.is_group_lr:/
}

subgraph attr:
spec_param : 1
core : 1
Undeterminate : 0
subgraph @63_hyper_map.638(%para115_[Parameter]784, %para116_[Parameter]622, %para117_[Parameter]623, %para118_[Parameter]624, %para119_[Parameter]785, %para120_[Parameter]786, %para121_u) {
  %0([CNode]618) = Partial(@64_619.620, S-Prim-ApplyMomentum, $(@1_construct_wrapper.536:para19_momentum), $(@53_construct.621:lr)) primitive_attrs: {side_effect_propagate: 1}
      : (<Func>, <Func>, <Ref[Tensor(F32)], ()>, <Ref[Tensor(F32)], ()>) -> (<Func>)
  %1([CNode]609) = %0(%para116_[Parameter]622, %para117_[Parameter]623, %para118_[Parameter]624, false, false, %para121_u)
      : (<Tensor[Float32], (6, 1, 5, 5)>, <Ref[Tensor(F32)], (6, 1, 5, 5)>, <Ref[Tensor(F32)], (6, 1, 5, 5)>, <Bool>, <Bool>, <UMonad>) -> (<Bool>)
  Return(%1)
      : (<Bool>)
}

subgraph attr:
spec_param : 1
core : 1
Undeterminate : 0
subgraph @62_hyper_map.601(%para122_[Parameter]639, %para123_[Parameter]625, %para124_[Parameter]636, %para125_[Parameter]637, %para126_[Parameter]787, %para127_[Parameter]788, %para128_u) {
  %0(success) = TupleGetItem(%para123_[Parameter]625, 0)
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Tensor[Float32], (6, 1, 5, 5)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %1(success) = TupleGetItem(%para124_[Parameter]636, 0)
      : (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={53_construct.621:[CNode]383{[0]: ValueNode<Primitive> MakeTuple, [1]: conv1.weight, [2]: conv2.weight, [3]: fc1.weight, [4]: fc1.bias, [5]: fc2.weight, [6]: fc2.bias, [7]: fc3.weight, [8]: fc3.bias}, elements_use_flags: {ptr: 0x159966d07d0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Ref[Tensor(F32)], (6, 1, 5, 5)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %2(success) = TupleGetItem(%para125_[Parameter]637, 0)
      : (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={53_construct.621:[CNode]384{[0]: ValueNode<Primitive> MakeTuple, [1]: moments.conv1.weight, [2]: moments.conv2.weight, [3]: moments.fc1.weight, [4]: moments.fc1.bias, [5]: moments.fc2.weight, [6]: moments.fc2.bias, [7]: moments.fc3.weight, [8]: moments.fc3.bias}, elements_use_flags: {ptr: 0x159966d02d0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Ref[Tensor(F32)], (6, 1, 5, 5)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %3(success) = TupleGetItem(%para123_[Parameter]625, 7)
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Tensor[Float32], (10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %4(success) = TupleGetItem(%para124_[Parameter]636, 7)
      : (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={53_construct.621:[CNode]383{[0]: ValueNode<Primitive> MakeTuple, [1]: conv1.weight, [2]: conv2.weight, [3]: fc1.weight, [4]: fc1.bias, [5]: fc2.weight, [6]: fc2.bias, [7]: fc3.weight, [8]: fc3.bias}, elements_use_flags: {ptr: 0x159966d07d0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Ref[Tensor(F32)], (10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %5(success) = TupleGetItem(%para125_[Parameter]637, 7)
      : (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={53_construct.621:[CNode]384{[0]: ValueNode<Primitive> MakeTuple, [1]: moments.conv1.weight, [2]: moments.conv2.weight, [3]: moments.fc1.weight, [4]: moments.fc1.bias, [5]: moments.fc2.weight, [6]: moments.fc2.bias, [7]: moments.fc3.weight, [8]: moments.fc3.bias}, elements_use_flags: {ptr: 0x159966d02d0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Ref[Tensor(F32)], (10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %6(success) = call @98_hyper_map.723(%para122_[Parameter]639, %3, %4, %5, false, false, %para128_u)
      : (<Func>, <Tensor[Float32], (10)>, <Ref[Tensor(F32)], (10)>, <Ref[Tensor(F32)], (10)>, <Bool>, <Bool>, <UMonad>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %7([CNode]854) = UpdateState(%para128_u, %6)
      : (<UMonad>, <Bool>) -> (<UMonad>)
  %8(success) = TupleGetItem(%para123_[Parameter]625, 6)
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Tensor[Float32], (10, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %9(success) = TupleGetItem(%para124_[Parameter]636, 6)
      : (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={53_construct.621:[CNode]383{[0]: ValueNode<Primitive> MakeTuple, [1]: conv1.weight, [2]: conv2.weight, [3]: fc1.weight, [4]: fc1.bias, [5]: fc2.weight, [6]: fc2.bias, [7]: fc3.weight, [8]: fc3.bias}, elements_use_flags: {ptr: 0x159966d07d0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Ref[Tensor(F32)], (10, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %10(success) = TupleGetItem(%para125_[Parameter]637, 6)
      : (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={53_construct.621:[CNode]384{[0]: ValueNode<Primitive> MakeTuple, [1]: moments.conv1.weight, [2]: moments.conv2.weight, [3]: moments.fc1.weight, [4]: moments.fc1.bias, [5]: moments.fc2.weight, [6]: moments.fc2.bias, [7]: moments.fc3.weight, [8]: moments.fc3.bias}, elements_use_flags: {ptr: 0x159966d02d0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Ref[Tensor(F32)], (10, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %11(success) = call @93_hyper_map.711(%para122_[Parameter]639, %8, %9, %10, false, false, %7)
      : (<Func>, <Tensor[Float32], (10, 84)>, <Ref[Tensor(F32)], (10, 84)>, <Ref[Tensor(F32)], (10, 84)>, <Bool>, <Bool>, <UMonad>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %12([CNode]856) = UpdateState(%7, %11)
      : (<UMonad>, <Bool>) -> (<UMonad>)
  %13(success) = TupleGetItem(%para123_[Parameter]625, 5)
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Tensor[Float32], (84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %14(success) = TupleGetItem(%para124_[Parameter]636, 5)
      : (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={53_construct.621:[CNode]383{[0]: ValueNode<Primitive> MakeTuple, [1]: conv1.weight, [2]: conv2.weight, [3]: fc1.weight, [4]: fc1.bias, [5]: fc2.weight, [6]: fc2.bias, [7]: fc3.weight, [8]: fc3.bias}, elements_use_flags: {ptr: 0x159966d07d0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Ref[Tensor(F32)], (84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %15(success) = TupleGetItem(%para125_[Parameter]637, 5)
      : (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={53_construct.621:[CNode]384{[0]: ValueNode<Primitive> MakeTuple, [1]: moments.conv1.weight, [2]: moments.conv2.weight, [3]: moments.fc1.weight, [4]: moments.fc1.bias, [5]: moments.fc2.weight, [6]: moments.fc2.bias, [7]: moments.fc3.weight, [8]: moments.fc3.bias}, elements_use_flags: {ptr: 0x159966d02d0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Ref[Tensor(F32)], (84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %16(success) = call @88_hyper_map.699(%para122_[Parameter]639, %13, %14, %15, false, false, %12)
      : (<Func>, <Tensor[Float32], (84)>, <Ref[Tensor(F32)], (84)>, <Ref[Tensor(F32)], (84)>, <Bool>, <Bool>, <UMonad>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %17([CNode]858) = UpdateState(%12, %16)
      : (<UMonad>, <Bool>) -> (<UMonad>)
  %18(success) = TupleGetItem(%para123_[Parameter]625, 4)
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Tensor[Float32], (84, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %19(success) = TupleGetItem(%para124_[Parameter]636, 4)
      : (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={53_construct.621:[CNode]383{[0]: ValueNode<Primitive> MakeTuple, [1]: conv1.weight, [2]: conv2.weight, [3]: fc1.weight, [4]: fc1.bias, [5]: fc2.weight, [6]: fc2.bias, [7]: fc3.weight, [8]: fc3.bias}, elements_use_flags: {ptr: 0x159966d07d0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Ref[Tensor(F32)], (84, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %20(success) = TupleGetItem(%para125_[Parameter]637, 4)
      : (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={53_construct.621:[CNode]384{[0]: ValueNode<Primitive> MakeTuple, [1]: moments.conv1.weight, [2]: moments.conv2.weight, [3]: moments.fc1.weight, [4]: moments.fc1.bias, [5]: moments.fc2.weight, [6]: moments.fc2.bias, [7]: moments.fc3.weight, [8]: moments.fc3.bias}, elements_use_flags: {ptr: 0x159966d02d0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Ref[Tensor(F32)], (84, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %21(success) = call @83_hyper_map.687(%para122_[Parameter]639, %18, %19, %20, false, false, %17)
      : (<Func>, <Tensor[Float32], (84, 120)>, <Ref[Tensor(F32)], (84, 120)>, <Ref[Tensor(F32)], (84, 120)>, <Bool>, <Bool>, <UMonad>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %22([CNode]860) = UpdateState(%17, %21)
      : (<UMonad>, <Bool>) -> (<UMonad>)
  %23(success) = TupleGetItem(%para123_[Parameter]625, 3)
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Tensor[Float32], (120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %24(success) = TupleGetItem(%para124_[Parameter]636, 3)
      : (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={53_construct.621:[CNode]383{[0]: ValueNode<Primitive> MakeTuple, [1]: conv1.weight, [2]: conv2.weight, [3]: fc1.weight, [4]: fc1.bias, [5]: fc2.weight, [6]: fc2.bias, [7]: fc3.weight, [8]: fc3.bias}, elements_use_flags: {ptr: 0x159966d07d0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Ref[Tensor(F32)], (120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %25(success) = TupleGetItem(%para125_[Parameter]637, 3)
      : (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={53_construct.621:[CNode]384{[0]: ValueNode<Primitive> MakeTuple, [1]: moments.conv1.weight, [2]: moments.conv2.weight, [3]: moments.fc1.weight, [4]: moments.fc1.bias, [5]: moments.fc2.weight, [6]: moments.fc2.bias, [7]: moments.fc3.weight, [8]: moments.fc3.bias}, elements_use_flags: {ptr: 0x159966d02d0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Ref[Tensor(F32)], (120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %26(success) = call @78_hyper_map.675(%para122_[Parameter]639, %23, %24, %25, false, false, %22)
      : (<Func>, <Tensor[Float32], (120)>, <Ref[Tensor(F32)], (120)>, <Ref[Tensor(F32)], (120)>, <Bool>, <Bool>, <UMonad>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %27([CNode]862) = UpdateState(%22, %26)
      : (<UMonad>, <Bool>) -> (<UMonad>)
  %28(success) = TupleGetItem(%para123_[Parameter]625, 2)
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Tensor[Float32], (120, 400)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %29(success) = TupleGetItem(%para124_[Parameter]636, 2)
      : (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={53_construct.621:[CNode]383{[0]: ValueNode<Primitive> MakeTuple, [1]: conv1.weight, [2]: conv2.weight, [3]: fc1.weight, [4]: fc1.bias, [5]: fc2.weight, [6]: fc2.bias, [7]: fc3.weight, [8]: fc3.bias}, elements_use_flags: {ptr: 0x159966d07d0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Ref[Tensor(F32)], (120, 400)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %30(success) = TupleGetItem(%para125_[Parameter]637, 2)
      : (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={53_construct.621:[CNode]384{[0]: ValueNode<Primitive> MakeTuple, [1]: moments.conv1.weight, [2]: moments.conv2.weight, [3]: moments.fc1.weight, [4]: moments.fc1.bias, [5]: moments.fc2.weight, [6]: moments.fc2.bias, [7]: moments.fc3.weight, [8]: moments.fc3.bias}, elements_use_flags: {ptr: 0x159966d02d0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Ref[Tensor(F32)], (120, 400)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %31(success) = call @73_hyper_map.663(%para122_[Parameter]639, %28, %29, %30, false, false, %27)
      : (<Func>, <Tensor[Float32], (120, 400)>, <Ref[Tensor(F32)], (120, 400)>, <Ref[Tensor(F32)], (120, 400)>, <Bool>, <Bool>, <UMonad>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %32([CNode]864) = UpdateState(%27, %31)
      : (<UMonad>, <Bool>) -> (<UMonad>)
  %33(success) = TupleGetItem(%para123_[Parameter]625, 1)
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Tensor[Float32], (16, 6, 5, 5)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %34(success) = TupleGetItem(%para124_[Parameter]636, 1)
      : (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={53_construct.621:[CNode]383{[0]: ValueNode<Primitive> MakeTuple, [1]: conv1.weight, [2]: conv2.weight, [3]: fc1.weight, [4]: fc1.bias, [5]: fc2.weight, [6]: fc2.bias, [7]: fc3.weight, [8]: fc3.bias}, elements_use_flags: {ptr: 0x159966d07d0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Ref[Tensor(F32)], (16, 6, 5, 5)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %35(success) = TupleGetItem(%para125_[Parameter]637, 1)
      : (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={53_construct.621:[CNode]384{[0]: ValueNode<Primitive> MakeTuple, [1]: moments.conv1.weight, [2]: moments.conv2.weight, [3]: moments.fc1.weight, [4]: moments.fc1.bias, [5]: moments.fc2.weight, [6]: moments.fc2.bias, [7]: moments.fc3.weight, [8]: moments.fc3.bias}, elements_use_flags: {ptr: 0x159966d02d0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Ref[Tensor(F32)], (16, 6, 5, 5)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %36(success) = call @68_hyper_map.651(%para122_[Parameter]639, %33, %34, %35, false, false, %32)
      : (<Func>, <Tensor[Float32], (16, 6, 5, 5)>, <Ref[Tensor(F32)], (16, 6, 5, 5)>, <Ref[Tensor(F32)], (16, 6, 5, 5)>, <Bool>, <Bool>, <UMonad>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %37([CNode]866) = UpdateState(%32, %36)
      : (<UMonad>, <Bool>) -> (<UMonad>)
  %38(success) = call @63_hyper_map.638(%para122_[Parameter]639, %0, %1, %2, false, false, %37)
      : (<Func>, <Tensor[Float32], (6, 1, 5, 5)>, <Ref[Tensor(F32)], (6, 1, 5, 5)>, <Ref[Tensor(F32)], (6, 1, 5, 5)>, <Bool>, <Bool>, <UMonad>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %39(success) = MakeTuple(%38, %36, %31, %26, %21, %16, %11, %6)
      : (<Bool>, <Bool>, <Bool>, <Bool>, <Bool>, <Bool>, <Bool>, <Bool>) -> (<Tuple[Bool*8], sequence_nodes={node={62_hyper_map.601:success{[0]: ValueNode<Primitive> MakeTuple, [1]: success, [2]: success, [3]: success, [4]: success, [5]: success, [6]: success, [7]: success, [8]: success}, elements_use_flags: {ptr: 0x15996845170, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %40([CNode]867) = UpdateState(%37, %38)
      : (<UMonad>, <Bool>) -> (<UMonad>)
  %41(success) = Depend(%39, %40) primitive_attrs: {side_effect_propagate: 1}
      : (<Tuple[Bool*8], sequence_nodes={node={62_hyper_map.601:success{[0]: ValueNode<Primitive> MakeTuple, [1]: success, [2]: success, [3]: success, [4]: success, [5]: success, [6]: success, [7]: success, [8]: success}, elements_use_flags: {ptr: 0x15996845170, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <UMonad>) -> (<Tuple[Bool*8], sequence_nodes={node={62_hyper_map.601:success{[0]: ValueNode<Primitive> MakeTuple, [1]: success, [2]: success, [3]: success, [4]: success, [5]: success, [6]: success, [7]: success, [8]: success}, elements_use_flags: {ptr: 0x15996845170, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  Return(%41)
      : (<Tuple[Bool*8], sequence_nodes={node={62_hyper_map.601:success{[0]: ValueNode<Primitive> MakeTuple, [1]: success, [2]: success, [3]: success, [4]: success, [5]: success, [6]: success, [7]: success, [8]: success}, elements_use_flags: {ptr: 0x15996845170, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
}

subgraph attr:
after_block : 1
Undeterminate : 0
subgraph @102_↓_tensor_run_opt_ext.713(%para129_Φsuccess) {
  Return(%para129_Φsuccess)
      : (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(38)/    return success/
}

subgraph attr:
Undeterminate : 0
subgraph @100__tensor_run_opt_ext.712(%para130_opt, %para131_momentum, %para132_learning_rate, %para133_gradient, %para134_weight, %para135_moment, %para136_ps_parameter, %para137_cache_enable, %para138_u) {
  %0([CNode]606) = Switch(false, DeadNode, @101_✗_tensor_run_opt_ext.714)
      : (<Bool>, <unknown>, <Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  %1([CNode]608) = %0[101_✗_tensor_run_opt_ext.714](%para138_u)
      : (<UMonad>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  Return(%1)
      : (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
}

subgraph attr:
Undeterminate : 0
subgraph @101_✗_tensor_run_opt_ext.714(%para139_u) {
  %0([CNode]602) = ApplyMomentum($(@100__tensor_run_opt_ext.712:para134_weight), $(@100__tensor_run_opt_ext.712:para135_moment), $(@100__tensor_run_opt_ext.712:para132_learning_rate), $(@100__tensor_run_opt_ext.712:para133_gradient), $(@100__tensor_run_opt_ext.712:para131_momentum), %para139_u) {instance name: opt} primitive_attrs: {output_names: [output], side_effect_mem: true, use_nesterov: false, input_names: [variable, accumulation, learning_rate, gradient, momentum], use_locking: false, gradient_scale: 1.000000}
      : (<Ref[Tensor(F32)], (10)>, <Ref[Tensor(F32)], (10)>, <Ref[Tensor(F32)], ()>, <Tensor[Float32], (10)>, <Ref[Tensor(F32)], ()>, <UMonad>) -> (<Tensor[Float32], (10)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/
  %1(success) = Depend(true, %0) primitive_attrs: {side_effect_propagate: 1}
      : (<Bool>, <Tensor[Float32], (10)>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/
  %2([CNode]604) = call @102_↓_tensor_run_opt_ext.713(%1)
      : (<Bool>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  %3([CNode]853) = UpdateState(%para139_u, %0)
      : (<UMonad>, <Tensor[Float32], (10)>) -> (<UMonad>)
  %4([CNode]604) = Depend(%2, %3) primitive_attrs: {side_effect_propagate: 1}
      : (<Bool>, <UMonad>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  Return(%4)
      : (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
}

subgraph attr:
core : 1
Undeterminate : 0
subgraph @99_721.722(%para140_807, %para141_715, %para142_716, %para143_717, %para144_718, %para145_719, %para146_808, %para147_809, %para148_u) {
  %0([CNode]609) = call @100__tensor_run_opt_ext.712(PolyNode, %para141_715, %para142_716, %para143_717, %para144_718, %para145_719, false, false, %para148_u)
      : (<unknown>, <Ref[Tensor(F32)], ()>, <Ref[Tensor(F32)], ()>, <Tensor[Float32], (10)>, <Ref[Tensor(F32)], (10)>, <Ref[Tensor(F32)], (10)>, <Bool>, <Bool>, <UMonad>) -> (<Bool>)
  Return(%0)
      : (<Bool>)
}

subgraph attr:
spec_param : 1
core : 1
Undeterminate : 0
subgraph @98_hyper_map.723(%para149_[Parameter]784, %para150_[Parameter]622, %para151_[Parameter]623, %para152_[Parameter]624, %para153_[Parameter]785, %para154_[Parameter]786, %para155_u) {
  %0([CNode]720) = Partial(@99_721.722, S-Prim-ApplyMomentum, $(@1_construct_wrapper.536:para19_momentum), $(@53_construct.621:lr)) primitive_attrs: {side_effect_propagate: 1}
      : (<Func>, <Func>, <Ref[Tensor(F32)], ()>, <Ref[Tensor(F32)], ()>) -> (<Func>)
  %1([CNode]609) = %0(%para150_[Parameter]622, %para151_[Parameter]623, %para152_[Parameter]624, false, false, %para155_u)
      : (<Tensor[Float32], (10)>, <Ref[Tensor(F32)], (10)>, <Ref[Tensor(F32)], (10)>, <Bool>, <Bool>, <UMonad>) -> (<Bool>)
  Return(%1)
      : (<Bool>)
}

subgraph attr:
after_block : 1
Undeterminate : 0
subgraph @97_↓_tensor_run_opt_ext.701(%para156_Φsuccess) {
  Return(%para156_Φsuccess)
      : (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(38)/    return success/
}

subgraph attr:
Undeterminate : 0
subgraph @95__tensor_run_opt_ext.700(%para157_opt, %para158_momentum, %para159_learning_rate, %para160_gradient, %para161_weight, %para162_moment, %para163_ps_parameter, %para164_cache_enable, %para165_u) {
  %0([CNode]606) = Switch(false, DeadNode, @96_✗_tensor_run_opt_ext.702)
      : (<Bool>, <unknown>, <Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  %1([CNode]608) = %0[96_✗_tensor_run_opt_ext.702](%para165_u)
      : (<UMonad>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  Return(%1)
      : (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
}

subgraph attr:
Undeterminate : 0
subgraph @96_✗_tensor_run_opt_ext.702(%para166_u) {
  %0([CNode]602) = ApplyMomentum($(@95__tensor_run_opt_ext.700:para161_weight), $(@95__tensor_run_opt_ext.700:para162_moment), $(@95__tensor_run_opt_ext.700:para159_learning_rate), $(@95__tensor_run_opt_ext.700:para160_gradient), $(@95__tensor_run_opt_ext.700:para158_momentum), %para166_u) {instance name: opt} primitive_attrs: {output_names: [output], side_effect_mem: true, use_nesterov: false, input_names: [variable, accumulation, learning_rate, gradient, momentum], use_locking: false, gradient_scale: 1.000000}
      : (<Ref[Tensor(F32)], (10, 84)>, <Ref[Tensor(F32)], (10, 84)>, <Ref[Tensor(F32)], ()>, <Tensor[Float32], (10, 84)>, <Ref[Tensor(F32)], ()>, <UMonad>) -> (<Tensor[Float32], (10, 84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/
  %1(success) = Depend(true, %0) primitive_attrs: {side_effect_propagate: 1}
      : (<Bool>, <Tensor[Float32], (10, 84)>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/
  %2([CNode]604) = call @97_↓_tensor_run_opt_ext.701(%1)
      : (<Bool>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  %3([CNode]855) = UpdateState(%para166_u, %0)
      : (<UMonad>, <Tensor[Float32], (10, 84)>) -> (<UMonad>)
  %4([CNode]604) = Depend(%2, %3) primitive_attrs: {side_effect_propagate: 1}
      : (<Bool>, <UMonad>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  Return(%4)
      : (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
}

subgraph attr:
core : 1
Undeterminate : 0
subgraph @94_709.710(%para167_804, %para168_703, %para169_704, %para170_705, %para171_706, %para172_707, %para173_805, %para174_806, %para175_u) {
  %0([CNode]609) = call @95__tensor_run_opt_ext.700(PolyNode, %para168_703, %para169_704, %para170_705, %para171_706, %para172_707, false, false, %para175_u)
      : (<unknown>, <Ref[Tensor(F32)], ()>, <Ref[Tensor(F32)], ()>, <Tensor[Float32], (10, 84)>, <Ref[Tensor(F32)], (10, 84)>, <Ref[Tensor(F32)], (10, 84)>, <Bool>, <Bool>, <UMonad>) -> (<Bool>)
  Return(%0)
      : (<Bool>)
}

subgraph attr:
spec_param : 1
core : 1
Undeterminate : 0
subgraph @93_hyper_map.711(%para176_[Parameter]784, %para177_[Parameter]622, %para178_[Parameter]623, %para179_[Parameter]624, %para180_[Parameter]785, %para181_[Parameter]786, %para182_u) {
  %0([CNode]708) = Partial(@94_709.710, S-Prim-ApplyMomentum, $(@1_construct_wrapper.536:para19_momentum), $(@53_construct.621:lr)) primitive_attrs: {side_effect_propagate: 1}
      : (<Func>, <Func>, <Ref[Tensor(F32)], ()>, <Ref[Tensor(F32)], ()>) -> (<Func>)
  %1([CNode]609) = %0(%para177_[Parameter]622, %para178_[Parameter]623, %para179_[Parameter]624, false, false, %para182_u)
      : (<Tensor[Float32], (10, 84)>, <Ref[Tensor(F32)], (10, 84)>, <Ref[Tensor(F32)], (10, 84)>, <Bool>, <Bool>, <UMonad>) -> (<Bool>)
  Return(%1)
      : (<Bool>)
}

subgraph attr:
after_block : 1
Undeterminate : 0
subgraph @92_↓_tensor_run_opt_ext.689(%para183_Φsuccess) {
  Return(%para183_Φsuccess)
      : (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(38)/    return success/
}

subgraph attr:
Undeterminate : 0
subgraph @90__tensor_run_opt_ext.688(%para184_opt, %para185_momentum, %para186_learning_rate, %para187_gradient, %para188_weight, %para189_moment, %para190_ps_parameter, %para191_cache_enable, %para192_u) {
  %0([CNode]606) = Switch(false, DeadNode, @91_✗_tensor_run_opt_ext.690)
      : (<Bool>, <unknown>, <Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  %1([CNode]608) = %0[91_✗_tensor_run_opt_ext.690](%para192_u)
      : (<UMonad>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  Return(%1)
      : (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
}

subgraph attr:
Undeterminate : 0
subgraph @91_✗_tensor_run_opt_ext.690(%para193_u) {
  %0([CNode]602) = ApplyMomentum($(@90__tensor_run_opt_ext.688:para188_weight), $(@90__tensor_run_opt_ext.688:para189_moment), $(@90__tensor_run_opt_ext.688:para186_learning_rate), $(@90__tensor_run_opt_ext.688:para187_gradient), $(@90__tensor_run_opt_ext.688:para185_momentum), %para193_u) {instance name: opt} primitive_attrs: {output_names: [output], side_effect_mem: true, use_nesterov: false, input_names: [variable, accumulation, learning_rate, gradient, momentum], use_locking: false, gradient_scale: 1.000000}
      : (<Ref[Tensor(F32)], (84)>, <Ref[Tensor(F32)], (84)>, <Ref[Tensor(F32)], ()>, <Tensor[Float32], (84)>, <Ref[Tensor(F32)], ()>, <UMonad>) -> (<Tensor[Float32], (84)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/
  %1(success) = Depend(true, %0) primitive_attrs: {side_effect_propagate: 1}
      : (<Bool>, <Tensor[Float32], (84)>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/
  %2([CNode]604) = call @92_↓_tensor_run_opt_ext.689(%1)
      : (<Bool>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  %3([CNode]857) = UpdateState(%para193_u, %0)
      : (<UMonad>, <Tensor[Float32], (84)>) -> (<UMonad>)
  %4([CNode]604) = Depend(%2, %3) primitive_attrs: {side_effect_propagate: 1}
      : (<Bool>, <UMonad>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  Return(%4)
      : (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
}

subgraph attr:
core : 1
Undeterminate : 0
subgraph @89_697.698(%para194_801, %para195_691, %para196_692, %para197_693, %para198_694, %para199_695, %para200_802, %para201_803, %para202_u) {
  %0([CNode]609) = call @90__tensor_run_opt_ext.688(PolyNode, %para195_691, %para196_692, %para197_693, %para198_694, %para199_695, false, false, %para202_u)
      : (<unknown>, <Ref[Tensor(F32)], ()>, <Ref[Tensor(F32)], ()>, <Tensor[Float32], (84)>, <Ref[Tensor(F32)], (84)>, <Ref[Tensor(F32)], (84)>, <Bool>, <Bool>, <UMonad>) -> (<Bool>)
  Return(%0)
      : (<Bool>)
}

subgraph attr:
spec_param : 1
core : 1
Undeterminate : 0
subgraph @88_hyper_map.699(%para203_[Parameter]784, %para204_[Parameter]622, %para205_[Parameter]623, %para206_[Parameter]624, %para207_[Parameter]785, %para208_[Parameter]786, %para209_u) {
  %0([CNode]696) = Partial(@89_697.698, S-Prim-ApplyMomentum, $(@1_construct_wrapper.536:para19_momentum), $(@53_construct.621:lr)) primitive_attrs: {side_effect_propagate: 1}
      : (<Func>, <Func>, <Ref[Tensor(F32)], ()>, <Ref[Tensor(F32)], ()>) -> (<Func>)
  %1([CNode]609) = %0(%para204_[Parameter]622, %para205_[Parameter]623, %para206_[Parameter]624, false, false, %para209_u)
      : (<Tensor[Float32], (84)>, <Ref[Tensor(F32)], (84)>, <Ref[Tensor(F32)], (84)>, <Bool>, <Bool>, <UMonad>) -> (<Bool>)
  Return(%1)
      : (<Bool>)
}

subgraph attr:
after_block : 1
Undeterminate : 0
subgraph @87_↓_tensor_run_opt_ext.677(%para210_Φsuccess) {
  Return(%para210_Φsuccess)
      : (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(38)/    return success/
}

subgraph attr:
Undeterminate : 0
subgraph @85__tensor_run_opt_ext.676(%para211_opt, %para212_momentum, %para213_learning_rate, %para214_gradient, %para215_weight, %para216_moment, %para217_ps_parameter, %para218_cache_enable, %para219_u) {
  %0([CNode]606) = Switch(false, DeadNode, @86_✗_tensor_run_opt_ext.678)
      : (<Bool>, <unknown>, <Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  %1([CNode]608) = %0[86_✗_tensor_run_opt_ext.678](%para219_u)
      : (<UMonad>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  Return(%1)
      : (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
}

subgraph attr:
Undeterminate : 0
subgraph @86_✗_tensor_run_opt_ext.678(%para220_u) {
  %0([CNode]602) = ApplyMomentum($(@85__tensor_run_opt_ext.676:para215_weight), $(@85__tensor_run_opt_ext.676:para216_moment), $(@85__tensor_run_opt_ext.676:para213_learning_rate), $(@85__tensor_run_opt_ext.676:para214_gradient), $(@85__tensor_run_opt_ext.676:para212_momentum), %para220_u) {instance name: opt} primitive_attrs: {output_names: [output], side_effect_mem: true, use_nesterov: false, input_names: [variable, accumulation, learning_rate, gradient, momentum], use_locking: false, gradient_scale: 1.000000}
      : (<Ref[Tensor(F32)], (84, 120)>, <Ref[Tensor(F32)], (84, 120)>, <Ref[Tensor(F32)], ()>, <Tensor[Float32], (84, 120)>, <Ref[Tensor(F32)], ()>, <UMonad>) -> (<Tensor[Float32], (84, 120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/
  %1(success) = Depend(true, %0) primitive_attrs: {side_effect_propagate: 1}
      : (<Bool>, <Tensor[Float32], (84, 120)>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/
  %2([CNode]604) = call @87_↓_tensor_run_opt_ext.677(%1)
      : (<Bool>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  %3([CNode]859) = UpdateState(%para220_u, %0)
      : (<UMonad>, <Tensor[Float32], (84, 120)>) -> (<UMonad>)
  %4([CNode]604) = Depend(%2, %3) primitive_attrs: {side_effect_propagate: 1}
      : (<Bool>, <UMonad>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  Return(%4)
      : (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
}

subgraph attr:
core : 1
Undeterminate : 0
subgraph @84_685.686(%para221_798, %para222_679, %para223_680, %para224_681, %para225_682, %para226_683, %para227_799, %para228_800, %para229_u) {
  %0([CNode]609) = call @85__tensor_run_opt_ext.676(PolyNode, %para222_679, %para223_680, %para224_681, %para225_682, %para226_683, false, false, %para229_u)
      : (<unknown>, <Ref[Tensor(F32)], ()>, <Ref[Tensor(F32)], ()>, <Tensor[Float32], (84, 120)>, <Ref[Tensor(F32)], (84, 120)>, <Ref[Tensor(F32)], (84, 120)>, <Bool>, <Bool>, <UMonad>) -> (<Bool>)
  Return(%0)
      : (<Bool>)
}

subgraph attr:
spec_param : 1
core : 1
Undeterminate : 0
subgraph @83_hyper_map.687(%para230_[Parameter]784, %para231_[Parameter]622, %para232_[Parameter]623, %para233_[Parameter]624, %para234_[Parameter]785, %para235_[Parameter]786, %para236_u) {
  %0([CNode]684) = Partial(@84_685.686, S-Prim-ApplyMomentum, $(@1_construct_wrapper.536:para19_momentum), $(@53_construct.621:lr)) primitive_attrs: {side_effect_propagate: 1}
      : (<Func>, <Func>, <Ref[Tensor(F32)], ()>, <Ref[Tensor(F32)], ()>) -> (<Func>)
  %1([CNode]609) = %0(%para231_[Parameter]622, %para232_[Parameter]623, %para233_[Parameter]624, false, false, %para236_u)
      : (<Tensor[Float32], (84, 120)>, <Ref[Tensor(F32)], (84, 120)>, <Ref[Tensor(F32)], (84, 120)>, <Bool>, <Bool>, <UMonad>) -> (<Bool>)
  Return(%1)
      : (<Bool>)
}

subgraph attr:
after_block : 1
Undeterminate : 0
subgraph @82_↓_tensor_run_opt_ext.665(%para237_Φsuccess) {
  Return(%para237_Φsuccess)
      : (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(38)/    return success/
}

subgraph attr:
Undeterminate : 0
subgraph @80__tensor_run_opt_ext.664(%para238_opt, %para239_momentum, %para240_learning_rate, %para241_gradient, %para242_weight, %para243_moment, %para244_ps_parameter, %para245_cache_enable, %para246_u) {
  %0([CNode]606) = Switch(false, DeadNode, @81_✗_tensor_run_opt_ext.666)
      : (<Bool>, <unknown>, <Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  %1([CNode]608) = %0[81_✗_tensor_run_opt_ext.666](%para246_u)
      : (<UMonad>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  Return(%1)
      : (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
}

subgraph attr:
Undeterminate : 0
subgraph @81_✗_tensor_run_opt_ext.666(%para247_u) {
  %0([CNode]602) = ApplyMomentum($(@80__tensor_run_opt_ext.664:para242_weight), $(@80__tensor_run_opt_ext.664:para243_moment), $(@80__tensor_run_opt_ext.664:para240_learning_rate), $(@80__tensor_run_opt_ext.664:para241_gradient), $(@80__tensor_run_opt_ext.664:para239_momentum), %para247_u) {instance name: opt} primitive_attrs: {output_names: [output], side_effect_mem: true, use_nesterov: false, input_names: [variable, accumulation, learning_rate, gradient, momentum], use_locking: false, gradient_scale: 1.000000}
      : (<Ref[Tensor(F32)], (120)>, <Ref[Tensor(F32)], (120)>, <Ref[Tensor(F32)], ()>, <Tensor[Float32], (120)>, <Ref[Tensor(F32)], ()>, <UMonad>) -> (<Tensor[Float32], (120)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/
  %1(success) = Depend(true, %0) primitive_attrs: {side_effect_propagate: 1}
      : (<Bool>, <Tensor[Float32], (120)>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/
  %2([CNode]604) = call @82_↓_tensor_run_opt_ext.665(%1)
      : (<Bool>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  %3([CNode]861) = UpdateState(%para247_u, %0)
      : (<UMonad>, <Tensor[Float32], (120)>) -> (<UMonad>)
  %4([CNode]604) = Depend(%2, %3) primitive_attrs: {side_effect_propagate: 1}
      : (<Bool>, <UMonad>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  Return(%4)
      : (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
}

subgraph attr:
core : 1
Undeterminate : 0
subgraph @79_673.674(%para248_795, %para249_667, %para250_668, %para251_669, %para252_670, %para253_671, %para254_796, %para255_797, %para256_u) {
  %0([CNode]609) = call @80__tensor_run_opt_ext.664(PolyNode, %para249_667, %para250_668, %para251_669, %para252_670, %para253_671, false, false, %para256_u)
      : (<unknown>, <Ref[Tensor(F32)], ()>, <Ref[Tensor(F32)], ()>, <Tensor[Float32], (120)>, <Ref[Tensor(F32)], (120)>, <Ref[Tensor(F32)], (120)>, <Bool>, <Bool>, <UMonad>) -> (<Bool>)
  Return(%0)
      : (<Bool>)
}

subgraph attr:
spec_param : 1
core : 1
Undeterminate : 0
subgraph @78_hyper_map.675(%para257_[Parameter]784, %para258_[Parameter]622, %para259_[Parameter]623, %para260_[Parameter]624, %para261_[Parameter]785, %para262_[Parameter]786, %para263_u) {
  %0([CNode]672) = Partial(@79_673.674, S-Prim-ApplyMomentum, $(@1_construct_wrapper.536:para19_momentum), $(@53_construct.621:lr)) primitive_attrs: {side_effect_propagate: 1}
      : (<Func>, <Func>, <Ref[Tensor(F32)], ()>, <Ref[Tensor(F32)], ()>) -> (<Func>)
  %1([CNode]609) = %0(%para258_[Parameter]622, %para259_[Parameter]623, %para260_[Parameter]624, false, false, %para263_u)
      : (<Tensor[Float32], (120)>, <Ref[Tensor(F32)], (120)>, <Ref[Tensor(F32)], (120)>, <Bool>, <Bool>, <UMonad>) -> (<Bool>)
  Return(%1)
      : (<Bool>)
}

subgraph attr:
after_block : 1
Undeterminate : 0
subgraph @77_↓_tensor_run_opt_ext.653(%para264_Φsuccess) {
  Return(%para264_Φsuccess)
      : (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(38)/    return success/
}

subgraph attr:
Undeterminate : 0
subgraph @75__tensor_run_opt_ext.652(%para265_opt, %para266_momentum, %para267_learning_rate, %para268_gradient, %para269_weight, %para270_moment, %para271_ps_parameter, %para272_cache_enable, %para273_u) {
  %0([CNode]606) = Switch(false, DeadNode, @76_✗_tensor_run_opt_ext.654)
      : (<Bool>, <unknown>, <Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  %1([CNode]608) = %0[76_✗_tensor_run_opt_ext.654](%para273_u)
      : (<UMonad>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  Return(%1)
      : (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
}

subgraph attr:
Undeterminate : 0
subgraph @76_✗_tensor_run_opt_ext.654(%para274_u) {
  %0([CNode]602) = ApplyMomentum($(@75__tensor_run_opt_ext.652:para269_weight), $(@75__tensor_run_opt_ext.652:para270_moment), $(@75__tensor_run_opt_ext.652:para267_learning_rate), $(@75__tensor_run_opt_ext.652:para268_gradient), $(@75__tensor_run_opt_ext.652:para266_momentum), %para274_u) {instance name: opt} primitive_attrs: {output_names: [output], side_effect_mem: true, use_nesterov: false, input_names: [variable, accumulation, learning_rate, gradient, momentum], use_locking: false, gradient_scale: 1.000000}
      : (<Ref[Tensor(F32)], (120, 400)>, <Ref[Tensor(F32)], (120, 400)>, <Ref[Tensor(F32)], ()>, <Tensor[Float32], (120, 400)>, <Ref[Tensor(F32)], ()>, <UMonad>) -> (<Tensor[Float32], (120, 400)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/
  %1(success) = Depend(true, %0) primitive_attrs: {side_effect_propagate: 1}
      : (<Bool>, <Tensor[Float32], (120, 400)>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/
  %2([CNode]604) = call @77_↓_tensor_run_opt_ext.653(%1)
      : (<Bool>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  %3([CNode]863) = UpdateState(%para274_u, %0)
      : (<UMonad>, <Tensor[Float32], (120, 400)>) -> (<UMonad>)
  %4([CNode]604) = Depend(%2, %3) primitive_attrs: {side_effect_propagate: 1}
      : (<Bool>, <UMonad>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  Return(%4)
      : (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
}

subgraph attr:
core : 1
Undeterminate : 0
subgraph @74_661.662(%para275_792, %para276_655, %para277_656, %para278_657, %para279_658, %para280_659, %para281_793, %para282_794, %para283_u) {
  %0([CNode]609) = call @75__tensor_run_opt_ext.652(PolyNode, %para276_655, %para277_656, %para278_657, %para279_658, %para280_659, false, false, %para283_u)
      : (<unknown>, <Ref[Tensor(F32)], ()>, <Ref[Tensor(F32)], ()>, <Tensor[Float32], (120, 400)>, <Ref[Tensor(F32)], (120, 400)>, <Ref[Tensor(F32)], (120, 400)>, <Bool>, <Bool>, <UMonad>) -> (<Bool>)
  Return(%0)
      : (<Bool>)
}

subgraph attr:
spec_param : 1
core : 1
Undeterminate : 0
subgraph @73_hyper_map.663(%para284_[Parameter]784, %para285_[Parameter]622, %para286_[Parameter]623, %para287_[Parameter]624, %para288_[Parameter]785, %para289_[Parameter]786, %para290_u) {
  %0([CNode]660) = Partial(@74_661.662, S-Prim-ApplyMomentum, $(@1_construct_wrapper.536:para19_momentum), $(@53_construct.621:lr)) primitive_attrs: {side_effect_propagate: 1}
      : (<Func>, <Func>, <Ref[Tensor(F32)], ()>, <Ref[Tensor(F32)], ()>) -> (<Func>)
  %1([CNode]609) = %0(%para285_[Parameter]622, %para286_[Parameter]623, %para287_[Parameter]624, false, false, %para290_u)
      : (<Tensor[Float32], (120, 400)>, <Ref[Tensor(F32)], (120, 400)>, <Ref[Tensor(F32)], (120, 400)>, <Bool>, <Bool>, <UMonad>) -> (<Bool>)
  Return(%1)
      : (<Bool>)
}

subgraph attr:
after_block : 1
Undeterminate : 0
subgraph @72_↓_tensor_run_opt_ext.641(%para291_Φsuccess) {
  Return(%para291_Φsuccess)
      : (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(38)/    return success/
}

subgraph attr:
Undeterminate : 0
subgraph @70__tensor_run_opt_ext.640(%para292_opt, %para293_momentum, %para294_learning_rate, %para295_gradient, %para296_weight, %para297_moment, %para298_ps_parameter, %para299_cache_enable, %para300_u) {
  %0([CNode]606) = Switch(false, DeadNode, @71_✗_tensor_run_opt_ext.642)
      : (<Bool>, <unknown>, <Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  %1([CNode]608) = %0[71_✗_tensor_run_opt_ext.642](%para300_u)
      : (<UMonad>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  Return(%1)
      : (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
}

subgraph attr:
Undeterminate : 0
subgraph @71_✗_tensor_run_opt_ext.642(%para301_u) {
  %0([CNode]602) = ApplyMomentum($(@70__tensor_run_opt_ext.640:para296_weight), $(@70__tensor_run_opt_ext.640:para297_moment), $(@70__tensor_run_opt_ext.640:para294_learning_rate), $(@70__tensor_run_opt_ext.640:para295_gradient), $(@70__tensor_run_opt_ext.640:para293_momentum), %para301_u) {instance name: opt} primitive_attrs: {output_names: [output], side_effect_mem: true, use_nesterov: false, input_names: [variable, accumulation, learning_rate, gradient, momentum], use_locking: false, gradient_scale: 1.000000}
      : (<Ref[Tensor(F32)], (16, 6, 5, 5)>, <Ref[Tensor(F32)], (16, 6, 5, 5)>, <Ref[Tensor(F32)], ()>, <Tensor[Float32], (16, 6, 5, 5)>, <Ref[Tensor(F32)], ()>, <UMonad>) -> (<Tensor[Float32], (16, 6, 5, 5)>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/
  %1(success) = Depend(true, %0) primitive_attrs: {side_effect_propagate: 1}
      : (<Bool>, <Tensor[Float32], (16, 6, 5, 5)>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/
  %2([CNode]604) = call @72_↓_tensor_run_opt_ext.641(%1)
      : (<Bool>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  %3([CNode]865) = UpdateState(%para301_u, %0)
      : (<UMonad>, <Tensor[Float32], (16, 6, 5, 5)>) -> (<UMonad>)
  %4([CNode]604) = Depend(%2, %3) primitive_attrs: {side_effect_propagate: 1}
      : (<Bool>, <UMonad>) -> (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
  Return(%4)
      : (<Bool>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
}

subgraph attr:
core : 1
Undeterminate : 0
subgraph @69_649.650(%para302_789, %para303_643, %para304_644, %para305_645, %para306_646, %para307_647, %para308_790, %para309_791, %para310_u) {
  %0([CNode]609) = call @70__tensor_run_opt_ext.640(PolyNode, %para303_643, %para304_644, %para305_645, %para306_646, %para307_647, false, false, %para310_u)
      : (<unknown>, <Ref[Tensor(F32)], ()>, <Ref[Tensor(F32)], ()>, <Tensor[Float32], (16, 6, 5, 5)>, <Ref[Tensor(F32)], (16, 6, 5, 5)>, <Ref[Tensor(F32)], (16, 6, 5, 5)>, <Bool>, <Bool>, <UMonad>) -> (<Bool>)
  Return(%0)
      : (<Bool>)
}

subgraph attr:
spec_param : 1
core : 1
Undeterminate : 0
subgraph @68_hyper_map.651(%para311_[Parameter]784, %para312_[Parameter]622, %para313_[Parameter]623, %para314_[Parameter]624, %para315_[Parameter]785, %para316_[Parameter]786, %para317_u) {
  %0([CNode]648) = Partial(@69_649.650, S-Prim-ApplyMomentum, $(@1_construct_wrapper.536:para19_momentum), $(@53_construct.621:lr)) primitive_attrs: {side_effect_propagate: 1}
      : (<Func>, <Func>, <Ref[Tensor(F32)], ()>, <Ref[Tensor(F32)], ()>) -> (<Func>)
  %1([CNode]609) = %0(%para312_[Parameter]622, %para313_[Parameter]623, %para314_[Parameter]624, false, false, %para317_u)
      : (<Tensor[Float32], (16, 6, 5, 5)>, <Ref[Tensor(F32)], (16, 6, 5, 5)>, <Ref[Tensor(F32)], (16, 6, 5, 5)>, <Bool>, <Bool>, <UMonad>) -> (<Bool>)
  Return(%1)
      : (<Bool>)
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @54_✗construct.734(%para318_u) {
  %0([CNode]388) = Partial(PolyNode, PolyNode, $(@1_construct_wrapper.536:para19_momentum), $(@53_construct.621:lr)) primitive_attrs: {side_effect_propagate: 1}
      : (<unknown>, <unknown>, <Ref[Tensor(F32)], ()>, <Ref[Tensor(F32)], ()>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %1(success) = call @62_hyper_map.601(%0, $(@53_construct.621:gradients), $(@53_construct.621:[CNode]383), $(@53_construct.621:[CNode]384), (false, false, false, false, false, false, false, false), (false, false, false, false, false, false, false, false), %para318_u)
      : (<Func>, <Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={53_construct.621:[CNode]383{[0]: ValueNode<Primitive> MakeTuple, [1]: conv1.weight, [2]: conv2.weight, [3]: fc1.weight, [4]: fc1.bias, [5]: fc2.weight, [6]: fc2.bias, [7]: fc3.weight, [8]: fc3.bias}, elements_use_flags: {ptr: 0x159966d07d0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={53_construct.621:[CNode]384{[0]: ValueNode<Primitive> MakeTuple, [1]: moments.conv1.weight, [2]: moments.conv2.weight, [3]: moments.fc1.weight, [4]: moments.fc1.bias, [5]: moments.fc2.weight, [6]: moments.fc2.bias, [7]: moments.fc3.weight, [8]: moments.fc3.bias}, elements_use_flags: {ptr: 0x159966d02d0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Tuple[Bool*8], sequence_nodes={node={ValueNode<ValueTuple> (false, false, false, false, false, false, false, false), elements_use_flags: {ptr: 0x159966d0490, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Tuple[Bool*8], sequence_nodes={node={ValueNode<ValueTuple> (false, false, false, false, false, false, false, false), elements_use_flags: {ptr: 0x159966d0550, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <UMonad>) -> (<Tuple[Bool*8], sequence_nodes={node={62_hyper_map.601:success{[0]: ValueNode<Primitive> MakeTuple, [1]: success, [2]: success, [3]: success, [4]: success, [5]: success, [6]: success, [7]: success, [8]: success}, elements_use_flags: {ptr: 0x15996845170, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
  %2([CNode]389) = call @61_↓construct.733(%1)
      : (<Tuple[Bool*8], sequence_nodes={node={62_hyper_map.601:success{[0]: ValueNode<Primitive> MakeTuple, [1]: success, [2]: success, [3]: success, [4]: success, [5]: success, [6]: success, [7]: success, [8]: success}, elements_use_flags: {ptr: 0x15996845170, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>) -> (<Tuple[Bool*8], sequence_nodes={node={62_hyper_map.601:success{[0]: ValueNode<Primitive> MakeTuple, [1]: success, [2]: success, [3]: success, [4]: success, [5]: success, [6]: success, [7]: success, [8]: success}, elements_use_flags: {ptr: 0x15996845170, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(177)/        if self.is_group_lr:/
  %3([CNode]868) = UpdateState(%para318_u, %1)
      : (<UMonad>, <Tuple[Bool*8], sequence_nodes={node={62_hyper_map.601:success{[0]: ValueNode<Primitive> MakeTuple, [1]: success, [2]: success, [3]: success, [4]: success, [5]: success, [6]: success, [7]: success, [8]: success}, elements_use_flags: {ptr: 0x15996845170, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>) -> (<UMonad>)
  %4([CNode]389) = Depend(%2, %3) primitive_attrs: {side_effect_propagate: 1}
      : (<Tuple[Bool*8], sequence_nodes={node={62_hyper_map.601:success{[0]: ValueNode<Primitive> MakeTuple, [1]: success, [2]: success, [3]: success, [4]: success, [5]: success, [6]: success, [7]: success, [8]: success}, elements_use_flags: {ptr: 0x15996845170, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <UMonad>) -> (<Tuple[Bool*8], sequence_nodes={node={62_hyper_map.601:success{[0]: ValueNode<Primitive> MakeTuple, [1]: success, [2]: success, [3]: success, [4]: success, [5]: success, [6]: success, [7]: success, [8]: success}, elements_use_flags: {ptr: 0x15996845170, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(177)/        if self.is_group_lr:/
  Return(%4)
      : (<Tuple[Bool*8], sequence_nodes={node={62_hyper_map.601:success{[0]: ValueNode<Primitive> MakeTuple, [1]: success, [2]: success, [3]: success, [4]: success, [5]: success, [6]: success, [7]: success, [8]: success}, elements_use_flags: {ptr: 0x15996845170, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(177)/        if self.is_group_lr:/
}

subgraph attr:
after_block : 1
Undeterminate : 0
training : 1
subgraph @57_↓scale_grad.724(%para319_Φgradients) {
  Return(%para319_Φgradients)
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(364)/        return gradients/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @55_scale_grad.725(%para320_gradients) {
  %0([CNode]349) = Switch(false, DeadNode, @56_✗scale_grad.726)
      : (<Bool>, <unknown>, <Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(361)/        if self.need_scale:/
  %1([CNode]352) = %0[56_✗scale_grad.726]()
      : () -> (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(361)/        if self.need_scale:/
  Return(%1)
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(361)/        if self.need_scale:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @56_✗scale_grad.726() {
  %0([CNode]348) = call @57_↓scale_grad.724($(@55_scale_grad.725:para320_gradients))
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>) -> (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(361)/        if self.need_scale:/
  Return(%0)
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(361)/        if self.need_scale:/
}

subgraph attr:
after_block : 1
Undeterminate : 0
training : 1
subgraph @105_↓gradients_centralization.727(%para321_Φgradients) {
  Return(%para321_Φgradients)
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(345)/        return gradients/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @103_gradients_centralization.728(%para322_gradients) {
  %0([CNode]359) = Switch(false, DeadNode, @104_✗gradients_centralization.729)
      : (<Bool>, <unknown>, <Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(342)/        if self.is_group:/
  %1([CNode]362) = %0[104_✗gradients_centralization.729]()
      : () -> (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(342)/        if self.is_group:/
  Return(%1)
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(342)/        if self.is_group:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @104_✗gradients_centralization.729() {
  %0([CNode]358) = call @105_↓gradients_centralization.727($(@103_gradients_centralization.728:para322_gradients))
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>) -> (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(342)/        if self.is_group:/
  Return(%0)
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(342)/        if self.is_group:/
}

subgraph attr:
after_block : 1
Undeterminate : 0
training : 1
subgraph @108_↓decay_weight.730(%para323_Φgradients) {
  Return(%para323_Φgradients)
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(326)/        return gradients/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @106_decay_weight.731(%para324_gradients) {
  %0([CNode]379) = Switch(false, DeadNode, @107_✗decay_weight.732)
      : (<Bool>, <unknown>, <Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(317)/        if self.exec_weight_decay:/
  %1([CNode]382) = %0[107_✗decay_weight.732]()
      : () -> (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(317)/        if self.exec_weight_decay:/
  Return(%1)
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(317)/        if self.exec_weight_decay:/
}

subgraph attr:
Undeterminate : 0
training : 1
subgraph @107_✗decay_weight.732() {
  %0([CNode]378) = call @108_↓decay_weight.730($(@106_decay_weight.731:para324_gradients))
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>) -> (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(317)/        if self.exec_weight_decay:/
  Return(%0)
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(317)/        if self.exec_weight_decay:/
}

subgraph attr:
core : 1
Undeterminate : 0
subgraph @109_UnpackCall.779(%para325_739, %para326_736, %para327_810, %para328_u) {
  %0(735) = TupleGetItem(%para326_736, 0)
      : (<Tuple[Tensor[Float32],Tensor[Int32]], sequence_nodes={node={3_construct.543:[CNode]546{[0]: ValueNode<Primitive> MakeTuple, [1]: inputs0, [2]: inputs1}, elements_use_flags: {ptr: 0x159961679b0, value: [const vector][1, 1]}}}>, <Int64>) -> (<Tensor[Float32], (32, 1, 32, 32)>)
  %1(737) = TupleGetItem(%para326_736, 1)
      : (<Tuple[Tensor[Float32],Tensor[Int32]], sequence_nodes={node={3_construct.543:[CNode]546{[0]: ValueNode<Primitive> MakeTuple, [1]: inputs0, [2]: inputs1}, elements_use_flags: {ptr: 0x159961679b0, value: [const vector][1, 1]}}}>, <Int64>) -> (<Tensor[Int32], (32)>)
  %2(738) = 739[111_construct.740](%0, %1, Tensor(shape=[], dtype=Float32, value=1), %para328_u)
      : (<Tensor[Float32], (32, 1, 32, 32)>, <Tensor[Int32], (32)>, <Tensor[Float32], (), value=...>, <UMonad>) -> (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
  Return(%2)
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
}

subgraph attr:
Undeterminate : 0
subgraph @114__tensor_env_get.744(%para329_env, %para330_parameter, %para331_u) {
  %0([CNode]741) = RefToEmbed(%para330_parameter)
      : (<Ref[Tensor(F32)], (6, 1, 5, 5)>) -> (<Object:kObjectTypeSymbolicKeyType>)
  %1([CNode]869) = Load(%para330_parameter, %para331_u)
      : (<Ref[Tensor(F32)], (6, 1, 5, 5)>, <UMonad>) -> (<Tensor[Float32], (6, 1, 5, 5)>)
  %2([CNode]741) = ZerosLike(%1) primitive_attrs: {output_names: [y], input_names: [x]}
      : (<Tensor[Float32], (6, 1, 5, 5)>) -> (<Tensor[Float32], (6, 1, 5, 5)>)
  %3([CNode]741) = EnvironGet(%para329_env, %0, %2)
      : (<Object:kObjectTypeEnvType>, <Object:kObjectTypeSymbolicKeyType>, <Tensor[Float32], (6, 1, 5, 5)>) -> (<Tensor[Float32], (6, 1, 5, 5)>)
  %4([CNode]870) = UpdateState(%para331_u, %1)
      : (<UMonad>, <Tensor[Float32], (6, 1, 5, 5)>) -> (<UMonad>)
  %5([CNode]741) = Depend(%3, %4) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], (6, 1, 5, 5)>, <UMonad>) -> (<Tensor[Float32], (6, 1, 5, 5)>)
  Return(%5)
      : (<Tensor[Float32], (6, 1, 5, 5)>)
}

subgraph attr:
core : 1
Undeterminate : 0
subgraph @110_construct.742(%para332_[Parameter]811, %para333_778) {
  %0(grads) = J(@5_construct.550) primitive_attrs: {side_effect_propagate: 1}
      : (<Func>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/
  Return(@111_construct.740)
      : (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/
}

subgraph attr:
k_graph : 1
core : 1
Undeterminate : 0
subgraph @111_construct.740(%para334_construct, %para335_construct, %para336_construct, %para337_u) {
  %0(grads) = $(@110_construct.742:grads)(%para334_construct, %para335_construct, %para337_u)
      : (<Tensor[Float32], (32, 1, 32, 32)>, <Tensor[Int32], (32)>, <UMonad>) -> (<Tuple[Tensor[Float32],Func]>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/
  %1(grads) = TupleGetItem(%0, 1)
      : (<Tuple[Tensor[Float32],Func]>, <Int64>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/
  %2(grads) = %1(Tensor(shape=[], dtype=Float32, value=1))
      : (<Tensor[Float32], (), value=...>) -> (<Tuple[Object:kObjectTypeEnvType,Tensor[Float32],Tensor[Int32]]>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/
  %3(grads) = TupleGetItem(%2, 0)
      : (<Tuple[Object:kObjectTypeEnvType,Tensor[Float32],Tensor[Int32]]>, <Int64>) -> (<Object:kObjectTypeEnvType>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/
  %4(grads) = Partial(PolyNode, %3) primitive_attrs: {side_effect_propagate: 1}
      : (<unknown>, <Object:kObjectTypeEnvType>) -> (<Func>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/
  %5([CNode]893) = UpdateState(%para337_u, %0)
      : (<UMonad>, <Tuple[Tensor[Float32],Func]>) -> (<UMonad>)
  %6(grads) = call @112_hyper_map.626(%4, $(@110_construct.742:para333_778), %5)
      : (<Func>, <Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={3_construct.543:[CNode]394{[0]: ValueNode<Primitive> MakeTuple, [1]: conv1.weight, [2]: conv2.weight, [3]: fc1.weight, [4]: fc1.bias, [5]: fc2.weight, [6]: fc2.bias, [7]: fc3.weight, [8]: fc3.bias}, elements_use_flags: {ptr: 0x15996645840, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <UMonad>) -> (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/
  %7([CNode]894) = UpdateState(%5, %6)
      : (<UMonad>, <Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>) -> (<UMonad>)
  %8(grads) = Depend(%6, %7) primitive_attrs: {side_effect_propagate: 1}
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <UMonad>) -> (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/
  Return(%8)
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/
}

subgraph attr:
spec_param : 1
core : 1
Undeterminate : 0
subgraph @113_hyper_map.748(%para338_[Parameter]812, %para339_[Parameter]745, %para340_u) {
  %0([CNode]743) = Partial(@114__tensor_env_get.744, $(@111_construct.740:grads)) primitive_attrs: {side_effect_propagate: 1}
      : (<Func>, <Object:kObjectTypeEnvType>) -> (<Func>)
  %1([CNode]741) = %0(%para339_[Parameter]745, %para340_u)
      : (<Ref[Tensor(F32)], (6, 1, 5, 5)>, <UMonad>) -> (<Tensor[Float32], (6, 1, 5, 5)>)
  Return(%1)
      : (<Tensor[Float32], (6, 1, 5, 5)>)
}

subgraph attr:
spec_param : 1
core : 1
Undeterminate : 0
subgraph @112_hyper_map.626(%para341_[Parameter]749, %para342_[Parameter]747, %para343_u) {
  %0([CNode]746) = TupleGetItem(%para342_[Parameter]747, 0)
      : (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={3_construct.543:[CNode]394{[0]: ValueNode<Primitive> MakeTuple, [1]: conv1.weight, [2]: conv2.weight, [3]: fc1.weight, [4]: fc1.bias, [5]: fc2.weight, [6]: fc2.bias, [7]: fc3.weight, [8]: fc3.bias}, elements_use_flags: {ptr: 0x15996645840, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Ref[Tensor(F32)], (6, 1, 5, 5)>)
  %1([CNode]628) = call @113_hyper_map.748(%para341_[Parameter]749, %0, %para343_u)
      : (<Func>, <Ref[Tensor(F32)], (6, 1, 5, 5)>, <UMonad>) -> (<Tensor[Float32], (6, 1, 5, 5)>)
  %2([CNode]752) = TupleGetItem(%para342_[Parameter]747, 1)
      : (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={3_construct.543:[CNode]394{[0]: ValueNode<Primitive> MakeTuple, [1]: conv1.weight, [2]: conv2.weight, [3]: fc1.weight, [4]: fc1.bias, [5]: fc2.weight, [6]: fc2.bias, [7]: fc3.weight, [8]: fc3.bias}, elements_use_flags: {ptr: 0x15996645840, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Ref[Tensor(F32)], (16, 6, 5, 5)>)
  %3([CNode]873) = UpdateState(%para343_u, %1)
      : (<UMonad>, <Tensor[Float32], (6, 1, 5, 5)>) -> (<UMonad>)
  %4([CNode]629) = call @115_hyper_map.753(%para341_[Parameter]749, %2, %3)
      : (<Func>, <Ref[Tensor(F32)], (16, 6, 5, 5)>, <UMonad>) -> (<Tensor[Float32], (16, 6, 5, 5)>)
  %5([CNode]756) = TupleGetItem(%para342_[Parameter]747, 2)
      : (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={3_construct.543:[CNode]394{[0]: ValueNode<Primitive> MakeTuple, [1]: conv1.weight, [2]: conv2.weight, [3]: fc1.weight, [4]: fc1.bias, [5]: fc2.weight, [6]: fc2.bias, [7]: fc3.weight, [8]: fc3.bias}, elements_use_flags: {ptr: 0x15996645840, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Ref[Tensor(F32)], (120, 400)>)
  %6([CNode]876) = UpdateState(%3, %4)
      : (<UMonad>, <Tensor[Float32], (16, 6, 5, 5)>) -> (<UMonad>)
  %7([CNode]630) = call @117_hyper_map.757(%para341_[Parameter]749, %5, %6)
      : (<Func>, <Ref[Tensor(F32)], (120, 400)>, <UMonad>) -> (<Tensor[Float32], (120, 400)>)
  %8([CNode]760) = TupleGetItem(%para342_[Parameter]747, 3)
      : (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={3_construct.543:[CNode]394{[0]: ValueNode<Primitive> MakeTuple, [1]: conv1.weight, [2]: conv2.weight, [3]: fc1.weight, [4]: fc1.bias, [5]: fc2.weight, [6]: fc2.bias, [7]: fc3.weight, [8]: fc3.bias}, elements_use_flags: {ptr: 0x15996645840, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Ref[Tensor(F32)], (120)>)
  %9([CNode]879) = UpdateState(%6, %7)
      : (<UMonad>, <Tensor[Float32], (120, 400)>) -> (<UMonad>)
  %10([CNode]631) = call @119_hyper_map.761(%para341_[Parameter]749, %8, %9)
      : (<Func>, <Ref[Tensor(F32)], (120)>, <UMonad>) -> (<Tensor[Float32], (120)>)
  %11([CNode]764) = TupleGetItem(%para342_[Parameter]747, 4)
      : (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={3_construct.543:[CNode]394{[0]: ValueNode<Primitive> MakeTuple, [1]: conv1.weight, [2]: conv2.weight, [3]: fc1.weight, [4]: fc1.bias, [5]: fc2.weight, [6]: fc2.bias, [7]: fc3.weight, [8]: fc3.bias}, elements_use_flags: {ptr: 0x15996645840, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Ref[Tensor(F32)], (84, 120)>)
  %12([CNode]882) = UpdateState(%9, %10)
      : (<UMonad>, <Tensor[Float32], (120)>) -> (<UMonad>)
  %13([CNode]632) = call @121_hyper_map.765(%para341_[Parameter]749, %11, %12)
      : (<Func>, <Ref[Tensor(F32)], (84, 120)>, <UMonad>) -> (<Tensor[Float32], (84, 120)>)
  %14([CNode]768) = TupleGetItem(%para342_[Parameter]747, 5)
      : (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={3_construct.543:[CNode]394{[0]: ValueNode<Primitive> MakeTuple, [1]: conv1.weight, [2]: conv2.weight, [3]: fc1.weight, [4]: fc1.bias, [5]: fc2.weight, [6]: fc2.bias, [7]: fc3.weight, [8]: fc3.bias}, elements_use_flags: {ptr: 0x15996645840, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Ref[Tensor(F32)], (84)>)
  %15([CNode]885) = UpdateState(%12, %13)
      : (<UMonad>, <Tensor[Float32], (84, 120)>) -> (<UMonad>)
  %16([CNode]633) = call @123_hyper_map.769(%para341_[Parameter]749, %14, %15)
      : (<Func>, <Ref[Tensor(F32)], (84)>, <UMonad>) -> (<Tensor[Float32], (84)>)
  %17([CNode]772) = TupleGetItem(%para342_[Parameter]747, 6)
      : (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={3_construct.543:[CNode]394{[0]: ValueNode<Primitive> MakeTuple, [1]: conv1.weight, [2]: conv2.weight, [3]: fc1.weight, [4]: fc1.bias, [5]: fc2.weight, [6]: fc2.bias, [7]: fc3.weight, [8]: fc3.bias}, elements_use_flags: {ptr: 0x15996645840, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Ref[Tensor(F32)], (10, 84)>)
  %18([CNode]888) = UpdateState(%15, %16)
      : (<UMonad>, <Tensor[Float32], (84)>) -> (<UMonad>)
  %19([CNode]634) = call @125_hyper_map.773(%para341_[Parameter]749, %17, %18)
      : (<Func>, <Ref[Tensor(F32)], (10, 84)>, <UMonad>) -> (<Tensor[Float32], (10, 84)>)
  %20([CNode]776) = TupleGetItem(%para342_[Parameter]747, 7)
      : (<Tuple[Ref[Tensor(F32)]*8], sequence_nodes={node={3_construct.543:[CNode]394{[0]: ValueNode<Primitive> MakeTuple, [1]: conv1.weight, [2]: conv2.weight, [3]: fc1.weight, [4]: fc1.bias, [5]: fc2.weight, [6]: fc2.bias, [7]: fc3.weight, [8]: fc3.bias}, elements_use_flags: {ptr: 0x15996645840, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Int64>) -> (<Ref[Tensor(F32)], (10)>)
  %21([CNode]891) = UpdateState(%18, %19)
      : (<UMonad>, <Tensor[Float32], (10, 84)>) -> (<UMonad>)
  %22([CNode]635) = call @127_hyper_map.777(%para341_[Parameter]749, %20, %21)
      : (<Func>, <Ref[Tensor(F32)], (10)>, <UMonad>) -> (<Tensor[Float32], (10)>)
  %23([CNode]627) = MakeTuple(%1, %4, %7, %10, %13, %16, %19, %22)
      : (<Tensor[Float32], (6, 1, 5, 5)>, <Tensor[Float32], (16, 6, 5, 5)>, <Tensor[Float32], (120, 400)>, <Tensor[Float32], (120)>, <Tensor[Float32], (84, 120)>, <Tensor[Float32], (84)>, <Tensor[Float32], (10, 84)>, <Tensor[Float32], (10)>) -> (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
  %24([CNode]892) = UpdateState(%21, %22)
      : (<UMonad>, <Tensor[Float32], (10)>) -> (<UMonad>)
  %25([CNode]627) = Depend(%23, %24) primitive_attrs: {side_effect_propagate: 1}
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <UMonad>) -> (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
  Return(%25)
      : (<Tuple[Tensor[Float32]*8], sequence_nodes={node={112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}, elements_use_flags: {ptr: 0x159966acff0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
}

subgraph attr:
Undeterminate : 0
subgraph @116__tensor_env_get.751(%para344_env, %para345_parameter, %para346_u) {
  %0([CNode]741) = RefToEmbed(%para345_parameter)
      : (<Ref[Tensor(F32)], (16, 6, 5, 5)>) -> (<Object:kObjectTypeSymbolicKeyType>)
  %1([CNode]871) = Load(%para345_parameter, %para346_u)
      : (<Ref[Tensor(F32)], (16, 6, 5, 5)>, <UMonad>) -> (<Tensor[Float32], (16, 6, 5, 5)>)
  %2([CNode]741) = ZerosLike(%1) primitive_attrs: {output_names: [y], input_names: [x]}
      : (<Tensor[Float32], (16, 6, 5, 5)>) -> (<Tensor[Float32], (16, 6, 5, 5)>)
  %3([CNode]741) = EnvironGet(%para344_env, %0, %2)
      : (<Object:kObjectTypeEnvType>, <Object:kObjectTypeSymbolicKeyType>, <Tensor[Float32], (16, 6, 5, 5)>) -> (<Tensor[Float32], (16, 6, 5, 5)>)
  %4([CNode]872) = UpdateState(%para346_u, %1)
      : (<UMonad>, <Tensor[Float32], (16, 6, 5, 5)>) -> (<UMonad>)
  %5([CNode]741) = Depend(%3, %4) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], (16, 6, 5, 5)>, <UMonad>) -> (<Tensor[Float32], (16, 6, 5, 5)>)
  Return(%5)
      : (<Tensor[Float32], (16, 6, 5, 5)>)
}

subgraph attr:
spec_param : 1
core : 1
Undeterminate : 0
subgraph @115_hyper_map.753(%para347_[Parameter]812, %para348_[Parameter]745, %para349_u) {
  %0([CNode]750) = Partial(@116__tensor_env_get.751, $(@111_construct.740:grads)) primitive_attrs: {side_effect_propagate: 1}
      : (<Func>, <Object:kObjectTypeEnvType>) -> (<Func>)
  %1([CNode]741) = %0(%para348_[Parameter]745, %para349_u)
      : (<Ref[Tensor(F32)], (16, 6, 5, 5)>, <UMonad>) -> (<Tensor[Float32], (16, 6, 5, 5)>)
  Return(%1)
      : (<Tensor[Float32], (16, 6, 5, 5)>)
}

subgraph attr:
Undeterminate : 0
subgraph @118__tensor_env_get.755(%para350_env, %para351_parameter, %para352_u) {
  %0([CNode]741) = RefToEmbed(%para351_parameter)
      : (<Ref[Tensor(F32)], (120, 400)>) -> (<Object:kObjectTypeSymbolicKeyType>)
  %1([CNode]874) = Load(%para351_parameter, %para352_u)
      : (<Ref[Tensor(F32)], (120, 400)>, <UMonad>) -> (<Tensor[Float32], (120, 400)>)
  %2([CNode]741) = ZerosLike(%1) primitive_attrs: {output_names: [y], input_names: [x]}
      : (<Tensor[Float32], (120, 400)>) -> (<Tensor[Float32], (120, 400)>)
  %3([CNode]741) = EnvironGet(%para350_env, %0, %2)
      : (<Object:kObjectTypeEnvType>, <Object:kObjectTypeSymbolicKeyType>, <Tensor[Float32], (120, 400)>) -> (<Tensor[Float32], (120, 400)>)
  %4([CNode]875) = UpdateState(%para352_u, %1)
      : (<UMonad>, <Tensor[Float32], (120, 400)>) -> (<UMonad>)
  %5([CNode]741) = Depend(%3, %4) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], (120, 400)>, <UMonad>) -> (<Tensor[Float32], (120, 400)>)
  Return(%5)
      : (<Tensor[Float32], (120, 400)>)
}

subgraph attr:
spec_param : 1
core : 1
Undeterminate : 0
subgraph @117_hyper_map.757(%para353_[Parameter]812, %para354_[Parameter]745, %para355_u) {
  %0([CNode]754) = Partial(@118__tensor_env_get.755, $(@111_construct.740:grads)) primitive_attrs: {side_effect_propagate: 1}
      : (<Func>, <Object:kObjectTypeEnvType>) -> (<Func>)
  %1([CNode]741) = %0(%para354_[Parameter]745, %para355_u)
      : (<Ref[Tensor(F32)], (120, 400)>, <UMonad>) -> (<Tensor[Float32], (120, 400)>)
  Return(%1)
      : (<Tensor[Float32], (120, 400)>)
}

subgraph attr:
Undeterminate : 0
subgraph @120__tensor_env_get.759(%para356_env, %para357_parameter, %para358_u) {
  %0([CNode]741) = RefToEmbed(%para357_parameter)
      : (<Ref[Tensor(F32)], (120)>) -> (<Object:kObjectTypeSymbolicKeyType>)
  %1([CNode]877) = Load(%para357_parameter, %para358_u)
      : (<Ref[Tensor(F32)], (120)>, <UMonad>) -> (<Tensor[Float32], (120)>)
  %2([CNode]741) = ZerosLike(%1) primitive_attrs: {output_names: [y], input_names: [x]}
      : (<Tensor[Float32], (120)>) -> (<Tensor[Float32], (120)>)
  %3([CNode]741) = EnvironGet(%para356_env, %0, %2)
      : (<Object:kObjectTypeEnvType>, <Object:kObjectTypeSymbolicKeyType>, <Tensor[Float32], (120)>) -> (<Tensor[Float32], (120)>)
  %4([CNode]878) = UpdateState(%para358_u, %1)
      : (<UMonad>, <Tensor[Float32], (120)>) -> (<UMonad>)
  %5([CNode]741) = Depend(%3, %4) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], (120)>, <UMonad>) -> (<Tensor[Float32], (120)>)
  Return(%5)
      : (<Tensor[Float32], (120)>)
}

subgraph attr:
spec_param : 1
core : 1
Undeterminate : 0
subgraph @119_hyper_map.761(%para359_[Parameter]812, %para360_[Parameter]745, %para361_u) {
  %0([CNode]758) = Partial(@120__tensor_env_get.759, $(@111_construct.740:grads)) primitive_attrs: {side_effect_propagate: 1}
      : (<Func>, <Object:kObjectTypeEnvType>) -> (<Func>)
  %1([CNode]741) = %0(%para360_[Parameter]745, %para361_u)
      : (<Ref[Tensor(F32)], (120)>, <UMonad>) -> (<Tensor[Float32], (120)>)
  Return(%1)
      : (<Tensor[Float32], (120)>)
}

subgraph attr:
Undeterminate : 0
subgraph @122__tensor_env_get.763(%para362_env, %para363_parameter, %para364_u) {
  %0([CNode]741) = RefToEmbed(%para363_parameter)
      : (<Ref[Tensor(F32)], (84, 120)>) -> (<Object:kObjectTypeSymbolicKeyType>)
  %1([CNode]880) = Load(%para363_parameter, %para364_u)
      : (<Ref[Tensor(F32)], (84, 120)>, <UMonad>) -> (<Tensor[Float32], (84, 120)>)
  %2([CNode]741) = ZerosLike(%1) primitive_attrs: {output_names: [y], input_names: [x]}
      : (<Tensor[Float32], (84, 120)>) -> (<Tensor[Float32], (84, 120)>)
  %3([CNode]741) = EnvironGet(%para362_env, %0, %2)
      : (<Object:kObjectTypeEnvType>, <Object:kObjectTypeSymbolicKeyType>, <Tensor[Float32], (84, 120)>) -> (<Tensor[Float32], (84, 120)>)
  %4([CNode]881) = UpdateState(%para364_u, %1)
      : (<UMonad>, <Tensor[Float32], (84, 120)>) -> (<UMonad>)
  %5([CNode]741) = Depend(%3, %4) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], (84, 120)>, <UMonad>) -> (<Tensor[Float32], (84, 120)>)
  Return(%5)
      : (<Tensor[Float32], (84, 120)>)
}

subgraph attr:
spec_param : 1
core : 1
Undeterminate : 0
subgraph @121_hyper_map.765(%para365_[Parameter]812, %para366_[Parameter]745, %para367_u) {
  %0([CNode]762) = Partial(@122__tensor_env_get.763, $(@111_construct.740:grads)) primitive_attrs: {side_effect_propagate: 1}
      : (<Func>, <Object:kObjectTypeEnvType>) -> (<Func>)
  %1([CNode]741) = %0(%para366_[Parameter]745, %para367_u)
      : (<Ref[Tensor(F32)], (84, 120)>, <UMonad>) -> (<Tensor[Float32], (84, 120)>)
  Return(%1)
      : (<Tensor[Float32], (84, 120)>)
}

subgraph attr:
Undeterminate : 0
subgraph @124__tensor_env_get.767(%para368_env, %para369_parameter, %para370_u) {
  %0([CNode]741) = RefToEmbed(%para369_parameter)
      : (<Ref[Tensor(F32)], (84)>) -> (<Object:kObjectTypeSymbolicKeyType>)
  %1([CNode]883) = Load(%para369_parameter, %para370_u)
      : (<Ref[Tensor(F32)], (84)>, <UMonad>) -> (<Tensor[Float32], (84)>)
  %2([CNode]741) = ZerosLike(%1) primitive_attrs: {output_names: [y], input_names: [x]}
      : (<Tensor[Float32], (84)>) -> (<Tensor[Float32], (84)>)
  %3([CNode]741) = EnvironGet(%para368_env, %0, %2)
      : (<Object:kObjectTypeEnvType>, <Object:kObjectTypeSymbolicKeyType>, <Tensor[Float32], (84)>) -> (<Tensor[Float32], (84)>)
  %4([CNode]884) = UpdateState(%para370_u, %1)
      : (<UMonad>, <Tensor[Float32], (84)>) -> (<UMonad>)
  %5([CNode]741) = Depend(%3, %4) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], (84)>, <UMonad>) -> (<Tensor[Float32], (84)>)
  Return(%5)
      : (<Tensor[Float32], (84)>)
}

subgraph attr:
spec_param : 1
core : 1
Undeterminate : 0
subgraph @123_hyper_map.769(%para371_[Parameter]812, %para372_[Parameter]745, %para373_u) {
  %0([CNode]766) = Partial(@124__tensor_env_get.767, $(@111_construct.740:grads)) primitive_attrs: {side_effect_propagate: 1}
      : (<Func>, <Object:kObjectTypeEnvType>) -> (<Func>)
  %1([CNode]741) = %0(%para372_[Parameter]745, %para373_u)
      : (<Ref[Tensor(F32)], (84)>, <UMonad>) -> (<Tensor[Float32], (84)>)
  Return(%1)
      : (<Tensor[Float32], (84)>)
}

subgraph attr:
Undeterminate : 0
subgraph @126__tensor_env_get.771(%para374_env, %para375_parameter, %para376_u) {
  %0([CNode]741) = RefToEmbed(%para375_parameter)
      : (<Ref[Tensor(F32)], (10, 84)>) -> (<Object:kObjectTypeSymbolicKeyType>)
  %1([CNode]886) = Load(%para375_parameter, %para376_u)
      : (<Ref[Tensor(F32)], (10, 84)>, <UMonad>) -> (<Tensor[Float32], (10, 84)>)
  %2([CNode]741) = ZerosLike(%1) primitive_attrs: {output_names: [y], input_names: [x]}
      : (<Tensor[Float32], (10, 84)>) -> (<Tensor[Float32], (10, 84)>)
  %3([CNode]741) = EnvironGet(%para374_env, %0, %2)
      : (<Object:kObjectTypeEnvType>, <Object:kObjectTypeSymbolicKeyType>, <Tensor[Float32], (10, 84)>) -> (<Tensor[Float32], (10, 84)>)
  %4([CNode]887) = UpdateState(%para376_u, %1)
      : (<UMonad>, <Tensor[Float32], (10, 84)>) -> (<UMonad>)
  %5([CNode]741) = Depend(%3, %4) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], (10, 84)>, <UMonad>) -> (<Tensor[Float32], (10, 84)>)
  Return(%5)
      : (<Tensor[Float32], (10, 84)>)
}

subgraph attr:
spec_param : 1
core : 1
Undeterminate : 0
subgraph @125_hyper_map.773(%para377_[Parameter]812, %para378_[Parameter]745, %para379_u) {
  %0([CNode]770) = Partial(@126__tensor_env_get.771, $(@111_construct.740:grads)) primitive_attrs: {side_effect_propagate: 1}
      : (<Func>, <Object:kObjectTypeEnvType>) -> (<Func>)
  %1([CNode]741) = %0(%para378_[Parameter]745, %para379_u)
      : (<Ref[Tensor(F32)], (10, 84)>, <UMonad>) -> (<Tensor[Float32], (10, 84)>)
  Return(%1)
      : (<Tensor[Float32], (10, 84)>)
}

subgraph attr:
Undeterminate : 0
subgraph @128__tensor_env_get.775(%para380_env, %para381_parameter, %para382_u) {
  %0([CNode]741) = RefToEmbed(%para381_parameter)
      : (<Ref[Tensor(F32)], (10)>) -> (<Object:kObjectTypeSymbolicKeyType>)
  %1([CNode]889) = Load(%para381_parameter, %para382_u)
      : (<Ref[Tensor(F32)], (10)>, <UMonad>) -> (<Tensor[Float32], (10)>)
  %2([CNode]741) = ZerosLike(%1) primitive_attrs: {output_names: [y], input_names: [x]}
      : (<Tensor[Float32], (10)>) -> (<Tensor[Float32], (10)>)
  %3([CNode]741) = EnvironGet(%para380_env, %0, %2)
      : (<Object:kObjectTypeEnvType>, <Object:kObjectTypeSymbolicKeyType>, <Tensor[Float32], (10)>) -> (<Tensor[Float32], (10)>)
  %4([CNode]890) = UpdateState(%para382_u, %1)
      : (<UMonad>, <Tensor[Float32], (10)>) -> (<UMonad>)
  %5([CNode]741) = Depend(%3, %4) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], (10)>, <UMonad>) -> (<Tensor[Float32], (10)>)
  Return(%5)
      : (<Tensor[Float32], (10)>)
}

subgraph attr:
spec_param : 1
core : 1
Undeterminate : 0
subgraph @127_hyper_map.777(%para383_[Parameter]812, %para384_[Parameter]745, %para385_u) {
  %0([CNode]774) = Partial(@128__tensor_env_get.775, $(@111_construct.740:grads)) primitive_attrs: {side_effect_propagate: 1}
      : (<Func>, <Object:kObjectTypeEnvType>) -> (<Func>)
  %1([CNode]741) = %0(%para384_[Parameter]745, %para385_u)
      : (<Ref[Tensor(F32)], (10)>, <UMonad>) -> (<Tensor[Float32], (10)>)
  Return(%1)
      : (<Tensor[Float32], (10)>)
}

