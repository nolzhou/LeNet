# [No.1] 1_construct_wrapper.536
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(360)/    def construct(self, *inputs):/
funcgraph fg_536(
        %para1 : Tensor(F32)[32, 1, 32, 32]    # inputs0
        , %para2 : Tensor(I32)[32]    # inputs1
        , %para3 : Ref[Tensor(F32)][6, 1, 5, 5]    # conv1.weight
        , %para4 : Ref[Tensor(F32)][16, 6, 5, 5]    # conv2.weight
        , %para5 : Ref[Tensor(F32)][120, 400]    # fc1.weight
        , %para6 : Ref[Tensor(F32)][120]    # fc1.bias
        , %para7 : Ref[Tensor(F32)][84, 120]    # fc2.weight
        , %para8 : Ref[Tensor(F32)][84]    # fc2.bias
        , %para9 : Ref[Tensor(F32)][10, 84]    # fc3.weight
        , %para10 : Ref[Tensor(F32)][10]    # fc3.bias
        , %para11 : Ref[Tensor(F32)][6, 1, 5, 5]    # moments.conv1.weight
        , %para12 : Ref[Tensor(F32)][16, 6, 5, 5]    # moments.conv2.weight
        , %para13 : Ref[Tensor(F32)][120, 400]    # moments.fc1.weight
        , %para14 : Ref[Tensor(F32)][120]    # moments.fc1.bias
        , %para15 : Ref[Tensor(F32)][84, 120]    # moments.fc2.weight
        , %para16 : Ref[Tensor(F32)][84]    # moments.fc2.bias
        , %para17 : Ref[Tensor(F32)][10, 84]    # moments.fc3.weight
        , %para18 : Ref[Tensor(F32)][10]    # moments.fc3.bias
        , %para19 : Ref[Tensor(F32)][]    # momentum
        , %para20 : Ref[Tensor(F32)][]    # learning_rate
    ) {
    %1 : Tuple[Tensor(F32),Tensor(I32)] = Primitive::MakeTuple{prim_type=1}(%para1, %para2)    #(Tensor(F32)[32, 1, 32, 32], Tensor(I32)[32]) #scope: Default
#[CNode]539
    %2 : Tensor(F32)[] = FuncGraph::fg_780(FuncGraph::fg_543, %1)    #(Func, Tuple[Tensor(F32),Tensor(I32)])    # fg_780=2_UnpackCall.780, fg_543=3_construct.543 #scope: Default
#[CNode]20
    Primitive::Return{prim_type=1}(%2)    #(Tensor(F32)[]) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(366)/        return loss/#[CNode]23
}
# order:
#   1: 1_construct_wrapper.536:[CNode]20{[0]: ValueNode<FuncGraph> 2_UnpackCall.780, [1]: ValueNode<FuncGraph> 3_construct.543, [2]: [CNode]539}
#   2: 1_construct_wrapper.536:[CNode]23{[0]: ValueNode<Primitive> Return, [1]: [CNode]20}


# [No.2] 2_UnpackCall.780

funcgraph fg_780(
        %para21 : Func    # 542
        , %para22 : Tuple[Tensor(F32),Tensor(I32)]    # 538
    ) {
    %1 : Tensor(F32)[32, 1, 32, 32] = Primitive::TupleGetItem{prim_type=1}(%para22, I64(0))    #(Tuple[Tensor(F32),Tensor(I32)], I64) #scope: Default
#537
    %2 : Tensor(I32)[32] = Primitive::TupleGetItem{prim_type=1}(%para22, I64(1))    #(Tuple[Tensor(F32),Tensor(I32)], I64) #scope: Default
#540
    %3 : Tensor(F32)[] = %para21[3_construct.543](%1, %2)    #(Tensor(F32)[32, 1, 32, 32], Tensor(I32)[32]) #scope: Default
#541
    Primitive::Return{prim_type=1}(%3)    #(Tensor(F32)[]) #scope: Default
#813
}
# order:
#   1: 2_UnpackCall.780:541{[0]: 542, [1]: 537, [2]: 540}
#   2: 2_UnpackCall.780:813{[0]: ValueNode<Primitive> Return, [1]: 541}


# [No.3] 3_construct.543
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(360)/    def construct(self, *inputs):/
funcgraph fg_543[fg_536](
        %para23 : Tensor(F32)[32, 1, 32, 32]    # inputs0
        , %para24 : Tensor(I32)[32]    # inputs1
    ) {
    %1 : Tuple[Tensor(F32),Tensor(I32)] = Primitive::MakeTuple{prim_type=1}(%para23, %para24)    #(Tensor(F32)[32, 1, 32, 32], Tensor(I32)[32]) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(360)/    def construct(self, *inputs):/#[CNode]546
    %2 : Tensor(F32)[] = FuncGraph::fg_600(FuncGraph::fg_550, %1)    #(Func, Tuple[Tensor(F32),Tensor(I32)])    # fg_600=4_UnpackCall.600, fg_550=5_construct.550 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(361)/        loss = self.network(*inputs)/#loss
    %3 : Tuple[Ref[Tensor(F32)]*8] = Primitive::MakeTuple{prim_type=1}(%para3, %para4, %para5, %para6, %para7, %para8, %para9, %para10)    #(Ref[Tensor(F32)][6, 1, 5, 5], Ref[Tensor(F32)][16, 6, 5, 5], Ref[Tensor(F32)][120, 400], Ref[Tensor(F32)][120], Ref[Tensor(F32)][84, 120], Ref[Tensor(F32)][84], Ref[Tensor(F32)][10, 84], Ref[Tensor(F32)][10]) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#[CNode]394
    %4 : Func = FuncGraph::fg_742(FuncGraph::fg_550, %3)    #(Func, Tuple[Ref[Tensor(F32)]*8])    # fg_742=110_construct.742, fg_550=5_construct.550 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %5 : Tuple[Tensor(F32)*8] = FuncGraph::fg_779(%4, %1, (Tensor(43)[]))    #(Func, Tuple[Tensor(F32),Tensor(I32)], Tuple[Tensor(F32)])    # fg_779=109_UnpackCall.779 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %6 : Tuple[Tensor(F32)*8] = PrimitivePy::identity{prim_type=1}[side_effect_propagate=I64(1)](%5)    #(Tuple[Tensor(F32)*8]) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(364)/        grads = self.grad_reducer(grads)/#grads
    %7 : Tuple[Bool*8] = FuncGraph::fg_621(%6)    #(Tuple[Tensor(F32)*8])    # fg_621=53_construct.621 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(365)/        loss = F.depend(loss, self.optimizer(grads))/#[CNode]19
    %8 : Tensor(F32)[] = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](%2, %7)    #(Tensor(F32)[], Tuple[Bool*8]) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(365)/        loss = F.depend(loss, self.optimizer(grads))/#loss
    Primitive::Return{prim_type=1}(%8)    #(Tensor(F32)[]) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(366)/        return loss/#[CNode]24
}
# order:
#   1: 3_construct.543:loss{[0]: ValueNode<FuncGraph> 4_UnpackCall.600, [1]: ValueNode<FuncGraph> 5_construct.550, [2]: [CNode]546}
#   2: 3_construct.543:grads{[0]: ValueNode<FuncGraph> 110_construct.742, [1]: ValueNode<FuncGraph> 5_construct.550, [2]: [CNode]394}
#   3: 3_construct.543:grads{[0]: ValueNode<FuncGraph> 109_UnpackCall.779, [1]: grads, [2]: [CNode]546, [3]: ValueNode<ValueTuple> (Tensor(shape=[], dtype=Float32, value=1))}
#   4: 3_construct.543:grads{[0]: ValueNode<PrimitivePy> identity, [1]: grads}
#   5: 3_construct.543:[CNode]19{[0]: ValueNode<FuncGraph> 53_construct.621, [1]: grads}
#   6: 3_construct.543:loss{[0]: ValueNode<PrimitivePy> Depend, [1]: loss, [2]: [CNode]19}
#   7: 3_construct.543:[CNode]24{[0]: ValueNode<Primitive> Return, [1]: loss}


# [No.4] 4_UnpackCall.600

funcgraph fg_600(
        %para25 : Func    # 549
        , %para26 : Tuple[Tensor(F32),Tensor(I32)]    # 545
    ) {
    %1 : Tensor(F32)[32, 1, 32, 32] = Primitive::TupleGetItem{prim_type=1}(%para26, I64(0))    #(Tuple[Tensor(F32),Tensor(I32)], I64) #scope: Default
#544
    %2 : Tensor(I32)[32] = Primitive::TupleGetItem{prim_type=1}(%para26, I64(1))    #(Tuple[Tensor(F32),Tensor(I32)], I64) #scope: Default
#547
    %3 : Tensor(F32)[] = %para25[5_construct.550](%1, %2)    #(Tensor(F32)[32, 1, 32, 32], Tensor(I32)[32]) #scope: Default
#548
    Primitive::Return{prim_type=1}(%3)    #(Tensor(F32)[]) #scope: Default
#814
}
# order:
#   1: 4_UnpackCall.600:548{[0]: 549, [1]: 544, [2]: 547}
#   2: 4_UnpackCall.600:814{[0]: ValueNode<Primitive> Return, [1]: 548}


# [No.5] 5_construct.550
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(109)/    def construct(self, data, label):/
funcgraph fg_550[fg_536](
        %para27 : Tensor(F32)[32, 1, 32, 32]    # data
        , %para28 : Tensor(I32)[32]    # label
    ) {
    %1 : Tensor(F32)[32, 10] = FuncGraph::fg_599(%para27)    #(Tensor(F32)[32, 1, 32, 32])    # fg_599=9_construct.599 #scope: Default/network-WithLossCell
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(110)/        out = self._backbone(data)/#out
    %2 : Tensor(F32)[] = FuncGraph::fg_551(%1, %para28)    #(Tensor(F32)[32, 10], Tensor(I32)[32])    # fg_551=6_construct.551 #scope: Default/network-WithLossCell
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(111)/        return self._loss_fn(out, label)/#[CNode]274
    Primitive::Return{prim_type=1}(%2)    #(Tensor(F32)[]) #scope: Default/network-WithLossCell
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(111)/        return self._loss_fn(out, label)/#[CNode]395
}
# order:
#   1: 5_construct.550:out{[0]: ValueNode<FuncGraph> 9_construct.599, [1]: data}
#   2: 5_construct.550:[CNode]274{[0]: ValueNode<FuncGraph> 6_construct.551, [1]: out, [2]: label}
#   3: 5_construct.550:[CNode]395{[0]: ValueNode<Primitive> Return, [1]: [CNode]274}


# [No.6] 110_construct.742
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(109)/    def construct(self, data, label):/
funcgraph fg_742[fg_536](
        %para29 : Func    # [Parameter]811
        , %para30 : Tuple[Ref[Tensor(F32)]*8]    # 778
    ) {
    Primitive::Return{prim_type=1}(FuncGraph::fg_740)    #(Func)    # fg_740=111_construct.740 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
}
# order:
#   1: 110_construct.742:grads{[0]: ValueNode<Primitive> J, [1]: ValueNode<FuncGraph> 5_construct.550}
#   2: 110_construct.742:grads{[0]: ValueNode<Primitive> Return, [1]: ValueNode<FuncGraph> 111_construct.740}


# [No.7] 109_UnpackCall.779

funcgraph fg_779(
        %para31 : Func    # 739
        , %para32 : Tuple[Tensor(F32),Tensor(I32)]    # 736
        , %para33 : Tuple[Tensor(F32)]    # 810
    ) {
    %1 : Tensor(F32)[32, 1, 32, 32] = Primitive::TupleGetItem{prim_type=1}(%para32, I64(0))    #(Tuple[Tensor(F32),Tensor(I32)], I64) #scope: Default
#735
    %2 : Tensor(I32)[32] = Primitive::TupleGetItem{prim_type=1}(%para32, I64(1))    #(Tuple[Tensor(F32),Tensor(I32)], I64) #scope: Default
#737
    %3 : Tuple[Tensor(F32)*8] = %para31[111_construct.740](%1, %2, Tensor(43)[])    #(Tensor(F32)[32, 1, 32, 32], Tensor(I32)[32], Tensor(F32)[](...)) #scope: Default
#738
    Primitive::Return{prim_type=1}(%3)    #(Tuple[Tensor(F32)*8]) #scope: Default
#815
}
# order:
#   1: 109_UnpackCall.779:738{[0]: 739, [1]: 735, [2]: 737, [3]: ValueNode<Tensor> Tensor(shape=[], dtype=Float32, value=1)}
#   2: 109_UnpackCall.779:815{[0]: ValueNode<Primitive> Return, [1]: 738}


# [No.8] 53_construct.621
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(170)/    def construct(self, gradients):/
funcgraph fg_621[fg_536](
        %para34 : Tuple[Tensor(F32)*8]    # gradients
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(0), "DeadNode", FuncGraph::fg_734)    #(Bool, ProblemType, Func)    # fg_734=54_✗construct.734 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(177)/        if self.is_group_lr:/#[CNode]390
    %2 : Tuple[Bool*8] = %1[54_✗construct.734]() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(177)/        if self.is_group_lr:/#[CNode]393
    Primitive::Return{prim_type=1}(%2)    #(Tuple[Bool*8]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(177)/        if self.is_group_lr:/#[CNode]396
}
# order:
#   1: 53_construct.621:gradients{[0]: ValueNode<FuncGraph> 106_decay_weight.731, [1]: gradients}
#   2: 53_construct.621:gradients{[0]: ValueNode<FuncGraph> 103_gradients_centralization.728, [1]: gradients}
#   3: 53_construct.621:gradients{[0]: ValueNode<FuncGraph> 55_scale_grad.725, [1]: gradients}
#   4: 53_construct.621:lr{[0]: ValueNode<FuncGraph> 58_get_lr.617}
#   5: 53_construct.621:[CNode]390{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> false, [2]: ValueNode<StringImm> DeadNode, [3]: ValueNode<FuncGraph> 54_✗construct.734}
#   6: 53_construct.621:[CNode]393{[0]: [CNode]390}
#   7: 53_construct.621:[CNode]396{[0]: ValueNode<Primitive> Return, [1]: [CNode]393}


# [No.9] 9_construct.599
# In file D:\PythonCode\LeNet\lenet.py(39)/    def construct(self, x):/
funcgraph fg_599[fg_536](
        %para35 : Tensor(F32)[32, 1, 32, 32]    # x
    ) {
    %1 : Tensor(F32)[32, 6, 28, 28] = FuncGraph::fg_587(%para35)    #(Tensor(F32)[32, 1, 32, 32])    # fg_587=50_construct.587 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(41)/        x = self.conv1(x)/#x
    %2 : Tensor(F32)[32, 6, 28, 28] = FuncGraph::fg_589(%1)    #(Tensor(F32)[32, 6, 28, 28])    # fg_589=49_construct.589 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(42)/        x = self.relu(x)/#x
    %3 : Tensor(F32)[32, 6, 14, 14] = FuncGraph::fg_590(%2)    #(Tensor(F32)[32, 6, 28, 28])    # fg_590=48_construct.590 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(43)/        x = self.max_pool2d(x)/#x
    %4 : Tensor(F32)[32, 16, 10, 10] = FuncGraph::fg_584(%3)    #(Tensor(F32)[32, 6, 14, 14])    # fg_584=45_construct.584 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(44)/        x = self.conv2(x)/#x
    %5 : Tensor(F32)[32, 16, 10, 10] = FuncGraph::fg_591(%4)    #(Tensor(F32)[32, 16, 10, 10])    # fg_591=44_construct.591 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(45)/        x = self.relu(x)/#x
    %6 : Tensor(F32)[32, 16, 5, 5] = FuncGraph::fg_592(%5)    #(Tensor(F32)[32, 16, 10, 10])    # fg_592=43_construct.592 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(46)/        x = self.max_pool2d(x)/#x
    %7 : Tensor(F32)[32, 400] = FuncGraph::fg_593(%6)    #(Tensor(F32)[32, 16, 5, 5])    # fg_593=42_construct.593 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(47)/        x = self.flatten(x)/#x
    %8 : Tensor(F32)[32, 120] = FuncGraph::fg_594(%7)    #(Tensor(F32)[32, 400])    # fg_594=32_construct.594 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(48)/        x = self.fc1(x)/#x
    %9 : Tensor(F32)[32, 120] = FuncGraph::fg_595(%8)    #(Tensor(F32)[32, 120])    # fg_595=31_construct.595 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(49)/        x = self.relu(x)/#x
    %10 : Tensor(F32)[32, 84] = FuncGraph::fg_596(%9)    #(Tensor(F32)[32, 120])    # fg_596=21_construct.596 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(50)/        x = self.fc2(x)/#x
    %11 : Tensor(F32)[32, 84] = FuncGraph::fg_597(%10)    #(Tensor(F32)[32, 84])    # fg_597=20_construct.597 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(51)/        x = self.relu(x)/#x
    %12 : Tensor(F32)[32, 10] = FuncGraph::fg_598(%11)    #(Tensor(F32)[32, 84])    # fg_598=10_construct.598 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(52)/        x = self.fc3(x)/#x
    Primitive::Return{prim_type=1}(%12)    #(Tensor(F32)[32, 10]) #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(53)/        return x/#[CNode]397
}
# order:
#   1: 9_construct.599:x{[0]: ValueNode<FuncGraph> 50_construct.587, [1]: x}
#   2: 9_construct.599:x{[0]: ValueNode<FuncGraph> 49_construct.589, [1]: x}
#   3: 9_construct.599:x{[0]: ValueNode<FuncGraph> 48_construct.590, [1]: x}
#   4: 9_construct.599:x{[0]: ValueNode<FuncGraph> 45_construct.584, [1]: x}
#   5: 9_construct.599:x{[0]: ValueNode<FuncGraph> 44_construct.591, [1]: x}
#   6: 9_construct.599:x{[0]: ValueNode<FuncGraph> 43_construct.592, [1]: x}
#   7: 9_construct.599:x{[0]: ValueNode<FuncGraph> 42_construct.593, [1]: x}
#   8: 9_construct.599:x{[0]: ValueNode<FuncGraph> 32_construct.594, [1]: x}
#   9: 9_construct.599:x{[0]: ValueNode<FuncGraph> 31_construct.595, [1]: x}
#  10: 9_construct.599:x{[0]: ValueNode<FuncGraph> 21_construct.596, [1]: x}
#  11: 9_construct.599:x{[0]: ValueNode<FuncGraph> 20_construct.597, [1]: x}
#  12: 9_construct.599:x{[0]: ValueNode<FuncGraph> 10_construct.598, [1]: x}
#  13: 9_construct.599:[CNode]397{[0]: ValueNode<Primitive> Return, [1]: x}


# [No.10] 6_construct.551
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(622)/    def construct(self, logits, labels):/
funcgraph fg_551(
        %para36 : Tensor(F32)[32, 10]    # Φlogits
        , %para37 : Tensor(I32)[32]    # labels
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(1), FuncGraph::fg_553, "DeadNode")    #(Bool, Func, ProblemType)    # fg_553=7_✓construct.553 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/#[CNode]91
    %2 : Tensor(F32)[] = %1[7_✓construct.553]() #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/#[CNode]94
    %3 : Tensor(F32)[] = Primitive::Depend{prim_type=1}[side_effect_propagate=I64(1)](%2, (None, None))    #(Tensor(F32)[], Tuple[NoneType*2]) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(111)/        return self._loss_fn(out, label)/#[CNode]95
    Primitive::Return{prim_type=1}(%3)    #(Tensor(F32)[]) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/#[CNode]398
}
# order:
#   1: 6_construct.551:[CNode]91{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> true, [2]: ValueNode<FuncGraph> 7_✓construct.553, [3]: ValueNode<StringImm> DeadNode}
#   2: 6_construct.551:[CNode]94{[0]: [CNode]91}
#   3: 6_construct.551:[CNode]398{[0]: ValueNode<Primitive> Return, [1]: [CNode]95}


# [No.11] 111_construct.740
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(109)/    def construct(self, data, label):/
funcgraph fg_740[fg_742](
        %para38 : Tensor(F32)[32, 1, 32, 32]    # construct
        , %para39 : Tensor(I32)[32]    # construct
        , %para40 : Tensor(F32)[](...)    # construct
    ) {
    %1 : $(110_construct.742):Func = Primitive::J{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_550)    #(Func)    # fg_550=5_construct.550 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %2 : Tuple[Tensor(F32),Func] = %1(%para38, %para39)    #(Tensor(F32)[32, 1, 32, 32], Tensor(I32)[32]) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %3 : Func = Primitive::TupleGetItem{prim_type=1}(%2, I64(1))    #(Tuple[Tensor(F32),Func], I64) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %4 : Tuple[EnvType,Tensor(F32),Tensor(I32)] = %3(Tensor(43)[])    #(Tensor(F32)[](...)) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %5 : EnvType = Primitive::TupleGetItem{prim_type=1}(%4, I64(0))    #(Tuple[EnvType,Tensor(F32),Tensor(I32)], I64) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %6 : Func = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)]("PolyNode", %5)    #(ProblemType, EnvType) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %7 : Tuple[Tensor(F32)*8] = FuncGraph::fg_626(%6, %para30)    #(Func, Tuple[Ref[Tensor(F32)]*8])    # fg_626=112_hyper_map.626 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    Primitive::Return{prim_type=1}(%7)    #(Tuple[Tensor(F32)*8]) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
}
# order:
#   1: 111_construct.740:grads{[0]: grads, [1]: construct, [2]: construct}
#   2: 111_construct.740:grads{[0]: ValueNode<Primitive> TupleGetItem, [1]: grads, [2]: ValueNode<Int64Imm> 1}
#   3: 111_construct.740:grads{[0]: grads, [1]: ValueNode<Tensor> Tensor(shape=[], dtype=Float32, value=1)}
#   4: 111_construct.740:grads{[0]: ValueNode<Primitive> TupleGetItem, [1]: grads, [2]: ValueNode<Int64Imm> 0}
#   5: 111_construct.740:grads{[0]: ValueNode<Primitive> Partial, [1]: ValueNode<StringImm> PolyNode, [2]: grads}
#   6: 111_construct.740:grads{[0]: ValueNode<FuncGraph> 112_hyper_map.626, [1]: grads, [2]: 778}
#   7: 111_construct.740:grads{[0]: ValueNode<Primitive> Return, [1]: grads}


# [No.12] 54_✗construct.734
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(177)/        if self.is_group_lr:/
funcgraph fg_734[fg_621](
) {
    %1 : $(53_construct.621):Ref[Tensor(F32)][] = FuncGraph::fg_617()    # fg_617=58_get_lr.617 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(176)/        lr = self.get_lr()/#lr
    %2 : Func = PrimitivePy::Partial{prim_type=1}[side_effect_propagate=I64(1)]("PolyNode", "PolyNode", %para19, %1)    #(ProblemType, ProblemType, Ref[Tensor(F32)][], Ref[Tensor(F32)][]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#[CNode]388
    %3 : $(53_construct.621):Tuple[Tensor(F32)*8] = FuncGraph::fg_731(%para34)    #(Tuple[Tensor(F32)*8])    # fg_731=106_decay_weight.731 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(173)/        gradients = self.decay_weight(gradients)/#gradients
    %4 : $(53_construct.621):Tuple[Tensor(F32)*8] = FuncGraph::fg_728(%3)    #(Tuple[Tensor(F32)*8])    # fg_728=103_gradients_centralization.728 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(174)/        gradients = self.gradients_centralization(gradients)/#gradients
    %5 : $(53_construct.621):Tuple[Tensor(F32)*8] = FuncGraph::fg_725(%4)    #(Tuple[Tensor(F32)*8])    # fg_725=55_scale_grad.725 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(175)/        gradients = self.scale_grad(gradients)/#gradients
    %6 : $(53_construct.621):Tuple[Ref[Tensor(F32)]*8] = Primitive::MakeTuple{prim_type=1}(%para3, %para4, %para5, %para6, %para7, %para8, %para9, %para10)    #(Ref[Tensor(F32)][6, 1, 5, 5], Ref[Tensor(F32)][16, 6, 5, 5], Ref[Tensor(F32)][120, 400], Ref[Tensor(F32)][120], Ref[Tensor(F32)][84, 120], Ref[Tensor(F32)][84], Ref[Tensor(F32)][10, 84], Ref[Tensor(F32)][10]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(171)/        params = self.params/#[CNode]383
    %7 : $(53_construct.621):Tuple[Ref[Tensor(F32)]*8] = Primitive::MakeTuple{prim_type=1}(%para11, %para12, %para13, %para14, %para15, %para16, %para17, %para18)    #(Ref[Tensor(F32)][6, 1, 5, 5], Ref[Tensor(F32)][16, 6, 5, 5], Ref[Tensor(F32)][120, 400], Ref[Tensor(F32)][120], Ref[Tensor(F32)][84, 120], Ref[Tensor(F32)][84], Ref[Tensor(F32)][10, 84], Ref[Tensor(F32)][10]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(172)/        moments = self.moments/#[CNode]384
    %8 : Tuple[Bool*8] = FuncGraph::fg_601(%2, %5, %6, %7, (Bool(0), Bool(0), Bool(0), Bool(0), Bool(0), Bool(0), Bool(0), Bool(0)), (Bool(0), Bool(0), Bool(0), Bool(0), Bool(0), Bool(0), Bool(0), Bool(0)))    #(Func, Tuple[Tensor(F32)*8], Tuple[Ref[Tensor(F32)]*8], Tuple[Ref[Tensor(F32)]*8], Tuple[Bool*8], Tuple[Bool*8])    # fg_601=62_hyper_map.601 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %9 : Tuple[Bool*8] = FuncGraph::fg_733(%8)    #(Tuple[Bool*8])    # fg_733=61_↓construct.733 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(177)/        if self.is_group_lr:/#[CNode]389
    Primitive::Return{prim_type=1}(%9)    #(Tuple[Bool*8]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(177)/        if self.is_group_lr:/#[CNode]401
}
# order:
#   1: 54_✗construct.734:[CNode]388{[0]: ValueNode<PrimitivePy> Partial, [1]: ValueNode<StringImm> PolyNode, [2]: ValueNode<StringImm> PolyNode, [3]: momentum, [4]: lr}
#   2: 54_✗construct.734:success{[0]: ValueNode<FuncGraph> 62_hyper_map.601, [1]: [CNode]388, [2]: gradients, [3]: [CNode]383, [4]: [CNode]384, [5]: ValueNode<ValueTuple> (false, false, false, false, false, false, false, false), [6]: ValueNode<ValueTuple> (false, false, false, false, false, false, false, false)}
#   3: 54_✗construct.734:[CNode]389{[0]: ValueNode<FuncGraph> 61_↓construct.733, [1]: success}
#   4: 54_✗construct.734:[CNode]401{[0]: ValueNode<Primitive> Return, [1]: [CNode]389}


# [No.13] 50_construct.587
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(265)/    def construct(self, x):/
funcgraph fg_587[fg_536](
        %para41 : Tensor(F32)[32, 1, 32, 32]    # x
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(0), "DeadNode", FuncGraph::fg_588)    #(Bool, ProblemType, Func)    # fg_588=51_✗construct.588 #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]266
    %2 : Tensor(F32)[32, 6, 28, 28] = %1[51_✗construct.588]() #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]269
    Primitive::Return{prim_type=1}(%2)    #(Tensor(F32)[32, 6, 28, 28]) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]402
}
# order:
#   1: 50_construct.587:output{[0]: ValueNode<PrimitivePy> Conv2D, [1]: x, [2]: conv1.weight}
#   2: 50_construct.587:[CNode]266{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> false, [2]: ValueNode<StringImm> DeadNode, [3]: ValueNode<FuncGraph> 51_✗construct.588}
#   3: 50_construct.587:[CNode]269{[0]: [CNode]266}
#   4: 50_construct.587:[CNode]402{[0]: ValueNode<Primitive> Return, [1]: [CNode]269}


# [No.14] 49_construct.589
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(294)/    def construct(self, x):/
funcgraph fg_589(
        %para42 : Tensor(F32)[32, 6, 28, 28]    # x
    ) {
    %1 : Tensor(F32)[32, 6, 28, 28] = PrimitivePy::ReLU{prim_type=1}[output_names=["output"], input_names=["x"]](%para42)    #(Tensor(F32)[32, 6, 28, 28]) #scope: Default/network-WithLossCell/_backbone-LeNet5/relu-ReLU
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(295)/        return self.relu(x)/#[CNode]148
    Primitive::Return{prim_type=1}(%1)    #(Tensor(F32)[32, 6, 28, 28]) #scope: Default/network-WithLossCell/_backbone-LeNet5/relu-ReLU
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(295)/        return self.relu(x)/#[CNode]403
}
# order:
#   1: 49_construct.589:[CNode]148{[0]: ValueNode<PrimitivePy> ReLU, [1]: x}
#   2: 49_construct.589:[CNode]403{[0]: ValueNode<Primitive> Return, [1]: [CNode]148}


# [No.15] 48_construct.590
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\pooling.py(141)/    def construct(self, x):/
funcgraph fg_590(
        %para43 : Tensor(F32)[32, 6, 28, 28]    # x
    ) {
    %1 : Tensor(F32)[32, 6, 14, 14] = PrimitivePy::MaxPool{prim_type=2}[pad_mode=I64(2), output_names=["output"], kernel_size=(I64(1), I64(1), I64(2), I64(2)), format="NCHW", strides=(I64(1), I64(1), I64(2), I64(2)), input_names=["x"]](%para43)    #(Tensor(F32)[32, 6, 28, 28]) #scope: Default/network-WithLossCell/_backbone-LeNet5/max_pool2d-MaxPool2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\pooling.py(142)/        out = self.max_pool(x)/#out
    Primitive::Return{prim_type=1}(%1)    #(Tensor(F32)[32, 6, 14, 14]) #scope: Default/network-WithLossCell/_backbone-LeNet5/max_pool2d-MaxPool2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\pooling.py(143)/        return out/#[CNode]404
}
# order:
#   1: 48_construct.590:out{[0]: ValueNode<PrimitivePy> MaxPool, [1]: x}
#   2: 48_construct.590:[CNode]404{[0]: ValueNode<Primitive> Return, [1]: out}


# [No.16] 45_construct.584
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(265)/    def construct(self, x):/
funcgraph fg_584[fg_536](
        %para44 : Tensor(F32)[32, 6, 14, 14]    # x
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(0), "DeadNode", FuncGraph::fg_585)    #(Bool, ProblemType, Func)    # fg_585=46_✗construct.585 #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]257
    %2 : Tensor(F32)[32, 16, 10, 10] = %1[46_✗construct.585]() #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]260
    Primitive::Return{prim_type=1}(%2)    #(Tensor(F32)[32, 16, 10, 10]) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]405
}
# order:
#   1: 45_construct.584:output{[0]: ValueNode<PrimitivePy> Conv2D, [1]: x, [2]: conv2.weight}
#   2: 45_construct.584:[CNode]257{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> false, [2]: ValueNode<StringImm> DeadNode, [3]: ValueNode<FuncGraph> 46_✗construct.585}
#   3: 45_construct.584:[CNode]260{[0]: [CNode]257}
#   4: 45_construct.584:[CNode]405{[0]: ValueNode<Primitive> Return, [1]: [CNode]260}


# [No.17] 44_construct.591
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(294)/    def construct(self, x):/
funcgraph fg_591(
        %para45 : Tensor(F32)[32, 16, 10, 10]    # x
    ) {
    %1 : Tensor(F32)[32, 16, 10, 10] = PrimitivePy::ReLU{prim_type=1}[output_names=["output"], input_names=["x"]](%para45)    #(Tensor(F32)[32, 16, 10, 10]) #scope: Default/network-WithLossCell/_backbone-LeNet5/relu-ReLU
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(295)/        return self.relu(x)/#[CNode]148
    Primitive::Return{prim_type=1}(%1)    #(Tensor(F32)[32, 16, 10, 10]) #scope: Default/network-WithLossCell/_backbone-LeNet5/relu-ReLU
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(295)/        return self.relu(x)/#[CNode]403
}
# order:
#   1: 44_construct.591:[CNode]148{[0]: ValueNode<PrimitivePy> ReLU, [1]: x}
#   2: 44_construct.591:[CNode]403{[0]: ValueNode<Primitive> Return, [1]: [CNode]148}


# [No.18] 43_construct.592
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\pooling.py(141)/    def construct(self, x):/
funcgraph fg_592(
        %para46 : Tensor(F32)[32, 16, 10, 10]    # x
    ) {
    %1 : Tensor(F32)[32, 16, 5, 5] = PrimitivePy::MaxPool{prim_type=2}[pad_mode=I64(2), output_names=["output"], kernel_size=(I64(1), I64(1), I64(2), I64(2)), format="NCHW", strides=(I64(1), I64(1), I64(2), I64(2)), input_names=["x"]](%para46)    #(Tensor(F32)[32, 16, 10, 10]) #scope: Default/network-WithLossCell/_backbone-LeNet5/max_pool2d-MaxPool2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\pooling.py(142)/        out = self.max_pool(x)/#out
    Primitive::Return{prim_type=1}(%1)    #(Tensor(F32)[32, 16, 5, 5]) #scope: Default/network-WithLossCell/_backbone-LeNet5/max_pool2d-MaxPool2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\pooling.py(143)/        return out/#[CNode]404
}
# order:
#   1: 43_construct.592:out{[0]: ValueNode<PrimitivePy> MaxPool, [1]: x}
#   2: 43_construct.592:[CNode]404{[0]: ValueNode<Primitive> Return, [1]: out}


# [No.19] 42_construct.593
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(214)/    def construct(self, x):/
funcgraph fg_593(
        %para47 : Tensor(F32)[32, 16, 5, 5]    # x
    ) {
    %1 : Tensor(F32)[32, 400] = PrimitivePy::Reshape{prim_type=2}[output_names=["output"], input_names=["tensor", "shape"]](%para47, (I64(32), I64(-1)))    #(Tensor(F32)[32, 16, 5, 5], Tuple[I64*2]) #scope: Default/network-WithLossCell/_backbone-LeNet5/flatten-Flatten
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(215)/        return F.reshape(x, (F.shape(x)[0], -1))/#[CNode]251
    Primitive::Return{prim_type=1}(%1)    #(Tensor(F32)[32, 400]) #scope: Default/network-WithLossCell/_backbone-LeNet5/flatten-Flatten
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(215)/        return F.reshape(x, (F.shape(x)[0], -1))/#[CNode]406
}
# order:
#   1: 42_construct.593:[CNode]251{[0]: ValueNode<PrimitivePy> Reshape, [1]: x, [2]: ValueNode<ValueTuple> (32, -1)}
#   2: 42_construct.593:[CNode]406{[0]: ValueNode<Primitive> Return, [1]: [CNode]251}


# [No.20] 32_construct.594
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(319)/    def construct(self, x):/
funcgraph fg_594[fg_536](
        %para48 : Tensor(F32)[32, 400]    # x
    ) {
    %1 : Tensor(F32)[32, 120] = FuncGraph::fg_578(%para48, %para6, %para5)    #(Tensor(F32)[32, 400], Ref[Tensor(F32)][120], Ref[Tensor(F32)][120, 400])    # fg_578=33_L-construct.578 #scope: Default
#[CNode]523
    Primitive::Return{prim_type=1}(%1)    #(Tensor(F32)[32, 120]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc1-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]407
}
# order:
#   1: 32_construct.594:[CNode]523{[0]: ValueNode<FuncGraph> 33_L-construct.578, [1]: x, [2]: fc1.bias, [3]: fc1.weight}
#   2: 32_construct.594:[CNode]407{[0]: ValueNode<Primitive> Return, [1]: [CNode]523}


# [No.21] 31_construct.595
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(294)/    def construct(self, x):/
funcgraph fg_595(
        %para49 : Tensor(F32)[32, 120]    # x
    ) {
    %1 : Tensor(F32)[32, 120] = PrimitivePy::ReLU{prim_type=1}[output_names=["output"], input_names=["x"]](%para49)    #(Tensor(F32)[32, 120]) #scope: Default/network-WithLossCell/_backbone-LeNet5/relu-ReLU
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(295)/        return self.relu(x)/#[CNode]148
    Primitive::Return{prim_type=1}(%1)    #(Tensor(F32)[32, 120]) #scope: Default/network-WithLossCell/_backbone-LeNet5/relu-ReLU
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(295)/        return self.relu(x)/#[CNode]403
}
# order:
#   1: 31_construct.595:[CNode]148{[0]: ValueNode<PrimitivePy> ReLU, [1]: x}
#   2: 31_construct.595:[CNode]403{[0]: ValueNode<Primitive> Return, [1]: [CNode]148}


# [No.22] 21_construct.596
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(319)/    def construct(self, x):/
funcgraph fg_596[fg_536](
        %para50 : Tensor(F32)[32, 120]    # x
    ) {
    %1 : Tensor(F32)[32, 84] = FuncGraph::fg_569(%para50, %para8, %para7)    #(Tensor(F32)[32, 120], Ref[Tensor(F32)][84], Ref[Tensor(F32)][84, 120])    # fg_569=22_L-construct.569 #scope: Default
#[CNode]522
    Primitive::Return{prim_type=1}(%1)    #(Tensor(F32)[32, 84]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc2-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]408
}
# order:
#   1: 21_construct.596:[CNode]522{[0]: ValueNode<FuncGraph> 22_L-construct.569, [1]: x, [2]: fc2.bias, [3]: fc2.weight}
#   2: 21_construct.596:[CNode]408{[0]: ValueNode<Primitive> Return, [1]: [CNode]522}


# [No.23] 20_construct.597
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(294)/    def construct(self, x):/
funcgraph fg_597(
        %para51 : Tensor(F32)[32, 84]    # x
    ) {
    %1 : Tensor(F32)[32, 84] = PrimitivePy::ReLU{prim_type=1}[output_names=["output"], input_names=["x"]](%para51)    #(Tensor(F32)[32, 84]) #scope: Default/network-WithLossCell/_backbone-LeNet5/relu-ReLU
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(295)/        return self.relu(x)/#[CNode]148
    Primitive::Return{prim_type=1}(%1)    #(Tensor(F32)[32, 84]) #scope: Default/network-WithLossCell/_backbone-LeNet5/relu-ReLU
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(295)/        return self.relu(x)/#[CNode]403
}
# order:
#   1: 20_construct.597:[CNode]148{[0]: ValueNode<PrimitivePy> ReLU, [1]: x}
#   2: 20_construct.597:[CNode]403{[0]: ValueNode<Primitive> Return, [1]: [CNode]148}


# [No.24] 10_construct.598
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(319)/    def construct(self, x):/
funcgraph fg_598[fg_536](
        %para52 : Tensor(F32)[32, 84]    # x
    ) {
    %1 : Tensor(F32)[32, 10] = FuncGraph::fg_560(%para52, %para10, %para9)    #(Tensor(F32)[32, 84], Ref[Tensor(F32)][10], Ref[Tensor(F32)][10, 84])    # fg_560=11_L-construct.560 #scope: Default
#[CNode]521
    Primitive::Return{prim_type=1}(%1)    #(Tensor(F32)[32, 10]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]409
}
# order:
#   1: 10_construct.598:[CNode]521{[0]: ValueNode<FuncGraph> 11_L-construct.560, [1]: x, [2]: fc3.bias, [3]: fc3.weight}
#   2: 10_construct.598:[CNode]409{[0]: ValueNode<Primitive> Return, [1]: [CNode]521}


# [No.25] 7_✓construct.553
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/
funcgraph fg_553[fg_551](
) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(1), FuncGraph::fg_552, "DeadNode")    #(Bool, Func, ProblemType)    # fg_552=8_✓✓construct.552 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/#[CNode]86
    %2 : Tensor(F32)[] = %1[8_✓✓construct.552]() #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/#[CNode]89
    Primitive::Return{prim_type=1}(%2)    #(Tensor(F32)[]) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/#[CNode]410
}
# order:
#   1: 7_✓construct.553:[CNode]86{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> true, [2]: ValueNode<FuncGraph> 8_✓✓construct.552, [3]: ValueNode<StringImm> DeadNode}
#   2: 7_✓construct.553:[CNode]89{[0]: [CNode]86}
#   3: 7_✓construct.553:[CNode]410{[0]: ValueNode<Primitive> Return, [1]: [CNode]89}


# [No.26] 112_hyper_map.626

funcgraph fg_626[fg_740](
        %para53 : Func    # [Parameter]749
        , %para54 : Tuple[Ref[Tensor(F32)]*8]    # [Parameter]747
    ) {
    %1 : Ref[Tensor(F32)][6, 1, 5, 5] = Primitive::TupleGetItem{prim_type=1}(%para54, I64(0))    #(Tuple[Ref[Tensor(F32)]*8], I64) #scope: Default
#[CNode]746
    %2 : Tensor(F32)[6, 1, 5, 5] = FuncGraph::fg_748(%para53, %1)    #(Func, Ref[Tensor(F32)][6, 1, 5, 5])    # fg_748=113_hyper_map.748 #scope: Default
#[CNode]628
    %3 : Ref[Tensor(F32)][16, 6, 5, 5] = Primitive::TupleGetItem{prim_type=1}(%para54, I64(1))    #(Tuple[Ref[Tensor(F32)]*8], I64) #scope: Default
#[CNode]752
    %4 : Tensor(F32)[16, 6, 5, 5] = FuncGraph::fg_753(%para53, %3)    #(Func, Ref[Tensor(F32)][16, 6, 5, 5])    # fg_753=115_hyper_map.753 #scope: Default
#[CNode]629
    %5 : Ref[Tensor(F32)][120, 400] = Primitive::TupleGetItem{prim_type=1}(%para54, I64(2))    #(Tuple[Ref[Tensor(F32)]*8], I64) #scope: Default
#[CNode]756
    %6 : Tensor(F32)[120, 400] = FuncGraph::fg_757(%para53, %5)    #(Func, Ref[Tensor(F32)][120, 400])    # fg_757=117_hyper_map.757 #scope: Default
#[CNode]630
    %7 : Ref[Tensor(F32)][120] = Primitive::TupleGetItem{prim_type=1}(%para54, I64(3))    #(Tuple[Ref[Tensor(F32)]*8], I64) #scope: Default
#[CNode]760
    %8 : Tensor(F32)[120] = FuncGraph::fg_761(%para53, %7)    #(Func, Ref[Tensor(F32)][120])    # fg_761=119_hyper_map.761 #scope: Default
#[CNode]631
    %9 : Ref[Tensor(F32)][84, 120] = Primitive::TupleGetItem{prim_type=1}(%para54, I64(4))    #(Tuple[Ref[Tensor(F32)]*8], I64) #scope: Default
#[CNode]764
    %10 : Tensor(F32)[84, 120] = FuncGraph::fg_765(%para53, %9)    #(Func, Ref[Tensor(F32)][84, 120])    # fg_765=121_hyper_map.765 #scope: Default
#[CNode]632
    %11 : Ref[Tensor(F32)][84] = Primitive::TupleGetItem{prim_type=1}(%para54, I64(5))    #(Tuple[Ref[Tensor(F32)]*8], I64) #scope: Default
#[CNode]768
    %12 : Tensor(F32)[84] = FuncGraph::fg_769(%para53, %11)    #(Func, Ref[Tensor(F32)][84])    # fg_769=123_hyper_map.769 #scope: Default
#[CNode]633
    %13 : Ref[Tensor(F32)][10, 84] = Primitive::TupleGetItem{prim_type=1}(%para54, I64(6))    #(Tuple[Ref[Tensor(F32)]*8], I64) #scope: Default
#[CNode]772
    %14 : Tensor(F32)[10, 84] = FuncGraph::fg_773(%para53, %13)    #(Func, Ref[Tensor(F32)][10, 84])    # fg_773=125_hyper_map.773 #scope: Default
#[CNode]634
    %15 : Ref[Tensor(F32)][10] = Primitive::TupleGetItem{prim_type=1}(%para54, I64(7))    #(Tuple[Ref[Tensor(F32)]*8], I64) #scope: Default
#[CNode]776
    %16 : Tensor(F32)[10] = FuncGraph::fg_777(%para53, %15)    #(Func, Ref[Tensor(F32)][10])    # fg_777=127_hyper_map.777 #scope: Default
#[CNode]635
    %17 : Tuple[Tensor(F32)*8] = Primitive::MakeTuple{prim_type=1}(%2, %4, %6, %8, %10, %12, %14, %16)    #(Tensor(F32)[6, 1, 5, 5], Tensor(F32)[16, 6, 5, 5], Tensor(F32)[120, 400], Tensor(F32)[120], Tensor(F32)[84, 120], Tensor(F32)[84], Tensor(F32)[10, 84], Tensor(F32)[10]) #scope: Default
#[CNode]627
    Primitive::Return{prim_type=1}(%17)    #(Tuple[Tensor(F32)*8]) #scope: Default
#[CNode]816
}
# order:
#   1: 112_hyper_map.626:[CNode]746{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]747, [2]: ValueNode<Int64Imm> 0}
#   2: 112_hyper_map.626:[CNode]628{[0]: ValueNode<FuncGraph> 113_hyper_map.748, [1]: [Parameter]749, [2]: [CNode]746}
#   3: 112_hyper_map.626:[CNode]752{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]747, [2]: ValueNode<Int64Imm> 1}
#   4: 112_hyper_map.626:[CNode]629{[0]: ValueNode<FuncGraph> 115_hyper_map.753, [1]: [Parameter]749, [2]: [CNode]752}
#   5: 112_hyper_map.626:[CNode]756{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]747, [2]: ValueNode<Int64Imm> 2}
#   6: 112_hyper_map.626:[CNode]630{[0]: ValueNode<FuncGraph> 117_hyper_map.757, [1]: [Parameter]749, [2]: [CNode]756}
#   7: 112_hyper_map.626:[CNode]760{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]747, [2]: ValueNode<Int64Imm> 3}
#   8: 112_hyper_map.626:[CNode]631{[0]: ValueNode<FuncGraph> 119_hyper_map.761, [1]: [Parameter]749, [2]: [CNode]760}
#   9: 112_hyper_map.626:[CNode]764{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]747, [2]: ValueNode<Int64Imm> 4}
#  10: 112_hyper_map.626:[CNode]632{[0]: ValueNode<FuncGraph> 121_hyper_map.765, [1]: [Parameter]749, [2]: [CNode]764}
#  11: 112_hyper_map.626:[CNode]768{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]747, [2]: ValueNode<Int64Imm> 5}
#  12: 112_hyper_map.626:[CNode]633{[0]: ValueNode<FuncGraph> 123_hyper_map.769, [1]: [Parameter]749, [2]: [CNode]768}
#  13: 112_hyper_map.626:[CNode]772{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]747, [2]: ValueNode<Int64Imm> 6}
#  14: 112_hyper_map.626:[CNode]634{[0]: ValueNode<FuncGraph> 125_hyper_map.773, [1]: [Parameter]749, [2]: [CNode]772}
#  15: 112_hyper_map.626:[CNode]776{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]747, [2]: ValueNode<Int64Imm> 7}
#  16: 112_hyper_map.626:[CNode]635{[0]: ValueNode<FuncGraph> 127_hyper_map.777, [1]: [Parameter]749, [2]: [CNode]776}
#  17: 112_hyper_map.626:[CNode]627{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]628, [2]: [CNode]629, [3]: [CNode]630, [4]: [CNode]631, [5]: [CNode]632, [6]: [CNode]633, [7]: [CNode]634, [8]: [CNode]635}
#  18: 112_hyper_map.626:[CNode]816{[0]: ValueNode<Primitive> Return, [1]: [CNode]627}


# [No.27] 58_get_lr.617
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(578)/    def get_lr(self):/
funcgraph fg_617[fg_536](
) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(0), "DeadNode", FuncGraph::fg_616)    #(Bool, ProblemType, Func)    # fg_616=59_✗get_lr.616 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(587)/        if self.dynamic_lr:/#[CNode]338
    %2 : Ref[Tensor(F32)][] = %1[59_✗get_lr.616]() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(587)/        if self.dynamic_lr:/#[CNode]341
    Primitive::Return{prim_type=1}(%2)    #(Ref[Tensor(F32)][]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(587)/        if self.dynamic_lr:/#[CNode]412
}
# order:
#   1: 58_get_lr.617:[CNode]338{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> false, [2]: ValueNode<StringImm> DeadNode, [3]: ValueNode<FuncGraph> 59_✗get_lr.616}
#   2: 58_get_lr.617:[CNode]341{[0]: [CNode]338}
#   3: 58_get_lr.617:[CNode]412{[0]: ValueNode<Primitive> Return, [1]: [CNode]341}


# [No.28] 106_decay_weight.731
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(304)/    def decay_weight(self, gradients):/
funcgraph fg_731(
        %para55 : Tuple[Tensor(F32)*8]    # gradients
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(0), "DeadNode", FuncGraph::fg_732)    #(Bool, ProblemType, Func)    # fg_732=107_✗decay_weight.732 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(317)/        if self.exec_weight_decay:/#[CNode]379
    %2 : Tuple[Tensor(F32)*8] = %1[107_✗decay_weight.732]() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(317)/        if self.exec_weight_decay:/#[CNode]382
    Primitive::Return{prim_type=1}(%2)    #(Tuple[Tensor(F32)*8]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(317)/        if self.exec_weight_decay:/#[CNode]413
}
# order:
#   1: 106_decay_weight.731:[CNode]379{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> false, [2]: ValueNode<StringImm> DeadNode, [3]: ValueNode<FuncGraph> 107_✗decay_weight.732}
#   2: 106_decay_weight.731:[CNode]382{[0]: [CNode]379}
#   3: 106_decay_weight.731:[CNode]413{[0]: ValueNode<Primitive> Return, [1]: [CNode]382}


# [No.29] 103_gradients_centralization.728
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(328)/    def gradients_centralization(self, gradients):/
funcgraph fg_728(
        %para56 : Tuple[Tensor(F32)*8]    # gradients
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(0), "DeadNode", FuncGraph::fg_729)    #(Bool, ProblemType, Func)    # fg_729=104_✗gradients_centralization.729 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(342)/        if self.is_group:/#[CNode]359
    %2 : Tuple[Tensor(F32)*8] = %1[104_✗gradients_centralization.729]() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(342)/        if self.is_group:/#[CNode]362
    Primitive::Return{prim_type=1}(%2)    #(Tuple[Tensor(F32)*8]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(342)/        if self.is_group:/#[CNode]414
}
# order:
#   1: 103_gradients_centralization.728:[CNode]359{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> false, [2]: ValueNode<StringImm> DeadNode, [3]: ValueNode<FuncGraph> 104_✗gradients_centralization.729}
#   2: 103_gradients_centralization.728:[CNode]362{[0]: [CNode]359}
#   3: 103_gradients_centralization.728:[CNode]414{[0]: ValueNode<Primitive> Return, [1]: [CNode]362}


# [No.30] 55_scale_grad.725
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(347)/    def scale_grad(self, gradients):/
funcgraph fg_725(
        %para57 : Tuple[Tensor(F32)*8]    # gradients
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(0), "DeadNode", FuncGraph::fg_726)    #(Bool, ProblemType, Func)    # fg_726=56_✗scale_grad.726 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(361)/        if self.need_scale:/#[CNode]349
    %2 : Tuple[Tensor(F32)*8] = %1[56_✗scale_grad.726]() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(361)/        if self.need_scale:/#[CNode]352
    Primitive::Return{prim_type=1}(%2)    #(Tuple[Tensor(F32)*8]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(361)/        if self.need_scale:/#[CNode]415
}
# order:
#   1: 55_scale_grad.725:[CNode]349{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> false, [2]: ValueNode<StringImm> DeadNode, [3]: ValueNode<FuncGraph> 56_✗scale_grad.726}
#   2: 55_scale_grad.725:[CNode]352{[0]: [CNode]349}
#   3: 55_scale_grad.725:[CNode]415{[0]: ValueNode<Primitive> Return, [1]: [CNode]352}


# [No.31] 62_hyper_map.601
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/
funcgraph fg_601[fg_621](
        %para58 : Func    # [Parameter]639
        , %para59 : Tuple[Tensor(F32)*8]    # [Parameter]625
        , %para60 : Tuple[Ref[Tensor(F32)]*8]    # [Parameter]636
        , %para61 : Tuple[Ref[Tensor(F32)]*8]    # [Parameter]637
        , %para62 : Tuple[Bool*8]    # [Parameter]787
        , %para63 : Tuple[Bool*8]    # [Parameter]788
    ) {
    %1 : Tensor(F32)[6, 1, 5, 5] = Primitive::TupleGetItem{prim_type=1}(%para59, I64(0))    #(Tuple[Tensor(F32)*8], I64) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %2 : Ref[Tensor(F32)][6, 1, 5, 5] = Primitive::TupleGetItem{prim_type=1}(%para60, I64(0))    #(Tuple[Ref[Tensor(F32)]*8], I64) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %3 : Ref[Tensor(F32)][6, 1, 5, 5] = Primitive::TupleGetItem{prim_type=1}(%para61, I64(0))    #(Tuple[Ref[Tensor(F32)]*8], I64) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %4 : Bool = FuncGraph::fg_638(%para58, %1, %2, %3, Bool(0), Bool(0))    #(Func, Tensor(F32)[6, 1, 5, 5], Ref[Tensor(F32)][6, 1, 5, 5], Ref[Tensor(F32)][6, 1, 5, 5], Bool, Bool)    # fg_638=63_hyper_map.638 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %5 : Tensor(F32)[16, 6, 5, 5] = Primitive::TupleGetItem{prim_type=1}(%para59, I64(1))    #(Tuple[Tensor(F32)*8], I64) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %6 : Ref[Tensor(F32)][16, 6, 5, 5] = Primitive::TupleGetItem{prim_type=1}(%para60, I64(1))    #(Tuple[Ref[Tensor(F32)]*8], I64) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %7 : Ref[Tensor(F32)][16, 6, 5, 5] = Primitive::TupleGetItem{prim_type=1}(%para61, I64(1))    #(Tuple[Ref[Tensor(F32)]*8], I64) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %8 : Bool = FuncGraph::fg_651(%para58, %5, %6, %7, Bool(0), Bool(0))    #(Func, Tensor(F32)[16, 6, 5, 5], Ref[Tensor(F32)][16, 6, 5, 5], Ref[Tensor(F32)][16, 6, 5, 5], Bool, Bool)    # fg_651=68_hyper_map.651 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %9 : Tensor(F32)[120, 400] = Primitive::TupleGetItem{prim_type=1}(%para59, I64(2))    #(Tuple[Tensor(F32)*8], I64) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %10 : Ref[Tensor(F32)][120, 400] = Primitive::TupleGetItem{prim_type=1}(%para60, I64(2))    #(Tuple[Ref[Tensor(F32)]*8], I64) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %11 : Ref[Tensor(F32)][120, 400] = Primitive::TupleGetItem{prim_type=1}(%para61, I64(2))    #(Tuple[Ref[Tensor(F32)]*8], I64) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %12 : Bool = FuncGraph::fg_663(%para58, %9, %10, %11, Bool(0), Bool(0))    #(Func, Tensor(F32)[120, 400], Ref[Tensor(F32)][120, 400], Ref[Tensor(F32)][120, 400], Bool, Bool)    # fg_663=73_hyper_map.663 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %13 : Tensor(F32)[120] = Primitive::TupleGetItem{prim_type=1}(%para59, I64(3))    #(Tuple[Tensor(F32)*8], I64) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %14 : Ref[Tensor(F32)][120] = Primitive::TupleGetItem{prim_type=1}(%para60, I64(3))    #(Tuple[Ref[Tensor(F32)]*8], I64) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %15 : Ref[Tensor(F32)][120] = Primitive::TupleGetItem{prim_type=1}(%para61, I64(3))    #(Tuple[Ref[Tensor(F32)]*8], I64) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %16 : Bool = FuncGraph::fg_675(%para58, %13, %14, %15, Bool(0), Bool(0))    #(Func, Tensor(F32)[120], Ref[Tensor(F32)][120], Ref[Tensor(F32)][120], Bool, Bool)    # fg_675=78_hyper_map.675 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %17 : Tensor(F32)[84, 120] = Primitive::TupleGetItem{prim_type=1}(%para59, I64(4))    #(Tuple[Tensor(F32)*8], I64) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %18 : Ref[Tensor(F32)][84, 120] = Primitive::TupleGetItem{prim_type=1}(%para60, I64(4))    #(Tuple[Ref[Tensor(F32)]*8], I64) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %19 : Ref[Tensor(F32)][84, 120] = Primitive::TupleGetItem{prim_type=1}(%para61, I64(4))    #(Tuple[Ref[Tensor(F32)]*8], I64) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %20 : Bool = FuncGraph::fg_687(%para58, %17, %18, %19, Bool(0), Bool(0))    #(Func, Tensor(F32)[84, 120], Ref[Tensor(F32)][84, 120], Ref[Tensor(F32)][84, 120], Bool, Bool)    # fg_687=83_hyper_map.687 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %21 : Tensor(F32)[84] = Primitive::TupleGetItem{prim_type=1}(%para59, I64(5))    #(Tuple[Tensor(F32)*8], I64) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %22 : Ref[Tensor(F32)][84] = Primitive::TupleGetItem{prim_type=1}(%para60, I64(5))    #(Tuple[Ref[Tensor(F32)]*8], I64) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %23 : Ref[Tensor(F32)][84] = Primitive::TupleGetItem{prim_type=1}(%para61, I64(5))    #(Tuple[Ref[Tensor(F32)]*8], I64) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %24 : Bool = FuncGraph::fg_699(%para58, %21, %22, %23, Bool(0), Bool(0))    #(Func, Tensor(F32)[84], Ref[Tensor(F32)][84], Ref[Tensor(F32)][84], Bool, Bool)    # fg_699=88_hyper_map.699 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %25 : Tensor(F32)[10, 84] = Primitive::TupleGetItem{prim_type=1}(%para59, I64(6))    #(Tuple[Tensor(F32)*8], I64) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %26 : Ref[Tensor(F32)][10, 84] = Primitive::TupleGetItem{prim_type=1}(%para60, I64(6))    #(Tuple[Ref[Tensor(F32)]*8], I64) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %27 : Ref[Tensor(F32)][10, 84] = Primitive::TupleGetItem{prim_type=1}(%para61, I64(6))    #(Tuple[Ref[Tensor(F32)]*8], I64) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %28 : Bool = FuncGraph::fg_711(%para58, %25, %26, %27, Bool(0), Bool(0))    #(Func, Tensor(F32)[10, 84], Ref[Tensor(F32)][10, 84], Ref[Tensor(F32)][10, 84], Bool, Bool)    # fg_711=93_hyper_map.711 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %29 : Tensor(F32)[10] = Primitive::TupleGetItem{prim_type=1}(%para59, I64(7))    #(Tuple[Tensor(F32)*8], I64) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %30 : Ref[Tensor(F32)][10] = Primitive::TupleGetItem{prim_type=1}(%para60, I64(7))    #(Tuple[Ref[Tensor(F32)]*8], I64) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %31 : Ref[Tensor(F32)][10] = Primitive::TupleGetItem{prim_type=1}(%para61, I64(7))    #(Tuple[Ref[Tensor(F32)]*8], I64) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %32 : Bool = FuncGraph::fg_723(%para58, %29, %30, %31, Bool(0), Bool(0))    #(Func, Tensor(F32)[10], Ref[Tensor(F32)][10], Ref[Tensor(F32)][10], Bool, Bool)    # fg_723=98_hyper_map.723 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %33 : Tuple[Bool*8] = Primitive::MakeTuple{prim_type=1}(%4, %8, %12, %16, %20, %24, %28, %32)    #(Bool, Bool, Bool, Bool, Bool, Bool, Bool, Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    Primitive::Return{prim_type=1}(%33)    #(Tuple[Bool*8]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
}
# order:
#   1: 62_hyper_map.601:success{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]625, [2]: ValueNode<Int64Imm> 7}
#   2: 62_hyper_map.601:success{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]636, [2]: ValueNode<Int64Imm> 7}
#   3: 62_hyper_map.601:success{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]637, [2]: ValueNode<Int64Imm> 7}
#   4: 62_hyper_map.601:success{[0]: ValueNode<FuncGraph> 98_hyper_map.723, [1]: [Parameter]639, [2]: success, [3]: success, [4]: success, [5]: ValueNode<BoolImm> false, [6]: ValueNode<BoolImm> false}
#   5: 62_hyper_map.601:success{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]625, [2]: ValueNode<Int64Imm> 6}
#   6: 62_hyper_map.601:success{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]636, [2]: ValueNode<Int64Imm> 6}
#   7: 62_hyper_map.601:success{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]637, [2]: ValueNode<Int64Imm> 6}
#   8: 62_hyper_map.601:success{[0]: ValueNode<FuncGraph> 93_hyper_map.711, [1]: [Parameter]639, [2]: success, [3]: success, [4]: success, [5]: ValueNode<BoolImm> false, [6]: ValueNode<BoolImm> false}
#   9: 62_hyper_map.601:success{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]625, [2]: ValueNode<Int64Imm> 5}
#  10: 62_hyper_map.601:success{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]636, [2]: ValueNode<Int64Imm> 5}
#  11: 62_hyper_map.601:success{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]637, [2]: ValueNode<Int64Imm> 5}
#  12: 62_hyper_map.601:success{[0]: ValueNode<FuncGraph> 88_hyper_map.699, [1]: [Parameter]639, [2]: success, [3]: success, [4]: success, [5]: ValueNode<BoolImm> false, [6]: ValueNode<BoolImm> false}
#  13: 62_hyper_map.601:success{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]625, [2]: ValueNode<Int64Imm> 4}
#  14: 62_hyper_map.601:success{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]636, [2]: ValueNode<Int64Imm> 4}
#  15: 62_hyper_map.601:success{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]637, [2]: ValueNode<Int64Imm> 4}
#  16: 62_hyper_map.601:success{[0]: ValueNode<FuncGraph> 83_hyper_map.687, [1]: [Parameter]639, [2]: success, [3]: success, [4]: success, [5]: ValueNode<BoolImm> false, [6]: ValueNode<BoolImm> false}
#  17: 62_hyper_map.601:success{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]625, [2]: ValueNode<Int64Imm> 3}
#  18: 62_hyper_map.601:success{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]636, [2]: ValueNode<Int64Imm> 3}
#  19: 62_hyper_map.601:success{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]637, [2]: ValueNode<Int64Imm> 3}
#  20: 62_hyper_map.601:success{[0]: ValueNode<FuncGraph> 78_hyper_map.675, [1]: [Parameter]639, [2]: success, [3]: success, [4]: success, [5]: ValueNode<BoolImm> false, [6]: ValueNode<BoolImm> false}
#  21: 62_hyper_map.601:success{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]625, [2]: ValueNode<Int64Imm> 2}
#  22: 62_hyper_map.601:success{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]636, [2]: ValueNode<Int64Imm> 2}
#  23: 62_hyper_map.601:success{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]637, [2]: ValueNode<Int64Imm> 2}
#  24: 62_hyper_map.601:success{[0]: ValueNode<FuncGraph> 73_hyper_map.663, [1]: [Parameter]639, [2]: success, [3]: success, [4]: success, [5]: ValueNode<BoolImm> false, [6]: ValueNode<BoolImm> false}
#  25: 62_hyper_map.601:success{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]625, [2]: ValueNode<Int64Imm> 1}
#  26: 62_hyper_map.601:success{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]636, [2]: ValueNode<Int64Imm> 1}
#  27: 62_hyper_map.601:success{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]637, [2]: ValueNode<Int64Imm> 1}
#  28: 62_hyper_map.601:success{[0]: ValueNode<FuncGraph> 68_hyper_map.651, [1]: [Parameter]639, [2]: success, [3]: success, [4]: success, [5]: ValueNode<BoolImm> false, [6]: ValueNode<BoolImm> false}
#  29: 62_hyper_map.601:success{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]625, [2]: ValueNode<Int64Imm> 0}
#  30: 62_hyper_map.601:success{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]636, [2]: ValueNode<Int64Imm> 0}
#  31: 62_hyper_map.601:success{[0]: ValueNode<Primitive> TupleGetItem, [1]: [Parameter]637, [2]: ValueNode<Int64Imm> 0}
#  32: 62_hyper_map.601:success{[0]: ValueNode<FuncGraph> 63_hyper_map.638, [1]: [Parameter]639, [2]: success, [3]: success, [4]: success, [5]: ValueNode<BoolImm> false, [6]: ValueNode<BoolImm> false}
#  33: 62_hyper_map.601:success{[0]: ValueNode<Primitive> MakeTuple, [1]: success, [2]: success, [3]: success, [4]: success, [5]: success, [6]: success, [7]: success, [8]: success}
#  34: 62_hyper_map.601:success{[0]: ValueNode<Primitive> Return, [1]: success}


# [No.32] 61_↓construct.733
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(177)/        if self.is_group_lr:/
funcgraph fg_733(
        %para64 : Tuple[Bool*8]    # Φsuccess
    ) {
    Primitive::Return{prim_type=1}(%para64)    #(Tuple[Bool*8]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(183)/        return success/#[CNode]416
}
# order:
#   1: 61_↓construct.733:[CNode]416{[0]: ValueNode<Primitive> Return, [1]: Φsuccess}


# [No.33] 51_✗construct.588
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
funcgraph fg_588[fg_587](
) {
    %1 : $(50_construct.587):Tensor(F32)[32, 6, 28, 28] = PrimitivePy::Conv2D{prim_type=1}[kernel_size=(I64(5), I64(5)), mode=I64(1), out_channel=I64(6), input_names=["x", "w"], pad=(I64(0), I64(0), I64(0), I64(0)), pad_mode=I64(2), format="NCHW", pad_list=(I64(0), I64(0), I64(0), I64(0)), groups=I64(1), stride=(I64(1), I64(1), I64(1), I64(1)), group=I64(1), dilation=(I64(1), I64(1), I64(1), I64(1)), output_names=["output"]](%para41, %para3)    #(Tensor(F32)[32, 1, 32, 32], Ref[Tensor(F32)][6, 1, 5, 5]) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(266)/        output = self.conv2d(x, self.weight)/#output
    %2 : Tensor(F32)[32, 6, 28, 28] = FuncGraph::fg_586(%1)    #(Tensor(F32)[32, 6, 28, 28])    # fg_586=52_↓construct.586 #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]265
    Primitive::Return{prim_type=1}(%2)    #(Tensor(F32)[32, 6, 28, 28]) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]418
}
# order:
#   1: 51_✗construct.588:[CNode]265{[0]: ValueNode<FuncGraph> 52_↓construct.586, [1]: output}
#   2: 51_✗construct.588:[CNode]418{[0]: ValueNode<Primitive> Return, [1]: [CNode]265}


# [No.34] 46_✗construct.585
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
funcgraph fg_585[fg_584](
) {
    %1 : $(45_construct.584):Tensor(F32)[32, 16, 10, 10] = PrimitivePy::Conv2D{prim_type=1}[kernel_size=(I64(5), I64(5)), mode=I64(1), out_channel=I64(16), input_names=["x", "w"], pad=(I64(0), I64(0), I64(0), I64(0)), pad_mode=I64(2), format="NCHW", pad_list=(I64(0), I64(0), I64(0), I64(0)), groups=I64(1), stride=(I64(1), I64(1), I64(1), I64(1)), group=I64(1), dilation=(I64(1), I64(1), I64(1), I64(1)), output_names=["output"]](%para44, %para4)    #(Tensor(F32)[32, 6, 14, 14], Ref[Tensor(F32)][16, 6, 5, 5]) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(266)/        output = self.conv2d(x, self.weight)/#output
    %2 : Tensor(F32)[32, 16, 10, 10] = FuncGraph::fg_583(%1)    #(Tensor(F32)[32, 16, 10, 10])    # fg_583=47_↓construct.583 #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]256
    Primitive::Return{prim_type=1}(%2)    #(Tensor(F32)[32, 16, 10, 10]) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]420
}
# order:
#   1: 46_✗construct.585:[CNode]256{[0]: ValueNode<FuncGraph> 47_↓construct.583, [1]: output}
#   2: 46_✗construct.585:[CNode]420{[0]: ValueNode<Primitive> Return, [1]: [CNode]256}


# [No.35] 33_L-construct.578
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(319)/    def construct(self, x):/
funcgraph fg_578(
        %para65 : Tensor(F32)[32, 400]    # x
        , %para66 : Ref[Tensor(F32)][120]    # L-fc3.bias
        , %para67 : Ref[Tensor(F32)][120, 400]    # L-fc3.weight
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(0), "DeadNode", FuncGraph::fg_581)    #(Bool, ProblemType, Func)    # fg_581=34_L-✗construct.581 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]143
    %2 : Tensor(F32)[32, 120] = %1[34_L-✗construct.581]() #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]146
    %3 : Tensor(F32)[32, 120] = Primitive::Depend{prim_type=1}[side_effect_propagate=I64(1)](%2, None)    #(Tensor(F32)[32, 120], NoneType) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\PythonCode\LeNet\lenet.py(52)/        x = self.fc3(x)/#[CNode]147
    Primitive::Return{prim_type=1}(%3)    #(Tensor(F32)[32, 120]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]409
}
# order:
#   1: 33_L-construct.578:[CNode]143{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> false, [2]: ValueNode<StringImm> DeadNode, [3]: ValueNode<FuncGraph> 34_L-✗construct.581}
#   2: 33_L-construct.578:[CNode]146{[0]: [CNode]143}
#   3: 33_L-construct.578:[CNode]409{[0]: ValueNode<Primitive> Return, [1]: [CNode]147}


# [No.36] 22_L-construct.569
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(319)/    def construct(self, x):/
funcgraph fg_569(
        %para68 : Tensor(F32)[32, 120]    # x
        , %para69 : Ref[Tensor(F32)][84]    # L-fc3.bias
        , %para70 : Ref[Tensor(F32)][84, 120]    # L-fc3.weight
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(0), "DeadNode", FuncGraph::fg_572)    #(Bool, ProblemType, Func)    # fg_572=23_L-✗construct.572 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]143
    %2 : Tensor(F32)[32, 84] = %1[23_L-✗construct.572]() #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]146
    %3 : Tensor(F32)[32, 84] = Primitive::Depend{prim_type=1}[side_effect_propagate=I64(1)](%2, None)    #(Tensor(F32)[32, 84], NoneType) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\PythonCode\LeNet\lenet.py(52)/        x = self.fc3(x)/#[CNode]147
    Primitive::Return{prim_type=1}(%3)    #(Tensor(F32)[32, 84]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]409
}
# order:
#   1: 22_L-construct.569:[CNode]143{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> false, [2]: ValueNode<StringImm> DeadNode, [3]: ValueNode<FuncGraph> 23_L-✗construct.572}
#   2: 22_L-construct.569:[CNode]146{[0]: [CNode]143}
#   3: 22_L-construct.569:[CNode]409{[0]: ValueNode<Primitive> Return, [1]: [CNode]147}


# [No.37] 11_L-construct.560
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(319)/    def construct(self, x):/
funcgraph fg_560(
        %para71 : Tensor(F32)[32, 84]    # x
        , %para72 : Ref[Tensor(F32)][10]    # L-fc3.bias
        , %para73 : Ref[Tensor(F32)][10, 84]    # L-fc3.weight
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(0), "DeadNode", FuncGraph::fg_563)    #(Bool, ProblemType, Func)    # fg_563=12_L-✗construct.563 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]143
    %2 : Tensor(F32)[32, 10] = %1[12_L-✗construct.563]() #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]146
    %3 : Tensor(F32)[32, 10] = Primitive::Depend{prim_type=1}[side_effect_propagate=I64(1)](%2, None)    #(Tensor(F32)[32, 10], NoneType) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\PythonCode\LeNet\lenet.py(52)/        x = self.fc3(x)/#[CNode]147
    Primitive::Return{prim_type=1}(%3)    #(Tensor(F32)[32, 10]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]409
}
# order:
#   1: 11_L-construct.560:[CNode]143{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> false, [2]: ValueNode<StringImm> DeadNode, [3]: ValueNode<FuncGraph> 12_L-✗construct.563}
#   2: 11_L-construct.560:[CNode]146{[0]: [CNode]143}
#   3: 11_L-construct.560:[CNode]409{[0]: ValueNode<Primitive> Return, [1]: [CNode]147}


# [No.38] 8_✓✓construct.552
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/
funcgraph fg_552[fg_551](
) {
    %1 : Tensor(F32)[] = PrimitivePy::SparseSoftmaxCrossEntropyWithLogits{prim_type=2}[output_names=["output"], input_names=["features", "labels"], sens=F32(1), is_grad=Bool(0)](%para36, %para37)    #(Tensor(F32)[32, 10], Tensor(I32)[32]) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(627)/                x = self.sparse_softmax_cross_entropy(logits, labels)/#x
    Primitive::Return{prim_type=1}(%1)    #(Tensor(F32)[]) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(628)/                return x/#[CNode]428
}
# order:
#   1: 8_✓✓construct.552:x{[0]: ValueNode<PrimitivePy> SparseSoftmaxCrossEntropyWithLogits, [1]: Φlogits, [2]: labels}
#   2: 8_✓✓construct.552:[CNode]428{[0]: ValueNode<Primitive> Return, [1]: x}


# [No.39] 113_hyper_map.748

funcgraph fg_748[fg_740](
        %para74 : Func    # [Parameter]812
        , %para75 : Ref[Tensor(F32)][6, 1, 5, 5]    # [Parameter]745
    ) {
    %1 : $(110_construct.742):Func = Primitive::J{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_550)    #(Func)    # fg_550=5_construct.550 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %2 : $(111_construct.740):Tuple[Tensor(F32),Func] = %1(%para38, %para39)    #(Tensor(F32)[32, 1, 32, 32], Tensor(I32)[32]) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %3 : $(111_construct.740):Func = Primitive::TupleGetItem{prim_type=1}(%2, I64(1))    #(Tuple[Tensor(F32),Func], I64) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %4 : $(111_construct.740):Tuple[EnvType,Tensor(F32),Tensor(I32)] = %3(Tensor(43)[])    #(Tensor(F32)[](...)) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %5 : $(111_construct.740):EnvType = Primitive::TupleGetItem{prim_type=1}(%4, I64(0))    #(Tuple[EnvType,Tensor(F32),Tensor(I32)], I64) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %6 : Func = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_744, %5)    #(Func, EnvType)    # fg_744=114__tensor_env_get.744 #scope: Default
#[CNode]743
    %7 : Tensor(F32)[6, 1, 5, 5] = %6(%para75)    #(Ref[Tensor(F32)][6, 1, 5, 5]) #scope: Default
#[CNode]741
    Primitive::Return{prim_type=1}(%7)    #(Tensor(F32)[6, 1, 5, 5]) #scope: Default
#[CNode]817
}
# order:
#   1: 113_hyper_map.748:[CNode]741{[0]: [CNode]743, [1]: [Parameter]745}
#   2: 113_hyper_map.748:[CNode]817{[0]: ValueNode<Primitive> Return, [1]: [CNode]741}


# [No.40] 115_hyper_map.753

funcgraph fg_753[fg_740](
        %para76 : Func    # [Parameter]812
        , %para77 : Ref[Tensor(F32)][16, 6, 5, 5]    # [Parameter]745
    ) {
    %1 : $(110_construct.742):Func = Primitive::J{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_550)    #(Func)    # fg_550=5_construct.550 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %2 : $(111_construct.740):Tuple[Tensor(F32),Func] = %1(%para38, %para39)    #(Tensor(F32)[32, 1, 32, 32], Tensor(I32)[32]) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %3 : $(111_construct.740):Func = Primitive::TupleGetItem{prim_type=1}(%2, I64(1))    #(Tuple[Tensor(F32),Func], I64) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %4 : $(111_construct.740):Tuple[EnvType,Tensor(F32),Tensor(I32)] = %3(Tensor(43)[])    #(Tensor(F32)[](...)) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %5 : $(111_construct.740):EnvType = Primitive::TupleGetItem{prim_type=1}(%4, I64(0))    #(Tuple[EnvType,Tensor(F32),Tensor(I32)], I64) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %6 : Func = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_751, %5)    #(Func, EnvType)    # fg_751=116__tensor_env_get.751 #scope: Default
#[CNode]750
    %7 : Tensor(F32)[16, 6, 5, 5] = %6(%para77)    #(Ref[Tensor(F32)][16, 6, 5, 5]) #scope: Default
#[CNode]741
    Primitive::Return{prim_type=1}(%7)    #(Tensor(F32)[16, 6, 5, 5]) #scope: Default
#[CNode]817
}
# order:
#   1: 115_hyper_map.753:[CNode]741{[0]: [CNode]750, [1]: [Parameter]745}
#   2: 115_hyper_map.753:[CNode]817{[0]: ValueNode<Primitive> Return, [1]: [CNode]741}


# [No.41] 117_hyper_map.757

funcgraph fg_757[fg_740](
        %para78 : Func    # [Parameter]812
        , %para79 : Ref[Tensor(F32)][120, 400]    # [Parameter]745
    ) {
    %1 : $(110_construct.742):Func = Primitive::J{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_550)    #(Func)    # fg_550=5_construct.550 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %2 : $(111_construct.740):Tuple[Tensor(F32),Func] = %1(%para38, %para39)    #(Tensor(F32)[32, 1, 32, 32], Tensor(I32)[32]) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %3 : $(111_construct.740):Func = Primitive::TupleGetItem{prim_type=1}(%2, I64(1))    #(Tuple[Tensor(F32),Func], I64) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %4 : $(111_construct.740):Tuple[EnvType,Tensor(F32),Tensor(I32)] = %3(Tensor(43)[])    #(Tensor(F32)[](...)) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %5 : $(111_construct.740):EnvType = Primitive::TupleGetItem{prim_type=1}(%4, I64(0))    #(Tuple[EnvType,Tensor(F32),Tensor(I32)], I64) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %6 : Func = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_755, %5)    #(Func, EnvType)    # fg_755=118__tensor_env_get.755 #scope: Default
#[CNode]754
    %7 : Tensor(F32)[120, 400] = %6(%para79)    #(Ref[Tensor(F32)][120, 400]) #scope: Default
#[CNode]741
    Primitive::Return{prim_type=1}(%7)    #(Tensor(F32)[120, 400]) #scope: Default
#[CNode]817
}
# order:
#   1: 117_hyper_map.757:[CNode]741{[0]: [CNode]754, [1]: [Parameter]745}
#   2: 117_hyper_map.757:[CNode]817{[0]: ValueNode<Primitive> Return, [1]: [CNode]741}


# [No.42] 119_hyper_map.761

funcgraph fg_761[fg_740](
        %para80 : Func    # [Parameter]812
        , %para81 : Ref[Tensor(F32)][120]    # [Parameter]745
    ) {
    %1 : $(110_construct.742):Func = Primitive::J{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_550)    #(Func)    # fg_550=5_construct.550 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %2 : $(111_construct.740):Tuple[Tensor(F32),Func] = %1(%para38, %para39)    #(Tensor(F32)[32, 1, 32, 32], Tensor(I32)[32]) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %3 : $(111_construct.740):Func = Primitive::TupleGetItem{prim_type=1}(%2, I64(1))    #(Tuple[Tensor(F32),Func], I64) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %4 : $(111_construct.740):Tuple[EnvType,Tensor(F32),Tensor(I32)] = %3(Tensor(43)[])    #(Tensor(F32)[](...)) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %5 : $(111_construct.740):EnvType = Primitive::TupleGetItem{prim_type=1}(%4, I64(0))    #(Tuple[EnvType,Tensor(F32),Tensor(I32)], I64) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %6 : Func = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_759, %5)    #(Func, EnvType)    # fg_759=120__tensor_env_get.759 #scope: Default
#[CNode]758
    %7 : Tensor(F32)[120] = %6(%para81)    #(Ref[Tensor(F32)][120]) #scope: Default
#[CNode]741
    Primitive::Return{prim_type=1}(%7)    #(Tensor(F32)[120]) #scope: Default
#[CNode]817
}
# order:
#   1: 119_hyper_map.761:[CNode]741{[0]: [CNode]758, [1]: [Parameter]745}
#   2: 119_hyper_map.761:[CNode]817{[0]: ValueNode<Primitive> Return, [1]: [CNode]741}


# [No.43] 121_hyper_map.765

funcgraph fg_765[fg_740](
        %para82 : Func    # [Parameter]812
        , %para83 : Ref[Tensor(F32)][84, 120]    # [Parameter]745
    ) {
    %1 : $(110_construct.742):Func = Primitive::J{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_550)    #(Func)    # fg_550=5_construct.550 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %2 : $(111_construct.740):Tuple[Tensor(F32),Func] = %1(%para38, %para39)    #(Tensor(F32)[32, 1, 32, 32], Tensor(I32)[32]) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %3 : $(111_construct.740):Func = Primitive::TupleGetItem{prim_type=1}(%2, I64(1))    #(Tuple[Tensor(F32),Func], I64) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %4 : $(111_construct.740):Tuple[EnvType,Tensor(F32),Tensor(I32)] = %3(Tensor(43)[])    #(Tensor(F32)[](...)) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %5 : $(111_construct.740):EnvType = Primitive::TupleGetItem{prim_type=1}(%4, I64(0))    #(Tuple[EnvType,Tensor(F32),Tensor(I32)], I64) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %6 : Func = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_763, %5)    #(Func, EnvType)    # fg_763=122__tensor_env_get.763 #scope: Default
#[CNode]762
    %7 : Tensor(F32)[84, 120] = %6(%para83)    #(Ref[Tensor(F32)][84, 120]) #scope: Default
#[CNode]741
    Primitive::Return{prim_type=1}(%7)    #(Tensor(F32)[84, 120]) #scope: Default
#[CNode]817
}
# order:
#   1: 121_hyper_map.765:[CNode]741{[0]: [CNode]762, [1]: [Parameter]745}
#   2: 121_hyper_map.765:[CNode]817{[0]: ValueNode<Primitive> Return, [1]: [CNode]741}


# [No.44] 123_hyper_map.769

funcgraph fg_769[fg_740](
        %para84 : Func    # [Parameter]812
        , %para85 : Ref[Tensor(F32)][84]    # [Parameter]745
    ) {
    %1 : $(110_construct.742):Func = Primitive::J{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_550)    #(Func)    # fg_550=5_construct.550 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %2 : $(111_construct.740):Tuple[Tensor(F32),Func] = %1(%para38, %para39)    #(Tensor(F32)[32, 1, 32, 32], Tensor(I32)[32]) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %3 : $(111_construct.740):Func = Primitive::TupleGetItem{prim_type=1}(%2, I64(1))    #(Tuple[Tensor(F32),Func], I64) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %4 : $(111_construct.740):Tuple[EnvType,Tensor(F32),Tensor(I32)] = %3(Tensor(43)[])    #(Tensor(F32)[](...)) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %5 : $(111_construct.740):EnvType = Primitive::TupleGetItem{prim_type=1}(%4, I64(0))    #(Tuple[EnvType,Tensor(F32),Tensor(I32)], I64) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %6 : Func = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_767, %5)    #(Func, EnvType)    # fg_767=124__tensor_env_get.767 #scope: Default
#[CNode]766
    %7 : Tensor(F32)[84] = %6(%para85)    #(Ref[Tensor(F32)][84]) #scope: Default
#[CNode]741
    Primitive::Return{prim_type=1}(%7)    #(Tensor(F32)[84]) #scope: Default
#[CNode]817
}
# order:
#   1: 123_hyper_map.769:[CNode]741{[0]: [CNode]766, [1]: [Parameter]745}
#   2: 123_hyper_map.769:[CNode]817{[0]: ValueNode<Primitive> Return, [1]: [CNode]741}


# [No.45] 125_hyper_map.773

funcgraph fg_773[fg_740](
        %para86 : Func    # [Parameter]812
        , %para87 : Ref[Tensor(F32)][10, 84]    # [Parameter]745
    ) {
    %1 : $(110_construct.742):Func = Primitive::J{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_550)    #(Func)    # fg_550=5_construct.550 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %2 : $(111_construct.740):Tuple[Tensor(F32),Func] = %1(%para38, %para39)    #(Tensor(F32)[32, 1, 32, 32], Tensor(I32)[32]) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %3 : $(111_construct.740):Func = Primitive::TupleGetItem{prim_type=1}(%2, I64(1))    #(Tuple[Tensor(F32),Func], I64) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %4 : $(111_construct.740):Tuple[EnvType,Tensor(F32),Tensor(I32)] = %3(Tensor(43)[])    #(Tensor(F32)[](...)) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %5 : $(111_construct.740):EnvType = Primitive::TupleGetItem{prim_type=1}(%4, I64(0))    #(Tuple[EnvType,Tensor(F32),Tensor(I32)], I64) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %6 : Func = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_771, %5)    #(Func, EnvType)    # fg_771=126__tensor_env_get.771 #scope: Default
#[CNode]770
    %7 : Tensor(F32)[10, 84] = %6(%para87)    #(Ref[Tensor(F32)][10, 84]) #scope: Default
#[CNode]741
    Primitive::Return{prim_type=1}(%7)    #(Tensor(F32)[10, 84]) #scope: Default
#[CNode]817
}
# order:
#   1: 125_hyper_map.773:[CNode]741{[0]: [CNode]770, [1]: [Parameter]745}
#   2: 125_hyper_map.773:[CNode]817{[0]: ValueNode<Primitive> Return, [1]: [CNode]741}


# [No.46] 127_hyper_map.777

funcgraph fg_777[fg_740](
        %para88 : Func    # [Parameter]812
        , %para89 : Ref[Tensor(F32)][10]    # [Parameter]745
    ) {
    %1 : $(110_construct.742):Func = Primitive::J{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_550)    #(Func)    # fg_550=5_construct.550 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %2 : $(111_construct.740):Tuple[Tensor(F32),Func] = %1(%para38, %para39)    #(Tensor(F32)[32, 1, 32, 32], Tensor(I32)[32]) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %3 : $(111_construct.740):Func = Primitive::TupleGetItem{prim_type=1}(%2, I64(1))    #(Tuple[Tensor(F32),Func], I64) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %4 : $(111_construct.740):Tuple[EnvType,Tensor(F32),Tensor(I32)] = %3(Tensor(43)[])    #(Tensor(F32)[](...)) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %5 : $(111_construct.740):EnvType = Primitive::TupleGetItem{prim_type=1}(%4, I64(0))    #(Tuple[EnvType,Tensor(F32),Tensor(I32)], I64) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %6 : Func = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_775, %5)    #(Func, EnvType)    # fg_775=128__tensor_env_get.775 #scope: Default
#[CNode]774
    %7 : Tensor(F32)[10] = %6(%para89)    #(Ref[Tensor(F32)][10]) #scope: Default
#[CNode]741
    Primitive::Return{prim_type=1}(%7)    #(Tensor(F32)[10]) #scope: Default
#[CNode]817
}
# order:
#   1: 127_hyper_map.777:[CNode]741{[0]: [CNode]774, [1]: [Parameter]745}
#   2: 127_hyper_map.777:[CNode]817{[0]: ValueNode<Primitive> Return, [1]: [CNode]741}


# [No.47] 59_✗get_lr.616
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(587)/        if self.dynamic_lr:/
funcgraph fg_616[fg_536](
) {
    %1 : Ref[Tensor(F32)][] = FuncGraph::fg_615(%para20)    #(Ref[Tensor(F32)][])    # fg_615=60_↓get_lr.615 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(587)/        if self.dynamic_lr:/#[CNode]337
    Primitive::Return{prim_type=1}(%1)    #(Ref[Tensor(F32)][]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(587)/        if self.dynamic_lr:/#[CNode]432
}
# order:
#   1: 59_✗get_lr.616:[CNode]337{[0]: ValueNode<FuncGraph> 60_↓get_lr.615, [1]: learning_rate}
#   2: 59_✗get_lr.616:[CNode]432{[0]: ValueNode<Primitive> Return, [1]: [CNode]337}


# [No.48] 107_✗decay_weight.732
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(317)/        if self.exec_weight_decay:/
funcgraph fg_732[fg_731](
) {
    %1 : Tuple[Tensor(F32)*8] = FuncGraph::fg_730(%para55)    #(Tuple[Tensor(F32)*8])    # fg_730=108_↓decay_weight.730 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(317)/        if self.exec_weight_decay:/#[CNode]378
    Primitive::Return{prim_type=1}(%1)    #(Tuple[Tensor(F32)*8]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(317)/        if self.exec_weight_decay:/#[CNode]434
}
# order:
#   1: 107_✗decay_weight.732:[CNode]378{[0]: ValueNode<FuncGraph> 108_↓decay_weight.730, [1]: gradients}
#   2: 107_✗decay_weight.732:[CNode]434{[0]: ValueNode<Primitive> Return, [1]: [CNode]378}


# [No.49] 104_✗gradients_centralization.729
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(342)/        if self.is_group:/
funcgraph fg_729[fg_728](
) {
    %1 : Tuple[Tensor(F32)*8] = FuncGraph::fg_727(%para56)    #(Tuple[Tensor(F32)*8])    # fg_727=105_↓gradients_centralization.727 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(342)/        if self.is_group:/#[CNode]358
    Primitive::Return{prim_type=1}(%1)    #(Tuple[Tensor(F32)*8]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(342)/        if self.is_group:/#[CNode]436
}
# order:
#   1: 104_✗gradients_centralization.729:[CNode]358{[0]: ValueNode<FuncGraph> 105_↓gradients_centralization.727, [1]: gradients}
#   2: 104_✗gradients_centralization.729:[CNode]436{[0]: ValueNode<Primitive> Return, [1]: [CNode]358}


# [No.50] 56_✗scale_grad.726
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(361)/        if self.need_scale:/
funcgraph fg_726[fg_725](
) {
    %1 : Tuple[Tensor(F32)*8] = FuncGraph::fg_724(%para57)    #(Tuple[Tensor(F32)*8])    # fg_724=57_↓scale_grad.724 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(361)/        if self.need_scale:/#[CNode]348
    Primitive::Return{prim_type=1}(%1)    #(Tuple[Tensor(F32)*8]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(361)/        if self.need_scale:/#[CNode]438
}
# order:
#   1: 56_✗scale_grad.726:[CNode]348{[0]: ValueNode<FuncGraph> 57_↓scale_grad.724, [1]: gradients}
#   2: 56_✗scale_grad.726:[CNode]438{[0]: ValueNode<Primitive> Return, [1]: [CNode]348}


# [No.51] 63_hyper_map.638

funcgraph fg_638[fg_621](
        %para90 : Func    # [Parameter]784
        , %para91 : Tensor(F32)[6, 1, 5, 5]    # [Parameter]622
        , %para92 : Ref[Tensor(F32)][6, 1, 5, 5]    # [Parameter]623
        , %para93 : Ref[Tensor(F32)][6, 1, 5, 5]    # [Parameter]624
        , %para94 : Bool    # [Parameter]785
        , %para95 : Bool    # [Parameter]786
    ) {
    %1 : $(53_construct.621):Ref[Tensor(F32)][] = FuncGraph::fg_617()    # fg_617=58_get_lr.617 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(176)/        lr = self.get_lr()/#lr
    %2 : Func = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_620, DoSignaturePrimitive::S-Prim-ApplyMomentum{prim_type=1}[output_names=["output"], side_effect_mem=Bool(1), use_nesterov=Bool(0), input_names=["variable", "accumulation", "learning_rate", "gradient", "momentum"], use_locking=Bool(0), gradient_scale=F32(1)], %para19, %1)    #(Func, Func, Ref[Tensor(F32)][], Ref[Tensor(F32)][])    # fg_620=64_619.620 #scope: Default/optimizer-Momentum
#[CNode]618
    %3 : Bool = %2(%para91, %para92, %para93, Bool(0), Bool(0))    #(Tensor(F32)[6, 1, 5, 5], Ref[Tensor(F32)][6, 1, 5, 5], Ref[Tensor(F32)][6, 1, 5, 5], Bool, Bool) #scope: Default/optimizer-Momentum
#[CNode]609
    Primitive::Return{prim_type=1}(%3)    #(Bool) #scope: Default/optimizer-Momentum
#[CNode]818
}
# order:
#   1: 63_hyper_map.638:[CNode]609{[0]: [CNode]618, [1]: [Parameter]622, [2]: [Parameter]623, [3]: [Parameter]624, [4]: ValueNode<BoolImm> false, [5]: ValueNode<BoolImm> false}
#   2: 63_hyper_map.638:[CNode]818{[0]: ValueNode<Primitive> Return, [1]: [CNode]609}


# [No.52] 68_hyper_map.651

funcgraph fg_651[fg_621](
        %para96 : Func    # [Parameter]784
        , %para97 : Tensor(F32)[16, 6, 5, 5]    # [Parameter]622
        , %para98 : Ref[Tensor(F32)][16, 6, 5, 5]    # [Parameter]623
        , %para99 : Ref[Tensor(F32)][16, 6, 5, 5]    # [Parameter]624
        , %para100 : Bool    # [Parameter]785
        , %para101 : Bool    # [Parameter]786
    ) {
    %1 : $(53_construct.621):Ref[Tensor(F32)][] = FuncGraph::fg_617()    # fg_617=58_get_lr.617 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(176)/        lr = self.get_lr()/#lr
    %2 : Func = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_650, DoSignaturePrimitive::S-Prim-ApplyMomentum{prim_type=1}[output_names=["output"], side_effect_mem=Bool(1), use_nesterov=Bool(0), input_names=["variable", "accumulation", "learning_rate", "gradient", "momentum"], use_locking=Bool(0), gradient_scale=F32(1)], %para19, %1)    #(Func, Func, Ref[Tensor(F32)][], Ref[Tensor(F32)][])    # fg_650=69_649.650 #scope: Default/optimizer-Momentum
#[CNode]648
    %3 : Bool = %2(%para97, %para98, %para99, Bool(0), Bool(0))    #(Tensor(F32)[16, 6, 5, 5], Ref[Tensor(F32)][16, 6, 5, 5], Ref[Tensor(F32)][16, 6, 5, 5], Bool, Bool) #scope: Default/optimizer-Momentum
#[CNode]609
    Primitive::Return{prim_type=1}(%3)    #(Bool) #scope: Default/optimizer-Momentum
#[CNode]818
}
# order:
#   1: 68_hyper_map.651:[CNode]609{[0]: [CNode]648, [1]: [Parameter]622, [2]: [Parameter]623, [3]: [Parameter]624, [4]: ValueNode<BoolImm> false, [5]: ValueNode<BoolImm> false}
#   2: 68_hyper_map.651:[CNode]818{[0]: ValueNode<Primitive> Return, [1]: [CNode]609}


# [No.53] 73_hyper_map.663

funcgraph fg_663[fg_621](
        %para102 : Func    # [Parameter]784
        , %para103 : Tensor(F32)[120, 400]    # [Parameter]622
        , %para104 : Ref[Tensor(F32)][120, 400]    # [Parameter]623
        , %para105 : Ref[Tensor(F32)][120, 400]    # [Parameter]624
        , %para106 : Bool    # [Parameter]785
        , %para107 : Bool    # [Parameter]786
    ) {
    %1 : $(53_construct.621):Ref[Tensor(F32)][] = FuncGraph::fg_617()    # fg_617=58_get_lr.617 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(176)/        lr = self.get_lr()/#lr
    %2 : Func = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_662, DoSignaturePrimitive::S-Prim-ApplyMomentum{prim_type=1}[output_names=["output"], side_effect_mem=Bool(1), use_nesterov=Bool(0), input_names=["variable", "accumulation", "learning_rate", "gradient", "momentum"], use_locking=Bool(0), gradient_scale=F32(1)], %para19, %1)    #(Func, Func, Ref[Tensor(F32)][], Ref[Tensor(F32)][])    # fg_662=74_661.662 #scope: Default/optimizer-Momentum
#[CNode]660
    %3 : Bool = %2(%para103, %para104, %para105, Bool(0), Bool(0))    #(Tensor(F32)[120, 400], Ref[Tensor(F32)][120, 400], Ref[Tensor(F32)][120, 400], Bool, Bool) #scope: Default/optimizer-Momentum
#[CNode]609
    Primitive::Return{prim_type=1}(%3)    #(Bool) #scope: Default/optimizer-Momentum
#[CNode]818
}
# order:
#   1: 73_hyper_map.663:[CNode]609{[0]: [CNode]660, [1]: [Parameter]622, [2]: [Parameter]623, [3]: [Parameter]624, [4]: ValueNode<BoolImm> false, [5]: ValueNode<BoolImm> false}
#   2: 73_hyper_map.663:[CNode]818{[0]: ValueNode<Primitive> Return, [1]: [CNode]609}


# [No.54] 78_hyper_map.675

funcgraph fg_675[fg_621](
        %para108 : Func    # [Parameter]784
        , %para109 : Tensor(F32)[120]    # [Parameter]622
        , %para110 : Ref[Tensor(F32)][120]    # [Parameter]623
        , %para111 : Ref[Tensor(F32)][120]    # [Parameter]624
        , %para112 : Bool    # [Parameter]785
        , %para113 : Bool    # [Parameter]786
    ) {
    %1 : $(53_construct.621):Ref[Tensor(F32)][] = FuncGraph::fg_617()    # fg_617=58_get_lr.617 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(176)/        lr = self.get_lr()/#lr
    %2 : Func = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_674, DoSignaturePrimitive::S-Prim-ApplyMomentum{prim_type=1}[output_names=["output"], side_effect_mem=Bool(1), use_nesterov=Bool(0), input_names=["variable", "accumulation", "learning_rate", "gradient", "momentum"], use_locking=Bool(0), gradient_scale=F32(1)], %para19, %1)    #(Func, Func, Ref[Tensor(F32)][], Ref[Tensor(F32)][])    # fg_674=79_673.674 #scope: Default/optimizer-Momentum
#[CNode]672
    %3 : Bool = %2(%para109, %para110, %para111, Bool(0), Bool(0))    #(Tensor(F32)[120], Ref[Tensor(F32)][120], Ref[Tensor(F32)][120], Bool, Bool) #scope: Default/optimizer-Momentum
#[CNode]609
    Primitive::Return{prim_type=1}(%3)    #(Bool) #scope: Default/optimizer-Momentum
#[CNode]818
}
# order:
#   1: 78_hyper_map.675:[CNode]609{[0]: [CNode]672, [1]: [Parameter]622, [2]: [Parameter]623, [3]: [Parameter]624, [4]: ValueNode<BoolImm> false, [5]: ValueNode<BoolImm> false}
#   2: 78_hyper_map.675:[CNode]818{[0]: ValueNode<Primitive> Return, [1]: [CNode]609}


# [No.55] 83_hyper_map.687

funcgraph fg_687[fg_621](
        %para114 : Func    # [Parameter]784
        , %para115 : Tensor(F32)[84, 120]    # [Parameter]622
        , %para116 : Ref[Tensor(F32)][84, 120]    # [Parameter]623
        , %para117 : Ref[Tensor(F32)][84, 120]    # [Parameter]624
        , %para118 : Bool    # [Parameter]785
        , %para119 : Bool    # [Parameter]786
    ) {
    %1 : $(53_construct.621):Ref[Tensor(F32)][] = FuncGraph::fg_617()    # fg_617=58_get_lr.617 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(176)/        lr = self.get_lr()/#lr
    %2 : Func = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_686, DoSignaturePrimitive::S-Prim-ApplyMomentum{prim_type=1}[output_names=["output"], side_effect_mem=Bool(1), use_nesterov=Bool(0), input_names=["variable", "accumulation", "learning_rate", "gradient", "momentum"], use_locking=Bool(0), gradient_scale=F32(1)], %para19, %1)    #(Func, Func, Ref[Tensor(F32)][], Ref[Tensor(F32)][])    # fg_686=84_685.686 #scope: Default/optimizer-Momentum
#[CNode]684
    %3 : Bool = %2(%para115, %para116, %para117, Bool(0), Bool(0))    #(Tensor(F32)[84, 120], Ref[Tensor(F32)][84, 120], Ref[Tensor(F32)][84, 120], Bool, Bool) #scope: Default/optimizer-Momentum
#[CNode]609
    Primitive::Return{prim_type=1}(%3)    #(Bool) #scope: Default/optimizer-Momentum
#[CNode]818
}
# order:
#   1: 83_hyper_map.687:[CNode]609{[0]: [CNode]684, [1]: [Parameter]622, [2]: [Parameter]623, [3]: [Parameter]624, [4]: ValueNode<BoolImm> false, [5]: ValueNode<BoolImm> false}
#   2: 83_hyper_map.687:[CNode]818{[0]: ValueNode<Primitive> Return, [1]: [CNode]609}


# [No.56] 88_hyper_map.699

funcgraph fg_699[fg_621](
        %para120 : Func    # [Parameter]784
        , %para121 : Tensor(F32)[84]    # [Parameter]622
        , %para122 : Ref[Tensor(F32)][84]    # [Parameter]623
        , %para123 : Ref[Tensor(F32)][84]    # [Parameter]624
        , %para124 : Bool    # [Parameter]785
        , %para125 : Bool    # [Parameter]786
    ) {
    %1 : $(53_construct.621):Ref[Tensor(F32)][] = FuncGraph::fg_617()    # fg_617=58_get_lr.617 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(176)/        lr = self.get_lr()/#lr
    %2 : Func = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_698, DoSignaturePrimitive::S-Prim-ApplyMomentum{prim_type=1}[output_names=["output"], side_effect_mem=Bool(1), use_nesterov=Bool(0), input_names=["variable", "accumulation", "learning_rate", "gradient", "momentum"], use_locking=Bool(0), gradient_scale=F32(1)], %para19, %1)    #(Func, Func, Ref[Tensor(F32)][], Ref[Tensor(F32)][])    # fg_698=89_697.698 #scope: Default/optimizer-Momentum
#[CNode]696
    %3 : Bool = %2(%para121, %para122, %para123, Bool(0), Bool(0))    #(Tensor(F32)[84], Ref[Tensor(F32)][84], Ref[Tensor(F32)][84], Bool, Bool) #scope: Default/optimizer-Momentum
#[CNode]609
    Primitive::Return{prim_type=1}(%3)    #(Bool) #scope: Default/optimizer-Momentum
#[CNode]818
}
# order:
#   1: 88_hyper_map.699:[CNode]609{[0]: [CNode]696, [1]: [Parameter]622, [2]: [Parameter]623, [3]: [Parameter]624, [4]: ValueNode<BoolImm> false, [5]: ValueNode<BoolImm> false}
#   2: 88_hyper_map.699:[CNode]818{[0]: ValueNode<Primitive> Return, [1]: [CNode]609}


# [No.57] 93_hyper_map.711

funcgraph fg_711[fg_621](
        %para126 : Func    # [Parameter]784
        , %para127 : Tensor(F32)[10, 84]    # [Parameter]622
        , %para128 : Ref[Tensor(F32)][10, 84]    # [Parameter]623
        , %para129 : Ref[Tensor(F32)][10, 84]    # [Parameter]624
        , %para130 : Bool    # [Parameter]785
        , %para131 : Bool    # [Parameter]786
    ) {
    %1 : $(53_construct.621):Ref[Tensor(F32)][] = FuncGraph::fg_617()    # fg_617=58_get_lr.617 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(176)/        lr = self.get_lr()/#lr
    %2 : Func = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_710, DoSignaturePrimitive::S-Prim-ApplyMomentum{prim_type=1}[output_names=["output"], side_effect_mem=Bool(1), use_nesterov=Bool(0), input_names=["variable", "accumulation", "learning_rate", "gradient", "momentum"], use_locking=Bool(0), gradient_scale=F32(1)], %para19, %1)    #(Func, Func, Ref[Tensor(F32)][], Ref[Tensor(F32)][])    # fg_710=94_709.710 #scope: Default/optimizer-Momentum
#[CNode]708
    %3 : Bool = %2(%para127, %para128, %para129, Bool(0), Bool(0))    #(Tensor(F32)[10, 84], Ref[Tensor(F32)][10, 84], Ref[Tensor(F32)][10, 84], Bool, Bool) #scope: Default/optimizer-Momentum
#[CNode]609
    Primitive::Return{prim_type=1}(%3)    #(Bool) #scope: Default/optimizer-Momentum
#[CNode]818
}
# order:
#   1: 93_hyper_map.711:[CNode]609{[0]: [CNode]708, [1]: [Parameter]622, [2]: [Parameter]623, [3]: [Parameter]624, [4]: ValueNode<BoolImm> false, [5]: ValueNode<BoolImm> false}
#   2: 93_hyper_map.711:[CNode]818{[0]: ValueNode<Primitive> Return, [1]: [CNode]609}


# [No.58] 98_hyper_map.723

funcgraph fg_723[fg_621](
        %para132 : Func    # [Parameter]784
        , %para133 : Tensor(F32)[10]    # [Parameter]622
        , %para134 : Ref[Tensor(F32)][10]    # [Parameter]623
        , %para135 : Ref[Tensor(F32)][10]    # [Parameter]624
        , %para136 : Bool    # [Parameter]785
        , %para137 : Bool    # [Parameter]786
    ) {
    %1 : $(53_construct.621):Ref[Tensor(F32)][] = FuncGraph::fg_617()    # fg_617=58_get_lr.617 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(176)/        lr = self.get_lr()/#lr
    %2 : Func = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_722, DoSignaturePrimitive::S-Prim-ApplyMomentum{prim_type=1}[output_names=["output"], side_effect_mem=Bool(1), use_nesterov=Bool(0), input_names=["variable", "accumulation", "learning_rate", "gradient", "momentum"], use_locking=Bool(0), gradient_scale=F32(1)], %para19, %1)    #(Func, Func, Ref[Tensor(F32)][], Ref[Tensor(F32)][])    # fg_722=99_721.722 #scope: Default/optimizer-Momentum
#[CNode]720
    %3 : Bool = %2(%para133, %para134, %para135, Bool(0), Bool(0))    #(Tensor(F32)[10], Ref[Tensor(F32)][10], Ref[Tensor(F32)][10], Bool, Bool) #scope: Default/optimizer-Momentum
#[CNode]609
    Primitive::Return{prim_type=1}(%3)    #(Bool) #scope: Default/optimizer-Momentum
#[CNode]818
}
# order:
#   1: 98_hyper_map.723:[CNode]609{[0]: [CNode]720, [1]: [Parameter]622, [2]: [Parameter]623, [3]: [Parameter]624, [4]: ValueNode<BoolImm> false, [5]: ValueNode<BoolImm> false}
#   2: 98_hyper_map.723:[CNode]818{[0]: ValueNode<Primitive> Return, [1]: [CNode]609}


# [No.59] 52_↓construct.586
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
funcgraph fg_586(
        %para138 : Tensor(F32)[32, 6, 28, 28]    # Φoutput
    ) {
    Primitive::Return{prim_type=1}(%para138)    #(Tensor(F32)[32, 6, 28, 28]) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(269)/        return output/#[CNode]439
}
# order:
#   1: 52_↓construct.586:[CNode]439{[0]: ValueNode<Primitive> Return, [1]: Φoutput}


# [No.60] 47_↓construct.583
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
funcgraph fg_583(
        %para139 : Tensor(F32)[32, 16, 10, 10]    # Φoutput
    ) {
    Primitive::Return{prim_type=1}(%para139)    #(Tensor(F32)[32, 16, 10, 10]) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(269)/        return output/#[CNode]440
}
# order:
#   1: 47_↓construct.583:[CNode]440{[0]: ValueNode<Primitive> Return, [1]: Φoutput}


# [No.61] 34_L-✗construct.581
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
funcgraph fg_581[fg_578](
) {
    %1 : Tensor(F32)[32, 120] = FuncGraph::fg_579(%para65)    #(Tensor(F32)[32, 400])    # fg_579=35_L-↓construct.579 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]142
    Primitive::Return{prim_type=1}(%1)    #(Tensor(F32)[32, 120]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]427
}
# order:
#   1: 34_L-✗construct.581:[CNode]142{[0]: ValueNode<FuncGraph> 35_L-↓construct.579, [1]: x}
#   2: 34_L-✗construct.581:[CNode]427{[0]: ValueNode<Primitive> Return, [1]: [CNode]142}


# [No.62] 23_L-✗construct.572
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
funcgraph fg_572[fg_569](
) {
    %1 : Tensor(F32)[32, 84] = FuncGraph::fg_570(%para68)    #(Tensor(F32)[32, 120])    # fg_570=24_L-↓construct.570 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]142
    Primitive::Return{prim_type=1}(%1)    #(Tensor(F32)[32, 84]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]427
}
# order:
#   1: 23_L-✗construct.572:[CNode]142{[0]: ValueNode<FuncGraph> 24_L-↓construct.570, [1]: x}
#   2: 23_L-✗construct.572:[CNode]427{[0]: ValueNode<Primitive> Return, [1]: [CNode]142}


# [No.63] 12_L-✗construct.563
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
funcgraph fg_563[fg_560](
) {
    %1 : Tensor(F32)[32, 10] = FuncGraph::fg_561(%para71)    #(Tensor(F32)[32, 84])    # fg_561=13_L-↓construct.561 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]142
    Primitive::Return{prim_type=1}(%1)    #(Tensor(F32)[32, 10]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]427
}
# order:
#   1: 12_L-✗construct.563:[CNode]142{[0]: ValueNode<FuncGraph> 13_L-↓construct.561, [1]: x}
#   2: 12_L-✗construct.563:[CNode]427{[0]: ValueNode<Primitive> Return, [1]: [CNode]142}


# [No.64] 114__tensor_env_get.744
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\ops\composite\base.py(865)/def _tensor_env_get(env, parameter):/
funcgraph fg_744(
        %para140 : EnvType    # env
        , %para141 : Ref[Tensor(F32)][6, 1, 5, 5]    # parameter
    ) {
    %1 : SymType = PrimitivePy::RefToEmbed{prim_type=1}(%para141)    #(Ref[Tensor(F32)][6, 1, 5, 5]) #scope: Default
#[CNode]741
    %2 : Tensor(F32)[6, 1, 5, 5] = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%para141)    #(Ref[Tensor(F32)][6, 1, 5, 5]) #scope: Default
#[CNode]741
    %3 : Tensor(F32)[6, 1, 5, 5] = PrimitivePy::EnvironGet{prim_type=1}(%para140, %1, %2)    #(EnvType, SymType, Tensor(F32)[6, 1, 5, 5]) #scope: Default
#[CNode]741
    Primitive::Return{prim_type=1}(%3)    #(Tensor(F32)[6, 1, 5, 5]) #scope: Default
#[CNode]741
}
# order:
#   1: 114__tensor_env_get.744:[CNode]741{[0]: ValueNode<PrimitivePy> RefToEmbed, [1]: parameter}
#   2: 114__tensor_env_get.744:[CNode]741{[0]: ValueNode<PrimitivePy> ZerosLike, [1]: parameter}
#   3: 114__tensor_env_get.744:[CNode]741{[0]: ValueNode<PrimitivePy> EnvironGet, [1]: env, [2]: [CNode]741, [3]: [CNode]741}
#   4: 114__tensor_env_get.744:[CNode]741{[0]: ValueNode<Primitive> Return, [1]: [CNode]741}


# [No.65] 116__tensor_env_get.751
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\ops\composite\base.py(865)/def _tensor_env_get(env, parameter):/
funcgraph fg_751(
        %para142 : EnvType    # env
        , %para143 : Ref[Tensor(F32)][16, 6, 5, 5]    # parameter
    ) {
    %1 : SymType = PrimitivePy::RefToEmbed{prim_type=1}(%para143)    #(Ref[Tensor(F32)][16, 6, 5, 5]) #scope: Default
#[CNode]741
    %2 : Tensor(F32)[16, 6, 5, 5] = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%para143)    #(Ref[Tensor(F32)][16, 6, 5, 5]) #scope: Default
#[CNode]741
    %3 : Tensor(F32)[16, 6, 5, 5] = PrimitivePy::EnvironGet{prim_type=1}(%para142, %1, %2)    #(EnvType, SymType, Tensor(F32)[16, 6, 5, 5]) #scope: Default
#[CNode]741
    Primitive::Return{prim_type=1}(%3)    #(Tensor(F32)[16, 6, 5, 5]) #scope: Default
#[CNode]741
}
# order:
#   1: 116__tensor_env_get.751:[CNode]741{[0]: ValueNode<PrimitivePy> RefToEmbed, [1]: parameter}
#   2: 116__tensor_env_get.751:[CNode]741{[0]: ValueNode<PrimitivePy> ZerosLike, [1]: parameter}
#   3: 116__tensor_env_get.751:[CNode]741{[0]: ValueNode<PrimitivePy> EnvironGet, [1]: env, [2]: [CNode]741, [3]: [CNode]741}
#   4: 116__tensor_env_get.751:[CNode]741{[0]: ValueNode<Primitive> Return, [1]: [CNode]741}


# [No.66] 118__tensor_env_get.755
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\ops\composite\base.py(865)/def _tensor_env_get(env, parameter):/
funcgraph fg_755(
        %para144 : EnvType    # env
        , %para145 : Ref[Tensor(F32)][120, 400]    # parameter
    ) {
    %1 : SymType = PrimitivePy::RefToEmbed{prim_type=1}(%para145)    #(Ref[Tensor(F32)][120, 400]) #scope: Default
#[CNode]741
    %2 : Tensor(F32)[120, 400] = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%para145)    #(Ref[Tensor(F32)][120, 400]) #scope: Default
#[CNode]741
    %3 : Tensor(F32)[120, 400] = PrimitivePy::EnvironGet{prim_type=1}(%para144, %1, %2)    #(EnvType, SymType, Tensor(F32)[120, 400]) #scope: Default
#[CNode]741
    Primitive::Return{prim_type=1}(%3)    #(Tensor(F32)[120, 400]) #scope: Default
#[CNode]741
}
# order:
#   1: 118__tensor_env_get.755:[CNode]741{[0]: ValueNode<PrimitivePy> RefToEmbed, [1]: parameter}
#   2: 118__tensor_env_get.755:[CNode]741{[0]: ValueNode<PrimitivePy> ZerosLike, [1]: parameter}
#   3: 118__tensor_env_get.755:[CNode]741{[0]: ValueNode<PrimitivePy> EnvironGet, [1]: env, [2]: [CNode]741, [3]: [CNode]741}
#   4: 118__tensor_env_get.755:[CNode]741{[0]: ValueNode<Primitive> Return, [1]: [CNode]741}


# [No.67] 120__tensor_env_get.759
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\ops\composite\base.py(865)/def _tensor_env_get(env, parameter):/
funcgraph fg_759(
        %para146 : EnvType    # env
        , %para147 : Ref[Tensor(F32)][120]    # parameter
    ) {
    %1 : SymType = PrimitivePy::RefToEmbed{prim_type=1}(%para147)    #(Ref[Tensor(F32)][120]) #scope: Default
#[CNode]741
    %2 : Tensor(F32)[120] = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%para147)    #(Ref[Tensor(F32)][120]) #scope: Default
#[CNode]741
    %3 : Tensor(F32)[120] = PrimitivePy::EnvironGet{prim_type=1}(%para146, %1, %2)    #(EnvType, SymType, Tensor(F32)[120]) #scope: Default
#[CNode]741
    Primitive::Return{prim_type=1}(%3)    #(Tensor(F32)[120]) #scope: Default
#[CNode]741
}
# order:
#   1: 120__tensor_env_get.759:[CNode]741{[0]: ValueNode<PrimitivePy> RefToEmbed, [1]: parameter}
#   2: 120__tensor_env_get.759:[CNode]741{[0]: ValueNode<PrimitivePy> ZerosLike, [1]: parameter}
#   3: 120__tensor_env_get.759:[CNode]741{[0]: ValueNode<PrimitivePy> EnvironGet, [1]: env, [2]: [CNode]741, [3]: [CNode]741}
#   4: 120__tensor_env_get.759:[CNode]741{[0]: ValueNode<Primitive> Return, [1]: [CNode]741}


# [No.68] 122__tensor_env_get.763
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\ops\composite\base.py(865)/def _tensor_env_get(env, parameter):/
funcgraph fg_763(
        %para148 : EnvType    # env
        , %para149 : Ref[Tensor(F32)][84, 120]    # parameter
    ) {
    %1 : SymType = PrimitivePy::RefToEmbed{prim_type=1}(%para149)    #(Ref[Tensor(F32)][84, 120]) #scope: Default
#[CNode]741
    %2 : Tensor(F32)[84, 120] = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%para149)    #(Ref[Tensor(F32)][84, 120]) #scope: Default
#[CNode]741
    %3 : Tensor(F32)[84, 120] = PrimitivePy::EnvironGet{prim_type=1}(%para148, %1, %2)    #(EnvType, SymType, Tensor(F32)[84, 120]) #scope: Default
#[CNode]741
    Primitive::Return{prim_type=1}(%3)    #(Tensor(F32)[84, 120]) #scope: Default
#[CNode]741
}
# order:
#   1: 122__tensor_env_get.763:[CNode]741{[0]: ValueNode<PrimitivePy> RefToEmbed, [1]: parameter}
#   2: 122__tensor_env_get.763:[CNode]741{[0]: ValueNode<PrimitivePy> ZerosLike, [1]: parameter}
#   3: 122__tensor_env_get.763:[CNode]741{[0]: ValueNode<PrimitivePy> EnvironGet, [1]: env, [2]: [CNode]741, [3]: [CNode]741}
#   4: 122__tensor_env_get.763:[CNode]741{[0]: ValueNode<Primitive> Return, [1]: [CNode]741}


# [No.69] 124__tensor_env_get.767
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\ops\composite\base.py(865)/def _tensor_env_get(env, parameter):/
funcgraph fg_767(
        %para150 : EnvType    # env
        , %para151 : Ref[Tensor(F32)][84]    # parameter
    ) {
    %1 : SymType = PrimitivePy::RefToEmbed{prim_type=1}(%para151)    #(Ref[Tensor(F32)][84]) #scope: Default
#[CNode]741
    %2 : Tensor(F32)[84] = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%para151)    #(Ref[Tensor(F32)][84]) #scope: Default
#[CNode]741
    %3 : Tensor(F32)[84] = PrimitivePy::EnvironGet{prim_type=1}(%para150, %1, %2)    #(EnvType, SymType, Tensor(F32)[84]) #scope: Default
#[CNode]741
    Primitive::Return{prim_type=1}(%3)    #(Tensor(F32)[84]) #scope: Default
#[CNode]741
}
# order:
#   1: 124__tensor_env_get.767:[CNode]741{[0]: ValueNode<PrimitivePy> RefToEmbed, [1]: parameter}
#   2: 124__tensor_env_get.767:[CNode]741{[0]: ValueNode<PrimitivePy> ZerosLike, [1]: parameter}
#   3: 124__tensor_env_get.767:[CNode]741{[0]: ValueNode<PrimitivePy> EnvironGet, [1]: env, [2]: [CNode]741, [3]: [CNode]741}
#   4: 124__tensor_env_get.767:[CNode]741{[0]: ValueNode<Primitive> Return, [1]: [CNode]741}


# [No.70] 126__tensor_env_get.771
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\ops\composite\base.py(865)/def _tensor_env_get(env, parameter):/
funcgraph fg_771(
        %para152 : EnvType    # env
        , %para153 : Ref[Tensor(F32)][10, 84]    # parameter
    ) {
    %1 : SymType = PrimitivePy::RefToEmbed{prim_type=1}(%para153)    #(Ref[Tensor(F32)][10, 84]) #scope: Default
#[CNode]741
    %2 : Tensor(F32)[10, 84] = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%para153)    #(Ref[Tensor(F32)][10, 84]) #scope: Default
#[CNode]741
    %3 : Tensor(F32)[10, 84] = PrimitivePy::EnvironGet{prim_type=1}(%para152, %1, %2)    #(EnvType, SymType, Tensor(F32)[10, 84]) #scope: Default
#[CNode]741
    Primitive::Return{prim_type=1}(%3)    #(Tensor(F32)[10, 84]) #scope: Default
#[CNode]741
}
# order:
#   1: 126__tensor_env_get.771:[CNode]741{[0]: ValueNode<PrimitivePy> RefToEmbed, [1]: parameter}
#   2: 126__tensor_env_get.771:[CNode]741{[0]: ValueNode<PrimitivePy> ZerosLike, [1]: parameter}
#   3: 126__tensor_env_get.771:[CNode]741{[0]: ValueNode<PrimitivePy> EnvironGet, [1]: env, [2]: [CNode]741, [3]: [CNode]741}
#   4: 126__tensor_env_get.771:[CNode]741{[0]: ValueNode<Primitive> Return, [1]: [CNode]741}


# [No.71] 128__tensor_env_get.775
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\ops\composite\base.py(865)/def _tensor_env_get(env, parameter):/
funcgraph fg_775(
        %para154 : EnvType    # env
        , %para155 : Ref[Tensor(F32)][10]    # parameter
    ) {
    %1 : SymType = PrimitivePy::RefToEmbed{prim_type=1}(%para155)    #(Ref[Tensor(F32)][10]) #scope: Default
#[CNode]741
    %2 : Tensor(F32)[10] = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%para155)    #(Ref[Tensor(F32)][10]) #scope: Default
#[CNode]741
    %3 : Tensor(F32)[10] = PrimitivePy::EnvironGet{prim_type=1}(%para154, %1, %2)    #(EnvType, SymType, Tensor(F32)[10]) #scope: Default
#[CNode]741
    Primitive::Return{prim_type=1}(%3)    #(Tensor(F32)[10]) #scope: Default
#[CNode]741
}
# order:
#   1: 128__tensor_env_get.775:[CNode]741{[0]: ValueNode<PrimitivePy> RefToEmbed, [1]: parameter}
#   2: 128__tensor_env_get.775:[CNode]741{[0]: ValueNode<PrimitivePy> ZerosLike, [1]: parameter}
#   3: 128__tensor_env_get.775:[CNode]741{[0]: ValueNode<PrimitivePy> EnvironGet, [1]: env, [2]: [CNode]741, [3]: [CNode]741}
#   4: 128__tensor_env_get.775:[CNode]741{[0]: ValueNode<Primitive> Return, [1]: [CNode]741}


# [No.72] 60_↓get_lr.615
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(587)/        if self.dynamic_lr:/
funcgraph fg_615(
        %para156 : Ref[Tensor(F32)][]    # Φlr
    ) {
    Primitive::Return{prim_type=1}(%para156)    #(Ref[Tensor(F32)][]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(597)/        return lr/#[CNode]448
}
# order:
#   1: 60_↓get_lr.615:[CNode]448{[0]: ValueNode<Primitive> Return, [1]: Φlr}


# [No.73] 108_↓decay_weight.730
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(317)/        if self.exec_weight_decay:/
funcgraph fg_730(
        %para157 : Tuple[Tensor(F32)*8]    # Φgradients
    ) {
    Primitive::Return{prim_type=1}(%para157)    #(Tuple[Tensor(F32)*8]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(326)/        return gradients/#[CNode]451
}
# order:
#   1: 108_↓decay_weight.730:[CNode]451{[0]: ValueNode<Primitive> Return, [1]: Φgradients}


# [No.74] 105_↓gradients_centralization.727
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(342)/        if self.is_group:/
funcgraph fg_727(
        %para158 : Tuple[Tensor(F32)*8]    # Φgradients
    ) {
    Primitive::Return{prim_type=1}(%para158)    #(Tuple[Tensor(F32)*8]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(345)/        return gradients/#[CNode]452
}
# order:
#   1: 105_↓gradients_centralization.727:[CNode]452{[0]: ValueNode<Primitive> Return, [1]: Φgradients}


# [No.75] 57_↓scale_grad.724
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(361)/        if self.need_scale:/
funcgraph fg_724(
        %para159 : Tuple[Tensor(F32)*8]    # Φgradients
    ) {
    Primitive::Return{prim_type=1}(%para159)    #(Tuple[Tensor(F32)*8]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(364)/        return gradients/#[CNode]453
}
# order:
#   1: 57_↓scale_grad.724:[CNode]453{[0]: ValueNode<Primitive> Return, [1]: Φgradients}


# [No.76] 64_619.620

funcgraph fg_620(
        %para160 : Func    # 781
        , %para161 : Ref[Tensor(F32)][]    # 610
        , %para162 : Ref[Tensor(F32)][]    # 611
        , %para163 : Tensor(F32)[6, 1, 5, 5]    # 612
        , %para164 : Ref[Tensor(F32)][6, 1, 5, 5]    # 613
        , %para165 : Ref[Tensor(F32)][6, 1, 5, 5]    # 614
        , %para166 : Bool    # 782
        , %para167 : Bool    # 783
    ) {
    %1 : Bool = FuncGraph::fg_603("PolyNode", %para161, %para162, %para163, %para164, %para165, Bool(0), Bool(0))    #(ProblemType, Ref[Tensor(F32)][], Ref[Tensor(F32)][], Tensor(F32)[6, 1, 5, 5], Ref[Tensor(F32)][6, 1, 5, 5], Ref[Tensor(F32)][6, 1, 5, 5], Bool, Bool)    # fg_603=65__tensor_run_opt_ext.603 #scope: Default/optimizer-Momentum
#[CNode]609
    Primitive::Return{prim_type=1}(%1)    #(Bool) #scope: Default/optimizer-Momentum
#[CNode]609
}
# order:
#   1: 64_619.620:[CNode]609{[0]: ValueNode<FuncGraph> 65__tensor_run_opt_ext.603, [1]: ValueNode<StringImm> PolyNode, [2]: 610, [3]: 611, [4]: 612, [5]: 613, [6]: 614, [7]: ValueNode<BoolImm> false, [8]: ValueNode<BoolImm> false}
#   2: 64_619.620:[CNode]609{[0]: ValueNode<Primitive> Return, [1]: [CNode]609}


# [No.77] 69_649.650

funcgraph fg_650(
        %para168 : Func    # 789
        , %para169 : Ref[Tensor(F32)][]    # 643
        , %para170 : Ref[Tensor(F32)][]    # 644
        , %para171 : Tensor(F32)[16, 6, 5, 5]    # 645
        , %para172 : Ref[Tensor(F32)][16, 6, 5, 5]    # 646
        , %para173 : Ref[Tensor(F32)][16, 6, 5, 5]    # 647
        , %para174 : Bool    # 790
        , %para175 : Bool    # 791
    ) {
    %1 : Bool = FuncGraph::fg_640("PolyNode", %para169, %para170, %para171, %para172, %para173, Bool(0), Bool(0))    #(ProblemType, Ref[Tensor(F32)][], Ref[Tensor(F32)][], Tensor(F32)[16, 6, 5, 5], Ref[Tensor(F32)][16, 6, 5, 5], Ref[Tensor(F32)][16, 6, 5, 5], Bool, Bool)    # fg_640=70__tensor_run_opt_ext.640 #scope: Default/optimizer-Momentum
#[CNode]609
    Primitive::Return{prim_type=1}(%1)    #(Bool) #scope: Default/optimizer-Momentum
#[CNode]609
}
# order:
#   1: 69_649.650:[CNode]609{[0]: ValueNode<FuncGraph> 70__tensor_run_opt_ext.640, [1]: ValueNode<StringImm> PolyNode, [2]: 643, [3]: 644, [4]: 645, [5]: 646, [6]: 647, [7]: ValueNode<BoolImm> false, [8]: ValueNode<BoolImm> false}
#   2: 69_649.650:[CNode]609{[0]: ValueNode<Primitive> Return, [1]: [CNode]609}


# [No.78] 74_661.662

funcgraph fg_662(
        %para176 : Func    # 792
        , %para177 : Ref[Tensor(F32)][]    # 655
        , %para178 : Ref[Tensor(F32)][]    # 656
        , %para179 : Tensor(F32)[120, 400]    # 657
        , %para180 : Ref[Tensor(F32)][120, 400]    # 658
        , %para181 : Ref[Tensor(F32)][120, 400]    # 659
        , %para182 : Bool    # 793
        , %para183 : Bool    # 794
    ) {
    %1 : Bool = FuncGraph::fg_652("PolyNode", %para177, %para178, %para179, %para180, %para181, Bool(0), Bool(0))    #(ProblemType, Ref[Tensor(F32)][], Ref[Tensor(F32)][], Tensor(F32)[120, 400], Ref[Tensor(F32)][120, 400], Ref[Tensor(F32)][120, 400], Bool, Bool)    # fg_652=75__tensor_run_opt_ext.652 #scope: Default/optimizer-Momentum
#[CNode]609
    Primitive::Return{prim_type=1}(%1)    #(Bool) #scope: Default/optimizer-Momentum
#[CNode]609
}
# order:
#   1: 74_661.662:[CNode]609{[0]: ValueNode<FuncGraph> 75__tensor_run_opt_ext.652, [1]: ValueNode<StringImm> PolyNode, [2]: 655, [3]: 656, [4]: 657, [5]: 658, [6]: 659, [7]: ValueNode<BoolImm> false, [8]: ValueNode<BoolImm> false}
#   2: 74_661.662:[CNode]609{[0]: ValueNode<Primitive> Return, [1]: [CNode]609}


# [No.79] 79_673.674

funcgraph fg_674(
        %para184 : Func    # 795
        , %para185 : Ref[Tensor(F32)][]    # 667
        , %para186 : Ref[Tensor(F32)][]    # 668
        , %para187 : Tensor(F32)[120]    # 669
        , %para188 : Ref[Tensor(F32)][120]    # 670
        , %para189 : Ref[Tensor(F32)][120]    # 671
        , %para190 : Bool    # 796
        , %para191 : Bool    # 797
    ) {
    %1 : Bool = FuncGraph::fg_664("PolyNode", %para185, %para186, %para187, %para188, %para189, Bool(0), Bool(0))    #(ProblemType, Ref[Tensor(F32)][], Ref[Tensor(F32)][], Tensor(F32)[120], Ref[Tensor(F32)][120], Ref[Tensor(F32)][120], Bool, Bool)    # fg_664=80__tensor_run_opt_ext.664 #scope: Default/optimizer-Momentum
#[CNode]609
    Primitive::Return{prim_type=1}(%1)    #(Bool) #scope: Default/optimizer-Momentum
#[CNode]609
}
# order:
#   1: 79_673.674:[CNode]609{[0]: ValueNode<FuncGraph> 80__tensor_run_opt_ext.664, [1]: ValueNode<StringImm> PolyNode, [2]: 667, [3]: 668, [4]: 669, [5]: 670, [6]: 671, [7]: ValueNode<BoolImm> false, [8]: ValueNode<BoolImm> false}
#   2: 79_673.674:[CNode]609{[0]: ValueNode<Primitive> Return, [1]: [CNode]609}


# [No.80] 84_685.686

funcgraph fg_686(
        %para192 : Func    # 798
        , %para193 : Ref[Tensor(F32)][]    # 679
        , %para194 : Ref[Tensor(F32)][]    # 680
        , %para195 : Tensor(F32)[84, 120]    # 681
        , %para196 : Ref[Tensor(F32)][84, 120]    # 682
        , %para197 : Ref[Tensor(F32)][84, 120]    # 683
        , %para198 : Bool    # 799
        , %para199 : Bool    # 800
    ) {
    %1 : Bool = FuncGraph::fg_676("PolyNode", %para193, %para194, %para195, %para196, %para197, Bool(0), Bool(0))    #(ProblemType, Ref[Tensor(F32)][], Ref[Tensor(F32)][], Tensor(F32)[84, 120], Ref[Tensor(F32)][84, 120], Ref[Tensor(F32)][84, 120], Bool, Bool)    # fg_676=85__tensor_run_opt_ext.676 #scope: Default/optimizer-Momentum
#[CNode]609
    Primitive::Return{prim_type=1}(%1)    #(Bool) #scope: Default/optimizer-Momentum
#[CNode]609
}
# order:
#   1: 84_685.686:[CNode]609{[0]: ValueNode<FuncGraph> 85__tensor_run_opt_ext.676, [1]: ValueNode<StringImm> PolyNode, [2]: 679, [3]: 680, [4]: 681, [5]: 682, [6]: 683, [7]: ValueNode<BoolImm> false, [8]: ValueNode<BoolImm> false}
#   2: 84_685.686:[CNode]609{[0]: ValueNode<Primitive> Return, [1]: [CNode]609}


# [No.81] 89_697.698

funcgraph fg_698(
        %para200 : Func    # 801
        , %para201 : Ref[Tensor(F32)][]    # 691
        , %para202 : Ref[Tensor(F32)][]    # 692
        , %para203 : Tensor(F32)[84]    # 693
        , %para204 : Ref[Tensor(F32)][84]    # 694
        , %para205 : Ref[Tensor(F32)][84]    # 695
        , %para206 : Bool    # 802
        , %para207 : Bool    # 803
    ) {
    %1 : Bool = FuncGraph::fg_688("PolyNode", %para201, %para202, %para203, %para204, %para205, Bool(0), Bool(0))    #(ProblemType, Ref[Tensor(F32)][], Ref[Tensor(F32)][], Tensor(F32)[84], Ref[Tensor(F32)][84], Ref[Tensor(F32)][84], Bool, Bool)    # fg_688=90__tensor_run_opt_ext.688 #scope: Default/optimizer-Momentum
#[CNode]609
    Primitive::Return{prim_type=1}(%1)    #(Bool) #scope: Default/optimizer-Momentum
#[CNode]609
}
# order:
#   1: 89_697.698:[CNode]609{[0]: ValueNode<FuncGraph> 90__tensor_run_opt_ext.688, [1]: ValueNode<StringImm> PolyNode, [2]: 691, [3]: 692, [4]: 693, [5]: 694, [6]: 695, [7]: ValueNode<BoolImm> false, [8]: ValueNode<BoolImm> false}
#   2: 89_697.698:[CNode]609{[0]: ValueNode<Primitive> Return, [1]: [CNode]609}


# [No.82] 94_709.710

funcgraph fg_710(
        %para208 : Func    # 804
        , %para209 : Ref[Tensor(F32)][]    # 703
        , %para210 : Ref[Tensor(F32)][]    # 704
        , %para211 : Tensor(F32)[10, 84]    # 705
        , %para212 : Ref[Tensor(F32)][10, 84]    # 706
        , %para213 : Ref[Tensor(F32)][10, 84]    # 707
        , %para214 : Bool    # 805
        , %para215 : Bool    # 806
    ) {
    %1 : Bool = FuncGraph::fg_700("PolyNode", %para209, %para210, %para211, %para212, %para213, Bool(0), Bool(0))    #(ProblemType, Ref[Tensor(F32)][], Ref[Tensor(F32)][], Tensor(F32)[10, 84], Ref[Tensor(F32)][10, 84], Ref[Tensor(F32)][10, 84], Bool, Bool)    # fg_700=95__tensor_run_opt_ext.700 #scope: Default/optimizer-Momentum
#[CNode]609
    Primitive::Return{prim_type=1}(%1)    #(Bool) #scope: Default/optimizer-Momentum
#[CNode]609
}
# order:
#   1: 94_709.710:[CNode]609{[0]: ValueNode<FuncGraph> 95__tensor_run_opt_ext.700, [1]: ValueNode<StringImm> PolyNode, [2]: 703, [3]: 704, [4]: 705, [5]: 706, [6]: 707, [7]: ValueNode<BoolImm> false, [8]: ValueNode<BoolImm> false}
#   2: 94_709.710:[CNode]609{[0]: ValueNode<Primitive> Return, [1]: [CNode]609}


# [No.83] 99_721.722

funcgraph fg_722(
        %para216 : Func    # 807
        , %para217 : Ref[Tensor(F32)][]    # 715
        , %para218 : Ref[Tensor(F32)][]    # 716
        , %para219 : Tensor(F32)[10]    # 717
        , %para220 : Ref[Tensor(F32)][10]    # 718
        , %para221 : Ref[Tensor(F32)][10]    # 719
        , %para222 : Bool    # 808
        , %para223 : Bool    # 809
    ) {
    %1 : Bool = FuncGraph::fg_712("PolyNode", %para217, %para218, %para219, %para220, %para221, Bool(0), Bool(0))    #(ProblemType, Ref[Tensor(F32)][], Ref[Tensor(F32)][], Tensor(F32)[10], Ref[Tensor(F32)][10], Ref[Tensor(F32)][10], Bool, Bool)    # fg_712=100__tensor_run_opt_ext.712 #scope: Default/optimizer-Momentum
#[CNode]609
    Primitive::Return{prim_type=1}(%1)    #(Bool) #scope: Default/optimizer-Momentum
#[CNode]609
}
# order:
#   1: 99_721.722:[CNode]609{[0]: ValueNode<FuncGraph> 100__tensor_run_opt_ext.712, [1]: ValueNode<StringImm> PolyNode, [2]: 715, [3]: 716, [4]: 717, [5]: 718, [6]: 719, [7]: ValueNode<BoolImm> false, [8]: ValueNode<BoolImm> false}
#   2: 99_721.722:[CNode]609{[0]: ValueNode<Primitive> Return, [1]: [CNode]609}


# [No.84] 35_L-↓construct.579
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
funcgraph fg_579[fg_578](
        %para224 : Tensor(F32)[32, 400]    # Φx
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(1), FuncGraph::fg_580, "DeadNode")    #(Bool, Func, ProblemType)    # fg_580=36_L-✓↓construct.580 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]133
    %2 : Tensor(F32)[32, 120] = %1[36_L-✓↓construct.580]() #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]136
    Primitive::Return{prim_type=1}(%2)    #(Tensor(F32)[32, 120]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]443
}
# order:
#   1: 35_L-↓construct.579:x{[0]: ValueNode<PrimitivePy> MatMul, [1]: Φx, [2]: L-fc3.weight}
#   2: 35_L-↓construct.579:[CNode]133{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> true, [2]: ValueNode<FuncGraph> 36_L-✓↓construct.580, [3]: ValueNode<StringImm> DeadNode}
#   3: 35_L-↓construct.579:[CNode]136{[0]: [CNode]133}
#   4: 35_L-↓construct.579:[CNode]443{[0]: ValueNode<Primitive> Return, [1]: [CNode]136}


# [No.85] 24_L-↓construct.570
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
funcgraph fg_570[fg_569](
        %para225 : Tensor(F32)[32, 120]    # Φx
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(1), FuncGraph::fg_571, "DeadNode")    #(Bool, Func, ProblemType)    # fg_571=25_L-✓↓construct.571 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]133
    %2 : Tensor(F32)[32, 84] = %1[25_L-✓↓construct.571]() #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]136
    Primitive::Return{prim_type=1}(%2)    #(Tensor(F32)[32, 84]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]443
}
# order:
#   1: 24_L-↓construct.570:x{[0]: ValueNode<PrimitivePy> MatMul, [1]: Φx, [2]: L-fc3.weight}
#   2: 24_L-↓construct.570:[CNode]133{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> true, [2]: ValueNode<FuncGraph> 25_L-✓↓construct.571, [3]: ValueNode<StringImm> DeadNode}
#   3: 24_L-↓construct.570:[CNode]136{[0]: [CNode]133}
#   4: 24_L-↓construct.570:[CNode]443{[0]: ValueNode<Primitive> Return, [1]: [CNode]136}


# [No.86] 13_L-↓construct.561
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
funcgraph fg_561[fg_560](
        %para226 : Tensor(F32)[32, 84]    # Φx
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(1), FuncGraph::fg_562, "DeadNode")    #(Bool, Func, ProblemType)    # fg_562=14_L-✓↓construct.562 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]133
    %2 : Tensor(F32)[32, 10] = %1[14_L-✓↓construct.562]() #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]136
    Primitive::Return{prim_type=1}(%2)    #(Tensor(F32)[32, 10]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]443
}
# order:
#   1: 13_L-↓construct.561:x{[0]: ValueNode<PrimitivePy> MatMul, [1]: Φx, [2]: L-fc3.weight}
#   2: 13_L-↓construct.561:[CNode]133{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> true, [2]: ValueNode<FuncGraph> 14_L-✓↓construct.562, [3]: ValueNode<StringImm> DeadNode}
#   3: 13_L-↓construct.561:[CNode]136{[0]: [CNode]133}
#   4: 13_L-↓construct.561:[CNode]443{[0]: ValueNode<Primitive> Return, [1]: [CNode]136}


# [No.87] 65__tensor_run_opt_ext.603
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(28)/def _tensor_run_opt_ext(opt, momentum, learning_rate, gradient, weight, moment, ps_parameter, cache_enable):/
funcgraph fg_603(
        %para227 : Func    # opt
        , %para228 : Ref[Tensor(F32)][]    # momentum
        , %para229 : Ref[Tensor(F32)][]    # learning_rate
        , %para230 : Tensor(F32)[6, 1, 5, 5]    # gradient
        , %para231 : Ref[Tensor(F32)][6, 1, 5, 5]    # weight
        , %para232 : Ref[Tensor(F32)][6, 1, 5, 5]    # moment
        , %para233 : Bool    # ps_parameter
        , %para234 : Bool    # cache_enable
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(0), "DeadNode", FuncGraph::fg_607)    #(Bool, ProblemType, Func)    # fg_607=66_✗_tensor_run_opt_ext.607 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]606
    %2 : Bool = %1[66_✗_tensor_run_opt_ext.607]() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]608
    Primitive::Return{prim_type=1}(%2)    #(Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]819
}
# order:
#   1: 65__tensor_run_opt_ext.603:[CNode]606{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> false, [2]: ValueNode<StringImm> DeadNode, [3]: ValueNode<FuncGraph> 66_✗_tensor_run_opt_ext.607}
#   2: 65__tensor_run_opt_ext.603:[CNode]608{[0]: [CNode]606}
#   3: 65__tensor_run_opt_ext.603:[CNode]819{[0]: ValueNode<Primitive> Return, [1]: [CNode]608}


# [No.88] 70__tensor_run_opt_ext.640
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(28)/def _tensor_run_opt_ext(opt, momentum, learning_rate, gradient, weight, moment, ps_parameter, cache_enable):/
funcgraph fg_640(
        %para235 : Func    # opt
        , %para236 : Ref[Tensor(F32)][]    # momentum
        , %para237 : Ref[Tensor(F32)][]    # learning_rate
        , %para238 : Tensor(F32)[16, 6, 5, 5]    # gradient
        , %para239 : Ref[Tensor(F32)][16, 6, 5, 5]    # weight
        , %para240 : Ref[Tensor(F32)][16, 6, 5, 5]    # moment
        , %para241 : Bool    # ps_parameter
        , %para242 : Bool    # cache_enable
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(0), "DeadNode", FuncGraph::fg_642)    #(Bool, ProblemType, Func)    # fg_642=71_✗_tensor_run_opt_ext.642 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]606
    %2 : Bool = %1[71_✗_tensor_run_opt_ext.642]() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]608
    Primitive::Return{prim_type=1}(%2)    #(Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]819
}
# order:
#   1: 70__tensor_run_opt_ext.640:[CNode]606{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> false, [2]: ValueNode<StringImm> DeadNode, [3]: ValueNode<FuncGraph> 71_✗_tensor_run_opt_ext.642}
#   2: 70__tensor_run_opt_ext.640:[CNode]608{[0]: [CNode]606}
#   3: 70__tensor_run_opt_ext.640:[CNode]819{[0]: ValueNode<Primitive> Return, [1]: [CNode]608}


# [No.89] 75__tensor_run_opt_ext.652
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(28)/def _tensor_run_opt_ext(opt, momentum, learning_rate, gradient, weight, moment, ps_parameter, cache_enable):/
funcgraph fg_652(
        %para243 : Func    # opt
        , %para244 : Ref[Tensor(F32)][]    # momentum
        , %para245 : Ref[Tensor(F32)][]    # learning_rate
        , %para246 : Tensor(F32)[120, 400]    # gradient
        , %para247 : Ref[Tensor(F32)][120, 400]    # weight
        , %para248 : Ref[Tensor(F32)][120, 400]    # moment
        , %para249 : Bool    # ps_parameter
        , %para250 : Bool    # cache_enable
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(0), "DeadNode", FuncGraph::fg_654)    #(Bool, ProblemType, Func)    # fg_654=76_✗_tensor_run_opt_ext.654 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]606
    %2 : Bool = %1[76_✗_tensor_run_opt_ext.654]() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]608
    Primitive::Return{prim_type=1}(%2)    #(Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]819
}
# order:
#   1: 75__tensor_run_opt_ext.652:[CNode]606{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> false, [2]: ValueNode<StringImm> DeadNode, [3]: ValueNode<FuncGraph> 76_✗_tensor_run_opt_ext.654}
#   2: 75__tensor_run_opt_ext.652:[CNode]608{[0]: [CNode]606}
#   3: 75__tensor_run_opt_ext.652:[CNode]819{[0]: ValueNode<Primitive> Return, [1]: [CNode]608}


# [No.90] 80__tensor_run_opt_ext.664
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(28)/def _tensor_run_opt_ext(opt, momentum, learning_rate, gradient, weight, moment, ps_parameter, cache_enable):/
funcgraph fg_664(
        %para251 : Func    # opt
        , %para252 : Ref[Tensor(F32)][]    # momentum
        , %para253 : Ref[Tensor(F32)][]    # learning_rate
        , %para254 : Tensor(F32)[120]    # gradient
        , %para255 : Ref[Tensor(F32)][120]    # weight
        , %para256 : Ref[Tensor(F32)][120]    # moment
        , %para257 : Bool    # ps_parameter
        , %para258 : Bool    # cache_enable
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(0), "DeadNode", FuncGraph::fg_666)    #(Bool, ProblemType, Func)    # fg_666=81_✗_tensor_run_opt_ext.666 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]606
    %2 : Bool = %1[81_✗_tensor_run_opt_ext.666]() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]608
    Primitive::Return{prim_type=1}(%2)    #(Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]819
}
# order:
#   1: 80__tensor_run_opt_ext.664:[CNode]606{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> false, [2]: ValueNode<StringImm> DeadNode, [3]: ValueNode<FuncGraph> 81_✗_tensor_run_opt_ext.666}
#   2: 80__tensor_run_opt_ext.664:[CNode]608{[0]: [CNode]606}
#   3: 80__tensor_run_opt_ext.664:[CNode]819{[0]: ValueNode<Primitive> Return, [1]: [CNode]608}


# [No.91] 85__tensor_run_opt_ext.676
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(28)/def _tensor_run_opt_ext(opt, momentum, learning_rate, gradient, weight, moment, ps_parameter, cache_enable):/
funcgraph fg_676(
        %para259 : Func    # opt
        , %para260 : Ref[Tensor(F32)][]    # momentum
        , %para261 : Ref[Tensor(F32)][]    # learning_rate
        , %para262 : Tensor(F32)[84, 120]    # gradient
        , %para263 : Ref[Tensor(F32)][84, 120]    # weight
        , %para264 : Ref[Tensor(F32)][84, 120]    # moment
        , %para265 : Bool    # ps_parameter
        , %para266 : Bool    # cache_enable
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(0), "DeadNode", FuncGraph::fg_678)    #(Bool, ProblemType, Func)    # fg_678=86_✗_tensor_run_opt_ext.678 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]606
    %2 : Bool = %1[86_✗_tensor_run_opt_ext.678]() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]608
    Primitive::Return{prim_type=1}(%2)    #(Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]819
}
# order:
#   1: 85__tensor_run_opt_ext.676:[CNode]606{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> false, [2]: ValueNode<StringImm> DeadNode, [3]: ValueNode<FuncGraph> 86_✗_tensor_run_opt_ext.678}
#   2: 85__tensor_run_opt_ext.676:[CNode]608{[0]: [CNode]606}
#   3: 85__tensor_run_opt_ext.676:[CNode]819{[0]: ValueNode<Primitive> Return, [1]: [CNode]608}


# [No.92] 90__tensor_run_opt_ext.688
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(28)/def _tensor_run_opt_ext(opt, momentum, learning_rate, gradient, weight, moment, ps_parameter, cache_enable):/
funcgraph fg_688(
        %para267 : Func    # opt
        , %para268 : Ref[Tensor(F32)][]    # momentum
        , %para269 : Ref[Tensor(F32)][]    # learning_rate
        , %para270 : Tensor(F32)[84]    # gradient
        , %para271 : Ref[Tensor(F32)][84]    # weight
        , %para272 : Ref[Tensor(F32)][84]    # moment
        , %para273 : Bool    # ps_parameter
        , %para274 : Bool    # cache_enable
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(0), "DeadNode", FuncGraph::fg_690)    #(Bool, ProblemType, Func)    # fg_690=91_✗_tensor_run_opt_ext.690 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]606
    %2 : Bool = %1[91_✗_tensor_run_opt_ext.690]() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]608
    Primitive::Return{prim_type=1}(%2)    #(Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]819
}
# order:
#   1: 90__tensor_run_opt_ext.688:[CNode]606{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> false, [2]: ValueNode<StringImm> DeadNode, [3]: ValueNode<FuncGraph> 91_✗_tensor_run_opt_ext.690}
#   2: 90__tensor_run_opt_ext.688:[CNode]608{[0]: [CNode]606}
#   3: 90__tensor_run_opt_ext.688:[CNode]819{[0]: ValueNode<Primitive> Return, [1]: [CNode]608}


# [No.93] 95__tensor_run_opt_ext.700
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(28)/def _tensor_run_opt_ext(opt, momentum, learning_rate, gradient, weight, moment, ps_parameter, cache_enable):/
funcgraph fg_700(
        %para275 : Func    # opt
        , %para276 : Ref[Tensor(F32)][]    # momentum
        , %para277 : Ref[Tensor(F32)][]    # learning_rate
        , %para278 : Tensor(F32)[10, 84]    # gradient
        , %para279 : Ref[Tensor(F32)][10, 84]    # weight
        , %para280 : Ref[Tensor(F32)][10, 84]    # moment
        , %para281 : Bool    # ps_parameter
        , %para282 : Bool    # cache_enable
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(0), "DeadNode", FuncGraph::fg_702)    #(Bool, ProblemType, Func)    # fg_702=96_✗_tensor_run_opt_ext.702 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]606
    %2 : Bool = %1[96_✗_tensor_run_opt_ext.702]() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]608
    Primitive::Return{prim_type=1}(%2)    #(Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]819
}
# order:
#   1: 95__tensor_run_opt_ext.700:[CNode]606{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> false, [2]: ValueNode<StringImm> DeadNode, [3]: ValueNode<FuncGraph> 96_✗_tensor_run_opt_ext.702}
#   2: 95__tensor_run_opt_ext.700:[CNode]608{[0]: [CNode]606}
#   3: 95__tensor_run_opt_ext.700:[CNode]819{[0]: ValueNode<Primitive> Return, [1]: [CNode]608}


# [No.94] 100__tensor_run_opt_ext.712
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(28)/def _tensor_run_opt_ext(opt, momentum, learning_rate, gradient, weight, moment, ps_parameter, cache_enable):/
funcgraph fg_712(
        %para283 : Func    # opt
        , %para284 : Ref[Tensor(F32)][]    # momentum
        , %para285 : Ref[Tensor(F32)][]    # learning_rate
        , %para286 : Tensor(F32)[10]    # gradient
        , %para287 : Ref[Tensor(F32)][10]    # weight
        , %para288 : Ref[Tensor(F32)][10]    # moment
        , %para289 : Bool    # ps_parameter
        , %para290 : Bool    # cache_enable
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(0), "DeadNode", FuncGraph::fg_714)    #(Bool, ProblemType, Func)    # fg_714=101_✗_tensor_run_opt_ext.714 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]606
    %2 : Bool = %1[101_✗_tensor_run_opt_ext.714]() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]608
    Primitive::Return{prim_type=1}(%2)    #(Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]819
}
# order:
#   1: 100__tensor_run_opt_ext.712:[CNode]606{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> false, [2]: ValueNode<StringImm> DeadNode, [3]: ValueNode<FuncGraph> 101_✗_tensor_run_opt_ext.714}
#   2: 100__tensor_run_opt_ext.712:[CNode]608{[0]: [CNode]606}
#   3: 100__tensor_run_opt_ext.712:[CNode]819{[0]: ValueNode<Primitive> Return, [1]: [CNode]608}


# [No.95] 36_L-✓↓construct.580
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
funcgraph fg_580[fg_579](
) {
    %1 : $(35_L-↓construct.579):Tensor(F32)[32, 120] = PrimitivePy::MatMul{prim_type=4}[output_names=["output"], transpose_a=Bool(0), input_names=["x1", "x2"], transpose_x2=Bool(1), transpose_x1=Bool(0), transpose_b=Bool(1)](%para224, %para67)    #(Tensor(F32)[32, 400], Ref[Tensor(F32)][120, 400]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(324)/        x = self.matmul(x, self.weight)/#x
    %2 : Tensor(F32)[32, 120] = PrimitivePy::BiasAdd{prim_type=1}[output_names=["output"], format="NCHW", input_names=["x", "b"]](%1, %para66)    #(Tensor(F32)[32, 120], Ref[Tensor(F32)][120]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(326)/            x = self.bias_add(x, self.bias)/#x
    %3 : Tensor(F32)[32, 120] = FuncGraph::fg_576(%2)    #(Tensor(F32)[32, 120])    # fg_576=37_L-↓↓construct.576 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]131
    Primitive::Return{prim_type=1}(%3)    #(Tensor(F32)[32, 120]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]458
}
# order:
#   1: 36_L-✓↓construct.580:x{[0]: ValueNode<PrimitivePy> BiasAdd, [1]: x, [2]: L-fc3.bias}
#   2: 36_L-✓↓construct.580:[CNode]131{[0]: ValueNode<FuncGraph> 37_L-↓↓construct.576, [1]: x}
#   3: 36_L-✓↓construct.580:[CNode]458{[0]: ValueNode<Primitive> Return, [1]: [CNode]131}


# [No.96] 25_L-✓↓construct.571
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
funcgraph fg_571[fg_570](
) {
    %1 : $(24_L-↓construct.570):Tensor(F32)[32, 84] = PrimitivePy::MatMul{prim_type=4}[output_names=["output"], transpose_a=Bool(0), input_names=["x1", "x2"], transpose_x2=Bool(1), transpose_x1=Bool(0), transpose_b=Bool(1)](%para225, %para70)    #(Tensor(F32)[32, 120], Ref[Tensor(F32)][84, 120]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(324)/        x = self.matmul(x, self.weight)/#x
    %2 : Tensor(F32)[32, 84] = PrimitivePy::BiasAdd{prim_type=1}[output_names=["output"], format="NCHW", input_names=["x", "b"]](%1, %para69)    #(Tensor(F32)[32, 84], Ref[Tensor(F32)][84]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(326)/            x = self.bias_add(x, self.bias)/#x
    %3 : Tensor(F32)[32, 84] = FuncGraph::fg_567(%2)    #(Tensor(F32)[32, 84])    # fg_567=26_L-↓↓construct.567 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]131
    Primitive::Return{prim_type=1}(%3)    #(Tensor(F32)[32, 84]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]458
}
# order:
#   1: 25_L-✓↓construct.571:x{[0]: ValueNode<PrimitivePy> BiasAdd, [1]: x, [2]: L-fc3.bias}
#   2: 25_L-✓↓construct.571:[CNode]131{[0]: ValueNode<FuncGraph> 26_L-↓↓construct.567, [1]: x}
#   3: 25_L-✓↓construct.571:[CNode]458{[0]: ValueNode<Primitive> Return, [1]: [CNode]131}


# [No.97] 14_L-✓↓construct.562
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
funcgraph fg_562[fg_561](
) {
    %1 : $(13_L-↓construct.561):Tensor(F32)[32, 10] = PrimitivePy::MatMul{prim_type=4}[output_names=["output"], transpose_a=Bool(0), input_names=["x1", "x2"], transpose_x2=Bool(1), transpose_x1=Bool(0), transpose_b=Bool(1)](%para226, %para73)    #(Tensor(F32)[32, 84], Ref[Tensor(F32)][10, 84]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(324)/        x = self.matmul(x, self.weight)/#x
    %2 : Tensor(F32)[32, 10] = PrimitivePy::BiasAdd{prim_type=1}[output_names=["output"], format="NCHW", input_names=["x", "b"]](%1, %para72)    #(Tensor(F32)[32, 10], Ref[Tensor(F32)][10]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(326)/            x = self.bias_add(x, self.bias)/#x
    %3 : Tensor(F32)[32, 10] = FuncGraph::fg_558(%2)    #(Tensor(F32)[32, 10])    # fg_558=15_L-↓↓construct.558 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]131
    Primitive::Return{prim_type=1}(%3)    #(Tensor(F32)[32, 10]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]458
}
# order:
#   1: 14_L-✓↓construct.562:x{[0]: ValueNode<PrimitivePy> BiasAdd, [1]: x, [2]: L-fc3.bias}
#   2: 14_L-✓↓construct.562:[CNode]131{[0]: ValueNode<FuncGraph> 15_L-↓↓construct.558, [1]: x}
#   3: 14_L-✓↓construct.562:[CNode]458{[0]: ValueNode<Primitive> Return, [1]: [CNode]131}


# [No.98] 66_✗_tensor_run_opt_ext.607
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
funcgraph fg_607[fg_603](
) {
    %1 : Tensor(F32)[6, 1, 5, 5] = PrimitivePy::ApplyMomentum{prim_type=1}[output_names=["output"], side_effect_mem=Bool(1), use_nesterov=Bool(0), input_names=["variable", "accumulation", "learning_rate", "gradient", "momentum"], use_locking=Bool(0), gradient_scale=F32(1)](%para231, %para232, %para229, %para230, %para228)    #(Ref[Tensor(F32)][6, 1, 5, 5], Ref[Tensor(F32)][6, 1, 5, 5], Ref[Tensor(F32)][], Tensor(F32)[6, 1, 5, 5], Ref[Tensor(F32)][]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/#[CNode]602
    %2 : Bool = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %1)    #(Bool, Tensor(F32)[6, 1, 5, 5]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/#success
    %3 : Bool = FuncGraph::fg_605(%2)    #(Bool)    # fg_605=67_↓_tensor_run_opt_ext.605 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]604
    Primitive::Return{prim_type=1}(%3)    #(Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]820
}
# order:
#   1: 66_✗_tensor_run_opt_ext.607:[CNode]602{[0]: ValueNode<PrimitivePy> ApplyMomentum, [1]: weight, [2]: moment, [3]: learning_rate, [4]: gradient, [5]: momentum}
#   2: 66_✗_tensor_run_opt_ext.607:success{[0]: ValueNode<PrimitivePy> Depend, [1]: ValueNode<BoolImm> true, [2]: [CNode]602}
#   3: 66_✗_tensor_run_opt_ext.607:[CNode]604{[0]: ValueNode<FuncGraph> 67_↓_tensor_run_opt_ext.605, [1]: success}
#   4: 66_✗_tensor_run_opt_ext.607:[CNode]820{[0]: ValueNode<Primitive> Return, [1]: [CNode]604}


# [No.99] 71_✗_tensor_run_opt_ext.642
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
funcgraph fg_642[fg_640](
) {
    %1 : Tensor(F32)[16, 6, 5, 5] = PrimitivePy::ApplyMomentum{prim_type=1}[output_names=["output"], side_effect_mem=Bool(1), use_nesterov=Bool(0), input_names=["variable", "accumulation", "learning_rate", "gradient", "momentum"], use_locking=Bool(0), gradient_scale=F32(1)](%para239, %para240, %para237, %para238, %para236)    #(Ref[Tensor(F32)][16, 6, 5, 5], Ref[Tensor(F32)][16, 6, 5, 5], Ref[Tensor(F32)][], Tensor(F32)[16, 6, 5, 5], Ref[Tensor(F32)][]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/#[CNode]602
    %2 : Bool = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %1)    #(Bool, Tensor(F32)[16, 6, 5, 5]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/#success
    %3 : Bool = FuncGraph::fg_641(%2)    #(Bool)    # fg_641=72_↓_tensor_run_opt_ext.641 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]604
    Primitive::Return{prim_type=1}(%3)    #(Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]820
}
# order:
#   1: 71_✗_tensor_run_opt_ext.642:[CNode]602{[0]: ValueNode<PrimitivePy> ApplyMomentum, [1]: weight, [2]: moment, [3]: learning_rate, [4]: gradient, [5]: momentum}
#   2: 71_✗_tensor_run_opt_ext.642:success{[0]: ValueNode<PrimitivePy> Depend, [1]: ValueNode<BoolImm> true, [2]: [CNode]602}
#   3: 71_✗_tensor_run_opt_ext.642:[CNode]604{[0]: ValueNode<FuncGraph> 72_↓_tensor_run_opt_ext.641, [1]: success}
#   4: 71_✗_tensor_run_opt_ext.642:[CNode]820{[0]: ValueNode<Primitive> Return, [1]: [CNode]604}


# [No.100] 76_✗_tensor_run_opt_ext.654
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
funcgraph fg_654[fg_652](
) {
    %1 : Tensor(F32)[120, 400] = PrimitivePy::ApplyMomentum{prim_type=1}[output_names=["output"], side_effect_mem=Bool(1), use_nesterov=Bool(0), input_names=["variable", "accumulation", "learning_rate", "gradient", "momentum"], use_locking=Bool(0), gradient_scale=F32(1)](%para247, %para248, %para245, %para246, %para244)    #(Ref[Tensor(F32)][120, 400], Ref[Tensor(F32)][120, 400], Ref[Tensor(F32)][], Tensor(F32)[120, 400], Ref[Tensor(F32)][]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/#[CNode]602
    %2 : Bool = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %1)    #(Bool, Tensor(F32)[120, 400]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/#success
    %3 : Bool = FuncGraph::fg_653(%2)    #(Bool)    # fg_653=77_↓_tensor_run_opt_ext.653 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]604
    Primitive::Return{prim_type=1}(%3)    #(Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]820
}
# order:
#   1: 76_✗_tensor_run_opt_ext.654:[CNode]602{[0]: ValueNode<PrimitivePy> ApplyMomentum, [1]: weight, [2]: moment, [3]: learning_rate, [4]: gradient, [5]: momentum}
#   2: 76_✗_tensor_run_opt_ext.654:success{[0]: ValueNode<PrimitivePy> Depend, [1]: ValueNode<BoolImm> true, [2]: [CNode]602}
#   3: 76_✗_tensor_run_opt_ext.654:[CNode]604{[0]: ValueNode<FuncGraph> 77_↓_tensor_run_opt_ext.653, [1]: success}
#   4: 76_✗_tensor_run_opt_ext.654:[CNode]820{[0]: ValueNode<Primitive> Return, [1]: [CNode]604}


# [No.101] 81_✗_tensor_run_opt_ext.666
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
funcgraph fg_666[fg_664](
) {
    %1 : Tensor(F32)[120] = PrimitivePy::ApplyMomentum{prim_type=1}[output_names=["output"], side_effect_mem=Bool(1), use_nesterov=Bool(0), input_names=["variable", "accumulation", "learning_rate", "gradient", "momentum"], use_locking=Bool(0), gradient_scale=F32(1)](%para255, %para256, %para253, %para254, %para252)    #(Ref[Tensor(F32)][120], Ref[Tensor(F32)][120], Ref[Tensor(F32)][], Tensor(F32)[120], Ref[Tensor(F32)][]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/#[CNode]602
    %2 : Bool = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %1)    #(Bool, Tensor(F32)[120]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/#success
    %3 : Bool = FuncGraph::fg_665(%2)    #(Bool)    # fg_665=82_↓_tensor_run_opt_ext.665 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]604
    Primitive::Return{prim_type=1}(%3)    #(Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]820
}
# order:
#   1: 81_✗_tensor_run_opt_ext.666:[CNode]602{[0]: ValueNode<PrimitivePy> ApplyMomentum, [1]: weight, [2]: moment, [3]: learning_rate, [4]: gradient, [5]: momentum}
#   2: 81_✗_tensor_run_opt_ext.666:success{[0]: ValueNode<PrimitivePy> Depend, [1]: ValueNode<BoolImm> true, [2]: [CNode]602}
#   3: 81_✗_tensor_run_opt_ext.666:[CNode]604{[0]: ValueNode<FuncGraph> 82_↓_tensor_run_opt_ext.665, [1]: success}
#   4: 81_✗_tensor_run_opt_ext.666:[CNode]820{[0]: ValueNode<Primitive> Return, [1]: [CNode]604}


# [No.102] 86_✗_tensor_run_opt_ext.678
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
funcgraph fg_678[fg_676](
) {
    %1 : Tensor(F32)[84, 120] = PrimitivePy::ApplyMomentum{prim_type=1}[output_names=["output"], side_effect_mem=Bool(1), use_nesterov=Bool(0), input_names=["variable", "accumulation", "learning_rate", "gradient", "momentum"], use_locking=Bool(0), gradient_scale=F32(1)](%para263, %para264, %para261, %para262, %para260)    #(Ref[Tensor(F32)][84, 120], Ref[Tensor(F32)][84, 120], Ref[Tensor(F32)][], Tensor(F32)[84, 120], Ref[Tensor(F32)][]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/#[CNode]602
    %2 : Bool = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %1)    #(Bool, Tensor(F32)[84, 120]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/#success
    %3 : Bool = FuncGraph::fg_677(%2)    #(Bool)    # fg_677=87_↓_tensor_run_opt_ext.677 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]604
    Primitive::Return{prim_type=1}(%3)    #(Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]820
}
# order:
#   1: 86_✗_tensor_run_opt_ext.678:[CNode]602{[0]: ValueNode<PrimitivePy> ApplyMomentum, [1]: weight, [2]: moment, [3]: learning_rate, [4]: gradient, [5]: momentum}
#   2: 86_✗_tensor_run_opt_ext.678:success{[0]: ValueNode<PrimitivePy> Depend, [1]: ValueNode<BoolImm> true, [2]: [CNode]602}
#   3: 86_✗_tensor_run_opt_ext.678:[CNode]604{[0]: ValueNode<FuncGraph> 87_↓_tensor_run_opt_ext.677, [1]: success}
#   4: 86_✗_tensor_run_opt_ext.678:[CNode]820{[0]: ValueNode<Primitive> Return, [1]: [CNode]604}


# [No.103] 91_✗_tensor_run_opt_ext.690
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
funcgraph fg_690[fg_688](
) {
    %1 : Tensor(F32)[84] = PrimitivePy::ApplyMomentum{prim_type=1}[output_names=["output"], side_effect_mem=Bool(1), use_nesterov=Bool(0), input_names=["variable", "accumulation", "learning_rate", "gradient", "momentum"], use_locking=Bool(0), gradient_scale=F32(1)](%para271, %para272, %para269, %para270, %para268)    #(Ref[Tensor(F32)][84], Ref[Tensor(F32)][84], Ref[Tensor(F32)][], Tensor(F32)[84], Ref[Tensor(F32)][]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/#[CNode]602
    %2 : Bool = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %1)    #(Bool, Tensor(F32)[84]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/#success
    %3 : Bool = FuncGraph::fg_689(%2)    #(Bool)    # fg_689=92_↓_tensor_run_opt_ext.689 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]604
    Primitive::Return{prim_type=1}(%3)    #(Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]820
}
# order:
#   1: 91_✗_tensor_run_opt_ext.690:[CNode]602{[0]: ValueNode<PrimitivePy> ApplyMomentum, [1]: weight, [2]: moment, [3]: learning_rate, [4]: gradient, [5]: momentum}
#   2: 91_✗_tensor_run_opt_ext.690:success{[0]: ValueNode<PrimitivePy> Depend, [1]: ValueNode<BoolImm> true, [2]: [CNode]602}
#   3: 91_✗_tensor_run_opt_ext.690:[CNode]604{[0]: ValueNode<FuncGraph> 92_↓_tensor_run_opt_ext.689, [1]: success}
#   4: 91_✗_tensor_run_opt_ext.690:[CNode]820{[0]: ValueNode<Primitive> Return, [1]: [CNode]604}


# [No.104] 96_✗_tensor_run_opt_ext.702
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
funcgraph fg_702[fg_700](
) {
    %1 : Tensor(F32)[10, 84] = PrimitivePy::ApplyMomentum{prim_type=1}[output_names=["output"], side_effect_mem=Bool(1), use_nesterov=Bool(0), input_names=["variable", "accumulation", "learning_rate", "gradient", "momentum"], use_locking=Bool(0), gradient_scale=F32(1)](%para279, %para280, %para277, %para278, %para276)    #(Ref[Tensor(F32)][10, 84], Ref[Tensor(F32)][10, 84], Ref[Tensor(F32)][], Tensor(F32)[10, 84], Ref[Tensor(F32)][]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/#[CNode]602
    %2 : Bool = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %1)    #(Bool, Tensor(F32)[10, 84]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/#success
    %3 : Bool = FuncGraph::fg_701(%2)    #(Bool)    # fg_701=97_↓_tensor_run_opt_ext.701 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]604
    Primitive::Return{prim_type=1}(%3)    #(Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]820
}
# order:
#   1: 96_✗_tensor_run_opt_ext.702:[CNode]602{[0]: ValueNode<PrimitivePy> ApplyMomentum, [1]: weight, [2]: moment, [3]: learning_rate, [4]: gradient, [5]: momentum}
#   2: 96_✗_tensor_run_opt_ext.702:success{[0]: ValueNode<PrimitivePy> Depend, [1]: ValueNode<BoolImm> true, [2]: [CNode]602}
#   3: 96_✗_tensor_run_opt_ext.702:[CNode]604{[0]: ValueNode<FuncGraph> 97_↓_tensor_run_opt_ext.701, [1]: success}
#   4: 96_✗_tensor_run_opt_ext.702:[CNode]820{[0]: ValueNode<Primitive> Return, [1]: [CNode]604}


# [No.105] 101_✗_tensor_run_opt_ext.714
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
funcgraph fg_714[fg_712](
) {
    %1 : Tensor(F32)[10] = PrimitivePy::ApplyMomentum{prim_type=1}[output_names=["output"], side_effect_mem=Bool(1), use_nesterov=Bool(0), input_names=["variable", "accumulation", "learning_rate", "gradient", "momentum"], use_locking=Bool(0), gradient_scale=F32(1)](%para287, %para288, %para285, %para286, %para284)    #(Ref[Tensor(F32)][10], Ref[Tensor(F32)][10], Ref[Tensor(F32)][], Tensor(F32)[10], Ref[Tensor(F32)][]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/#[CNode]602
    %2 : Bool = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %1)    #(Bool, Tensor(F32)[10]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(37)/        success = F.depend(True, opt(weight, moment, learning_rate, gradient, momentum))/#success
    %3 : Bool = FuncGraph::fg_713(%2)    #(Bool)    # fg_713=102_↓_tensor_run_opt_ext.713 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]604
    Primitive::Return{prim_type=1}(%3)    #(Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/#[CNode]820
}
# order:
#   1: 101_✗_tensor_run_opt_ext.714:[CNode]602{[0]: ValueNode<PrimitivePy> ApplyMomentum, [1]: weight, [2]: moment, [3]: learning_rate, [4]: gradient, [5]: momentum}
#   2: 101_✗_tensor_run_opt_ext.714:success{[0]: ValueNode<PrimitivePy> Depend, [1]: ValueNode<BoolImm> true, [2]: [CNode]602}
#   3: 101_✗_tensor_run_opt_ext.714:[CNode]604{[0]: ValueNode<FuncGraph> 102_↓_tensor_run_opt_ext.713, [1]: success}
#   4: 101_✗_tensor_run_opt_ext.714:[CNode]820{[0]: ValueNode<Primitive> Return, [1]: [CNode]604}


# [No.106] 37_L-↓↓construct.576
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
funcgraph fg_576(
        %para291 : Tensor(F32)[32, 120]    # Φx
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(0), "DeadNode", FuncGraph::fg_577)    #(Bool, ProblemType, Func)    # fg_577=38_L-✗↓↓construct.577 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]126
    %2 : Tensor(F32)[32, 120] = %1[38_L-✗↓↓construct.577]() #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]129
    Primitive::Return{prim_type=1}(%2)    #(Tensor(F32)[32, 120]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]470
}
# order:
#   1: 37_L-↓↓construct.576:[CNode]126{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> false, [2]: ValueNode<StringImm> DeadNode, [3]: ValueNode<FuncGraph> 38_L-✗↓↓construct.577}
#   2: 37_L-↓↓construct.576:[CNode]129{[0]: [CNode]126}
#   3: 37_L-↓↓construct.576:[CNode]470{[0]: ValueNode<Primitive> Return, [1]: [CNode]129}


# [No.107] 26_L-↓↓construct.567
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
funcgraph fg_567(
        %para292 : Tensor(F32)[32, 84]    # Φx
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(0), "DeadNode", FuncGraph::fg_568)    #(Bool, ProblemType, Func)    # fg_568=27_L-✗↓↓construct.568 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]126
    %2 : Tensor(F32)[32, 84] = %1[27_L-✗↓↓construct.568]() #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]129
    Primitive::Return{prim_type=1}(%2)    #(Tensor(F32)[32, 84]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]470
}
# order:
#   1: 26_L-↓↓construct.567:[CNode]126{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> false, [2]: ValueNode<StringImm> DeadNode, [3]: ValueNode<FuncGraph> 27_L-✗↓↓construct.568}
#   2: 26_L-↓↓construct.567:[CNode]129{[0]: [CNode]126}
#   3: 26_L-↓↓construct.567:[CNode]470{[0]: ValueNode<Primitive> Return, [1]: [CNode]129}


# [No.108] 15_L-↓↓construct.558
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
funcgraph fg_558(
        %para293 : Tensor(F32)[32, 10]    # Φx
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(0), "DeadNode", FuncGraph::fg_559)    #(Bool, ProblemType, Func)    # fg_559=16_L-✗↓↓construct.559 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]126
    %2 : Tensor(F32)[32, 10] = %1[16_L-✗↓↓construct.559]() #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]129
    Primitive::Return{prim_type=1}(%2)    #(Tensor(F32)[32, 10]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]470
}
# order:
#   1: 15_L-↓↓construct.558:[CNode]126{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> false, [2]: ValueNode<StringImm> DeadNode, [3]: ValueNode<FuncGraph> 16_L-✗↓↓construct.559}
#   2: 15_L-↓↓construct.558:[CNode]129{[0]: [CNode]126}
#   3: 15_L-↓↓construct.558:[CNode]470{[0]: ValueNode<Primitive> Return, [1]: [CNode]129}


# [No.109] 67_↓_tensor_run_opt_ext.605
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
funcgraph fg_605(
        %para294 : Bool    # Φsuccess
    ) {
    Primitive::Return{prim_type=1}(%para294)    #(Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(38)/    return success/#[CNode]821
}
# order:
#   1: 67_↓_tensor_run_opt_ext.605:[CNode]821{[0]: ValueNode<Primitive> Return, [1]: Φsuccess}


# [No.110] 72_↓_tensor_run_opt_ext.641
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
funcgraph fg_641(
        %para295 : Bool    # Φsuccess
    ) {
    Primitive::Return{prim_type=1}(%para295)    #(Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(38)/    return success/#[CNode]821
}
# order:
#   1: 72_↓_tensor_run_opt_ext.641:[CNode]821{[0]: ValueNode<Primitive> Return, [1]: Φsuccess}


# [No.111] 77_↓_tensor_run_opt_ext.653
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
funcgraph fg_653(
        %para296 : Bool    # Φsuccess
    ) {
    Primitive::Return{prim_type=1}(%para296)    #(Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(38)/    return success/#[CNode]821
}
# order:
#   1: 77_↓_tensor_run_opt_ext.653:[CNode]821{[0]: ValueNode<Primitive> Return, [1]: Φsuccess}


# [No.112] 82_↓_tensor_run_opt_ext.665
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
funcgraph fg_665(
        %para297 : Bool    # Φsuccess
    ) {
    Primitive::Return{prim_type=1}(%para297)    #(Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(38)/    return success/#[CNode]821
}
# order:
#   1: 82_↓_tensor_run_opt_ext.665:[CNode]821{[0]: ValueNode<Primitive> Return, [1]: Φsuccess}


# [No.113] 87_↓_tensor_run_opt_ext.677
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
funcgraph fg_677(
        %para298 : Bool    # Φsuccess
    ) {
    Primitive::Return{prim_type=1}(%para298)    #(Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(38)/    return success/#[CNode]821
}
# order:
#   1: 87_↓_tensor_run_opt_ext.677:[CNode]821{[0]: ValueNode<Primitive> Return, [1]: Φsuccess}


# [No.114] 92_↓_tensor_run_opt_ext.689
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
funcgraph fg_689(
        %para299 : Bool    # Φsuccess
    ) {
    Primitive::Return{prim_type=1}(%para299)    #(Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(38)/    return success/#[CNode]821
}
# order:
#   1: 92_↓_tensor_run_opt_ext.689:[CNode]821{[0]: ValueNode<Primitive> Return, [1]: Φsuccess}


# [No.115] 97_↓_tensor_run_opt_ext.701
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
funcgraph fg_701(
        %para300 : Bool    # Φsuccess
    ) {
    Primitive::Return{prim_type=1}(%para300)    #(Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(38)/    return success/#[CNode]821
}
# order:
#   1: 97_↓_tensor_run_opt_ext.701:[CNode]821{[0]: ValueNode<Primitive> Return, [1]: Φsuccess}


# [No.116] 102_↓_tensor_run_opt_ext.713
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(30)/    if ps_parameter and not cache_enable:/
funcgraph fg_713(
        %para301 : Bool    # Φsuccess
    ) {
    Primitive::Return{prim_type=1}(%para301)    #(Bool) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(38)/    return success/#[CNode]821
}
# order:
#   1: 102_↓_tensor_run_opt_ext.713:[CNode]821{[0]: ValueNode<Primitive> Return, [1]: Φsuccess}


# [No.117] 38_L-✗↓↓construct.577
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
funcgraph fg_577[fg_576](
) {
    %1 : Tensor(F32)[32, 120] = FuncGraph::fg_574(%para291)    #(Tensor(F32)[32, 120])    # fg_574=39_L-↓↓↓construct.574 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]125
    Primitive::Return{prim_type=1}(%1)    #(Tensor(F32)[32, 120]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]481
}
# order:
#   1: 38_L-✗↓↓construct.577:[CNode]125{[0]: ValueNode<FuncGraph> 39_L-↓↓↓construct.574, [1]: Φx}
#   2: 38_L-✗↓↓construct.577:[CNode]481{[0]: ValueNode<Primitive> Return, [1]: [CNode]125}


# [No.118] 27_L-✗↓↓construct.568
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
funcgraph fg_568[fg_567](
) {
    %1 : Tensor(F32)[32, 84] = FuncGraph::fg_565(%para292)    #(Tensor(F32)[32, 84])    # fg_565=28_L-↓↓↓construct.565 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]125
    Primitive::Return{prim_type=1}(%1)    #(Tensor(F32)[32, 84]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]481
}
# order:
#   1: 27_L-✗↓↓construct.568:[CNode]125{[0]: ValueNode<FuncGraph> 28_L-↓↓↓construct.565, [1]: Φx}
#   2: 27_L-✗↓↓construct.568:[CNode]481{[0]: ValueNode<Primitive> Return, [1]: [CNode]125}


# [No.119] 16_L-✗↓↓construct.559
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
funcgraph fg_559[fg_558](
) {
    %1 : Tensor(F32)[32, 10] = FuncGraph::fg_556(%para293)    #(Tensor(F32)[32, 10])    # fg_556=17_L-↓↓↓construct.556 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]125
    Primitive::Return{prim_type=1}(%1)    #(Tensor(F32)[32, 10]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]481
}
# order:
#   1: 16_L-✗↓↓construct.559:[CNode]125{[0]: ValueNode<FuncGraph> 17_L-↓↓↓construct.556, [1]: Φx}
#   2: 16_L-✗↓↓construct.559:[CNode]481{[0]: ValueNode<Primitive> Return, [1]: [CNode]125}


# [No.120] 39_L-↓↓↓construct.574
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
funcgraph fg_574(
        %para302 : Tensor(F32)[32, 120]    # Φx
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(0), "DeadNode", FuncGraph::fg_575)    #(Bool, ProblemType, Func)    # fg_575=40_L-✗↓↓↓construct.575 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]119
    %2 : Tensor(F32)[32, 120] = %1[40_L-✗↓↓↓construct.575]() #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]122
    Primitive::Return{prim_type=1}(%2)    #(Tensor(F32)[32, 120]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]493
}
# order:
#   1: 39_L-↓↓↓construct.574:[CNode]119{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> false, [2]: ValueNode<StringImm> DeadNode, [3]: ValueNode<FuncGraph> 40_L-✗↓↓↓construct.575}
#   2: 39_L-↓↓↓construct.574:[CNode]122{[0]: [CNode]119}
#   3: 39_L-↓↓↓construct.574:[CNode]493{[0]: ValueNode<Primitive> Return, [1]: [CNode]122}


# [No.121] 28_L-↓↓↓construct.565
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
funcgraph fg_565(
        %para303 : Tensor(F32)[32, 84]    # Φx
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(0), "DeadNode", FuncGraph::fg_566)    #(Bool, ProblemType, Func)    # fg_566=29_L-✗↓↓↓construct.566 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]119
    %2 : Tensor(F32)[32, 84] = %1[29_L-✗↓↓↓construct.566]() #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]122
    Primitive::Return{prim_type=1}(%2)    #(Tensor(F32)[32, 84]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]493
}
# order:
#   1: 28_L-↓↓↓construct.565:[CNode]119{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> false, [2]: ValueNode<StringImm> DeadNode, [3]: ValueNode<FuncGraph> 29_L-✗↓↓↓construct.566}
#   2: 28_L-↓↓↓construct.565:[CNode]122{[0]: [CNode]119}
#   3: 28_L-↓↓↓construct.565:[CNode]493{[0]: ValueNode<Primitive> Return, [1]: [CNode]122}


# [No.122] 17_L-↓↓↓construct.556
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
funcgraph fg_556(
        %para304 : Tensor(F32)[32, 10]    # Φx
    ) {
    %1 : Func = Primitive::Switch{prim_type=1}(Bool(0), "DeadNode", FuncGraph::fg_557)    #(Bool, ProblemType, Func)    # fg_557=18_L-✗↓↓↓construct.557 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]119
    %2 : Tensor(F32)[32, 10] = %1[18_L-✗↓↓↓construct.557]() #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]122
    Primitive::Return{prim_type=1}(%2)    #(Tensor(F32)[32, 10]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]493
}
# order:
#   1: 17_L-↓↓↓construct.556:[CNode]119{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> false, [2]: ValueNode<StringImm> DeadNode, [3]: ValueNode<FuncGraph> 18_L-✗↓↓↓construct.557}
#   2: 17_L-↓↓↓construct.556:[CNode]122{[0]: [CNode]119}
#   3: 17_L-↓↓↓construct.556:[CNode]493{[0]: ValueNode<Primitive> Return, [1]: [CNode]122}


# [No.123] 40_L-✗↓↓↓construct.575
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
funcgraph fg_575[fg_574](
) {
    %1 : Tensor(F32)[32, 120] = FuncGraph::fg_573(%para302)    #(Tensor(F32)[32, 120])    # fg_573=41_L-↓↓↓↓construct.573 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]118
    Primitive::Return{prim_type=1}(%1)    #(Tensor(F32)[32, 120]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]502
}
# order:
#   1: 40_L-✗↓↓↓construct.575:[CNode]118{[0]: ValueNode<FuncGraph> 41_L-↓↓↓↓construct.573, [1]: Φx}
#   2: 40_L-✗↓↓↓construct.575:[CNode]502{[0]: ValueNode<Primitive> Return, [1]: [CNode]118}


# [No.124] 29_L-✗↓↓↓construct.566
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
funcgraph fg_566[fg_565](
) {
    %1 : Tensor(F32)[32, 84] = FuncGraph::fg_564(%para303)    #(Tensor(F32)[32, 84])    # fg_564=30_L-↓↓↓↓construct.564 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]118
    Primitive::Return{prim_type=1}(%1)    #(Tensor(F32)[32, 84]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]502
}
# order:
#   1: 29_L-✗↓↓↓construct.566:[CNode]118{[0]: ValueNode<FuncGraph> 30_L-↓↓↓↓construct.564, [1]: Φx}
#   2: 29_L-✗↓↓↓construct.566:[CNode]502{[0]: ValueNode<Primitive> Return, [1]: [CNode]118}


# [No.125] 18_L-✗↓↓↓construct.557
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
funcgraph fg_557[fg_556](
) {
    %1 : Tensor(F32)[32, 10] = FuncGraph::fg_555(%para304)    #(Tensor(F32)[32, 10])    # fg_555=19_L-↓↓↓↓construct.555 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]118
    Primitive::Return{prim_type=1}(%1)    #(Tensor(F32)[32, 10]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]502
}
# order:
#   1: 18_L-✗↓↓↓construct.557:[CNode]118{[0]: ValueNode<FuncGraph> 19_L-↓↓↓↓construct.555, [1]: Φx}
#   2: 18_L-✗↓↓↓construct.557:[CNode]502{[0]: ValueNode<Primitive> Return, [1]: [CNode]118}


# [No.126] 41_L-↓↓↓↓construct.573
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
funcgraph fg_573(
        %para305 : Tensor(F32)[32, 120]    # Φx
    ) {
    Primitive::Return{prim_type=1}(%para305)    #(Tensor(F32)[32, 120]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(332)/        return x/#[CNode]505
}
# order:
#   1: 41_L-↓↓↓↓construct.573:[CNode]505{[0]: ValueNode<Primitive> Return, [1]: Φx}


# [No.127] 30_L-↓↓↓↓construct.564
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
funcgraph fg_564(
        %para306 : Tensor(F32)[32, 84]    # Φx
    ) {
    Primitive::Return{prim_type=1}(%para306)    #(Tensor(F32)[32, 84]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(332)/        return x/#[CNode]505
}
# order:
#   1: 30_L-↓↓↓↓construct.564:[CNode]505{[0]: ValueNode<Primitive> Return, [1]: Φx}


# [No.128] 19_L-↓↓↓↓construct.555
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
funcgraph fg_555(
        %para307 : Tensor(F32)[32, 10]    # Φx
    ) {
    Primitive::Return{prim_type=1}(%para307)    #(Tensor(F32)[32, 10]) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(332)/        return x/#[CNode]505
}
# order:
#   1: 19_L-↓↓↓↓construct.555:[CNode]505{[0]: ValueNode<Primitive> Return, [1]: Φx}


# num of total function graphs: 128