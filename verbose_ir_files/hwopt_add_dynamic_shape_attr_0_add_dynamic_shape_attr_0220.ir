#IR entry      : @kernel_graph_1
#attrs         :
#Total params  : 10

%para1_fc3.bias : <Ref[Tensor(F32)], (10)>  :  <kTypeUnknownxDefaultFormat[const vector][10]>  :  IsWeight:true
%para2_fc2.bias : <Ref[Tensor(F32)], (84)>  :  <kTypeUnknownxDefaultFormat[const vector][84]>  :  IsWeight:true
%para3_fc1.bias : <Ref[Tensor(F32)], (120)>  :  <kTypeUnknownxDefaultFormat[const vector][120]>  :  IsWeight:true
%para4_conv2.weight : <Ref[Tensor(F32)], (16, 6, 5, 5)>  :  <kTypeUnknownxDefaultFormat[const vector][16, 6, 5, 5]>  :  IsWeight:true
%para5_conv1.weight : <Ref[Tensor(F32)], (6, 1, 5, 5)>  :  <kTypeUnknownxDefaultFormat[const vector][6, 1, 5, 5]>  :  IsWeight:true
%para6_fc1.weight : <Ref[Tensor(F32)], (120, 400)>  :  <kTypeUnknownxDefaultFormat[const vector][120, 400]>  :  IsWeight:true
%para7_fc2.weight : <Ref[Tensor(F32)], (84, 120)>  :  <kTypeUnknownxDefaultFormat[const vector][84, 120]>  :  IsWeight:true
%para8_fc3.weight : <Ref[Tensor(F32)], (10, 84)>  :  <kTypeUnknownxDefaultFormat[const vector][10, 84]>  :  IsWeight:true
%para9_data : <Tensor[Float32], (32, 1, 32, 32)>  :  <Float32xDefaultFormat[const vector][32, 1, 32, 32]>  :  IsWeight:false
%para10_label : <Tensor[Int32], (32)>  :  <Int32xDefaultFormat[const vector][32]>  :  IsWeight:false

#Total subgraph : 1

subgraph attr:
subgraph @kernel_graph_1() {
  %0([CNode]1348) = Load(%para5_conv1.weight, U)
      : (<Ref[Tensor(F32)], (6, 1, 5, 5)>, <UMonad>) -> (<Tensor[Float32], (6, 1, 5, 5)>)
      : (conv1.weight)
  %1(output) = Conv2D(%para9_data, %0) {instance name: conv2d} primitive_attrs: {IsFeatureMapInputList: (0), kernel_size: (5, 5), mode: 1, out_channel: 6, input_names: [x, w], pad: (0, 0, 0, 0), pad_mode: valid, format: NCHW, pad_list: (0, 0, 0, 0), groups: 1, stride: (1, 1, 1, 1), group: 1, dilation: (1, 1, 1, 1), output_names: [output], IsFeatureMapOutput: true}
      : (<Tensor[Float32], (32, 1, 32, 32)>, <Tensor[Float32], (6, 1, 5, 5)>) -> (<Tensor[Float32], (32, 6, 28, 28)>)
      : (Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d/Conv2D-op182)
  %2([CNode]1060) = ReLU(%1) {instance name: relu} primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0), input_names: [x]}
      : (<Tensor[Float32], (32, 6, 28, 28)>) -> (<Tensor[Float32], (32, 6, 28, 28)>)
      : (Default/network-WithLossCell/_backbone-LeNet5/relu-ReLU/ReLU-op183)
  %3(out) = MaxPool(%2) {instance name: max_pool} primitive_attrs: {IsFeatureMapInputList: (0), kernel_size: (1, 1, 2, 2), strides: (1, 1, 2, 2), input_names: [x], pad_mode: VALID, output_names: [output], IsFeatureMapOutput: true, format: NCHW}
      : (<Tensor[Float32], (32, 6, 28, 28)>) -> (<Tensor[Float32], (32, 6, 14, 14)>)
      : (Default/network-WithLossCell/_backbone-LeNet5/max_pool2d-MaxPool2d/MaxPool-op184)
  %4([CNode]1345) = Load(%para4_conv2.weight, U)
      : (<Ref[Tensor(F32)], (16, 6, 5, 5)>, <UMonad>) -> (<Tensor[Float32], (16, 6, 5, 5)>)
      : (conv2.weight)
  %5(output) = Conv2D(%3, %4) {instance name: conv2d} primitive_attrs: {IsFeatureMapInputList: (0), kernel_size: (5, 5), mode: 1, out_channel: 16, input_names: [x, w], pad: (0, 0, 0, 0), pad_mode: valid, format: NCHW, pad_list: (0, 0, 0, 0), groups: 1, stride: (1, 1, 1, 1), group: 1, dilation: (1, 1, 1, 1), output_names: [output], IsFeatureMapOutput: true}
      : (<Tensor[Float32], (32, 6, 14, 14)>, <Tensor[Float32], (16, 6, 5, 5)>) -> (<Tensor[Float32], (32, 16, 10, 10)>)
      : (Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d/Conv2D-op185)
  %6([CNode]1060) = ReLU(%5) {instance name: relu} primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0), input_names: [x]}
      : (<Tensor[Float32], (32, 16, 10, 10)>) -> (<Tensor[Float32], (32, 16, 10, 10)>)
      : (Default/network-WithLossCell/_backbone-LeNet5/relu-ReLU/ReLU-op186)
  %7(out) = MaxPool(%6) {instance name: max_pool} primitive_attrs: {IsFeatureMapInputList: (0), kernel_size: (1, 1, 2, 2), strides: (1, 1, 2, 2), input_names: [x], pad_mode: VALID, output_names: [output], IsFeatureMapOutput: true, format: NCHW}
      : (<Tensor[Float32], (32, 16, 10, 10)>) -> (<Tensor[Float32], (32, 16, 5, 5)>)
      : (Default/network-WithLossCell/_backbone-LeNet5/max_pool2d-MaxPool2d/MaxPool-op187)
  %8([CNode]1163) = Reshape(%7) primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0), shape: (32, -1), input_names: [tensor, shape]}
      : (<Tensor[Float32], (32, 16, 5, 5)>) -> (<Tensor[Float32], (32, 400)>)
      : (Default/network-WithLossCell/_backbone-LeNet5/flatten-Flatten/Reshape-op188)
  %9([CNode]1339) = Load(%para6_fc1.weight, U)
      : (<Ref[Tensor(F32)], (120, 400)>, <UMonad>) -> (<Tensor[Float32], (120, 400)>)
      : (fc1.weight)
  %10(x) = MatMul(%8, %9) {instance name: matmul} primitive_attrs: {IsFeatureMapInputList: (0), input_names: [x1, x2], transpose_x2: true, transpose_b: true, output_names: [output], transpose_a: false, IsFeatureMapOutput: true, transpose_x1: false}
      : (<Tensor[Float32], (32, 400)>, <Tensor[Float32], (120, 400)>) -> (<Tensor[Float32], (32, 120)>)
      : (Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense/MatMul-op189)
  %11([CNode]1340) = Load(%para3_fc1.bias, U)
      : (<Ref[Tensor(F32)], (120)>, <UMonad>) -> (<Tensor[Float32], (120)>)
      : (fc1.bias)
  %12(x) = BiasAdd(%10, %11) {instance name: bias_add} primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0), format: NCHW, input_names: [x, b]}
      : (<Tensor[Float32], (32, 120)>, <Tensor[Float32], (120)>) -> (<Tensor[Float32], (32, 120)>)
      : (Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense/BiasAdd-op190)
  %13([CNode]1060) = ReLU(%12) {instance name: relu} primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0), input_names: [x]}
      : (<Tensor[Float32], (32, 120)>) -> (<Tensor[Float32], (32, 120)>)
      : (Default/network-WithLossCell/_backbone-LeNet5/relu-ReLU/ReLU-op191)
  %14([CNode]1333) = Load(%para7_fc2.weight, U)
      : (<Ref[Tensor(F32)], (84, 120)>, <UMonad>) -> (<Tensor[Float32], (84, 120)>)
      : (fc2.weight)
  %15(x) = MatMul(%13, %14) {instance name: matmul} primitive_attrs: {IsFeatureMapInputList: (0), input_names: [x1, x2], transpose_x2: true, transpose_b: true, output_names: [output], transpose_a: false, IsFeatureMapOutput: true, transpose_x1: false}
      : (<Tensor[Float32], (32, 120)>, <Tensor[Float32], (84, 120)>) -> (<Tensor[Float32], (32, 84)>)
      : (Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense/MatMul-op192)
  %16([CNode]1334) = Load(%para2_fc2.bias, U)
      : (<Ref[Tensor(F32)], (84)>, <UMonad>) -> (<Tensor[Float32], (84)>)
      : (fc2.bias)
  %17(x) = BiasAdd(%15, %16) {instance name: bias_add} primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0), format: NCHW, input_names: [x, b]}
      : (<Tensor[Float32], (32, 84)>, <Tensor[Float32], (84)>) -> (<Tensor[Float32], (32, 84)>)
      : (Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense/BiasAdd-op193)
  %18([CNode]1060) = ReLU(%17) {instance name: relu} primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0), input_names: [x]}
      : (<Tensor[Float32], (32, 84)>) -> (<Tensor[Float32], (32, 84)>)
      : (Default/network-WithLossCell/_backbone-LeNet5/relu-ReLU/ReLU-op194)
  %19([CNode]1327) = Load(%para8_fc3.weight, U)
      : (<Ref[Tensor(F32)], (10, 84)>, <UMonad>) -> (<Tensor[Float32], (10, 84)>)
      : (fc3.weight)
  %20(x) = MatMul(%18, %19) {instance name: matmul} primitive_attrs: {IsFeatureMapInputList: (0), input_names: [x1, x2], transpose_x2: true, transpose_b: true, output_names: [output], transpose_a: false, IsFeatureMapOutput: true, transpose_x1: false}
      : (<Tensor[Float32], (32, 84)>, <Tensor[Float32], (10, 84)>) -> (<Tensor[Float32], (32, 10)>)
      : (Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense/MatMul-op195)
  %21([CNode]1328) = Load(%para1_fc3.bias, U)
      : (<Ref[Tensor(F32)], (10)>, <UMonad>) -> (<Tensor[Float32], (10)>)
      : (fc3.bias)
  %22(x) = BiasAdd(%20, %21) {instance name: bias_add} primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0), format: NCHW, input_names: [x, b]}
      : (<Tensor[Float32], (32, 10)>, <Tensor[Float32], (10)>) -> (<Tensor[Float32], (32, 10)>)
      : (Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense/BiasAdd-op196)
  %23(x) = SparseSoftmaxCrossEntropyWithLogits(%22, %para10_label) {instance name: sparse_softmax_cross_entropy} primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0, 1), input_names: [features, labels], sens: 1.000000, is_grad: false}
      : (<Tensor[Float32], (32, 10)>, <Tensor[Int32], (32)>) -> (<Tensor[Float32], ()>)
      : (Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits-op197)
  %24([CNode]917) = MakeTuple(%23, %22, %para10_label)
      : (<Tensor[Float32], ()>, <Tensor[Float32], (32, 10)>, <Tensor[Int32], (32)>) -> (<Tuple[Tensor[Float32]*2,Tensor[Int32]], sequence_nodes={node={306_255_construct_wrapper.1358:[CNode]917{[0]: ValueNode<Primitive> MakeTuple, [1]: x, [2]: x, [3]: label}, elements_use_flags: {ptr: 0x1598fda9f20, value: [const vector][1, 1, 1]}}}>)
      : (Default/MakeTuple-op198)
  %25([CNode]1359) = MakeTuple(%19, %14, %9, %0, %4, %11, %16, %21)
      : (<Tensor[Float32], (10, 84)>, <Tensor[Float32], (84, 120)>, <Tensor[Float32], (120, 400)>, <Tensor[Float32], (6, 1, 5, 5)>, <Tensor[Float32], (16, 6, 5, 5)>, <Tensor[Float32], (120)>, <Tensor[Float32], (84)>, <Tensor[Float32], (10)>) -> (<Tuple[Tensor[Float32]*8], sequence_nodes={node={306_255_construct_wrapper.1358:[CNode]1359{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]1327, [2]: [CNode]1333, [3]: [CNode]1339, [4]: [CNode]1348, [5]: [CNode]1345, [6]: [CNode]1340, [7]: [CNode]1334, [8]: [CNode]1328}, elements_use_flags: {ptr: 0x1598fda9fe0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
      : (Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense/MakeTuple-op199)
  %26([CNode]1360) = UpdateState(U, %25)
      : (<UMonad>, <Tuple[Tensor[Float32]*8], sequence_nodes={node={306_255_construct_wrapper.1358:[CNode]1359{[0]: ValueNode<Primitive> MakeTuple, [1]: [CNode]1327, [2]: [CNode]1333, [3]: [CNode]1339, [4]: [CNode]1348, [5]: [CNode]1345, [6]: [CNode]1340, [7]: [CNode]1334, [8]: [CNode]1328}, elements_use_flags: {ptr: 0x1598fda9fe0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>) -> (<UMonad>)
      : (Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense/UpdateState-op200)
  %27([CNode]932) = Depend(%24, %26) primitive_attrs: {side_effect_propagate: 1}
      : (<Tuple[Tensor[Float32]*2,Tensor[Int32]], sequence_nodes={node={306_255_construct_wrapper.1358:[CNode]917{[0]: ValueNode<Primitive> MakeTuple, [1]: x, [2]: x, [3]: label}, elements_use_flags: {ptr: 0x1598fda9f20, value: [const vector][1, 1, 1]}}}>, <UMonad>) -> (<Tuple[Tensor[Float32]*2,Tensor[Int32]], sequence_nodes={node={306_255_construct_wrapper.1358:[CNode]917{[0]: ValueNode<Primitive> MakeTuple, [1]: x, [2]: x, [3]: label}, elements_use_flags: {ptr: 0x1598fda9f20, value: [const vector][1, 1, 1]}}}>)
      : (Default/Depend-op201)
  %28([CNode]1361) = MakeTuple(%27)
      : (<Tuple[Tensor[Float32]*2,Tensor[Int32]], sequence_nodes={node={306_255_construct_wrapper.1358:[CNode]917{[0]: ValueNode<Primitive> MakeTuple, [1]: x, [2]: x, [3]: label}, elements_use_flags: {ptr: 0x1598fda9f20, value: [const vector][1, 1, 1]}}}>) -> (<kMetaTypeNone>)
      : (Default/MakeTuple-op202)
  Return(%28)
      : (<kMetaTypeNone>)
      : (Default/Return-op203)
}

