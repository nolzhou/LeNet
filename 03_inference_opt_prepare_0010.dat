# [No.1] construct_wrapper.1
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(360)/    def construct(self, *inputs):/
funcgraph fg_1(
        %para1    # inputs
        , %para2 : Ref[Tensor(F32)][6, 1, 5, 5]    # conv1.weight
        , %para3 : Ref[Tensor(F32)][16, 6, 5, 5]    # conv2.weight
        , %para4 : Ref[Tensor(F32)][120, 400]    # fc1.weight
        , %para5 : Ref[Tensor(F32)][120]    # fc1.bias
        , %para6 : Ref[Tensor(F32)][84, 120]    # fc2.weight
        , %para7 : Ref[Tensor(F32)][84]    # fc2.bias
        , %para8 : Ref[Tensor(F32)][10, 84]    # fc3.weight
        , %para9 : Ref[Tensor(F32)][10]    # fc3.bias
        , %para10 : Ref[Tensor(F32)][6, 1, 5, 5]    # moments.conv1.weight
        , %para11 : Ref[Tensor(F32)][16, 6, 5, 5]    # moments.conv2.weight
        , %para12 : Ref[Tensor(F32)][120, 400]    # moments.fc1.weight
        , %para13 : Ref[Tensor(F32)][120]    # moments.fc1.bias
        , %para14 : Ref[Tensor(F32)][84, 120]    # moments.fc2.weight
        , %para15 : Ref[Tensor(F32)][84]    # moments.fc2.bias
        , %para16 : Ref[Tensor(F32)][10, 84]    # moments.fc3.weight
        , %para17 : Ref[Tensor(F32)][10]    # moments.fc3.bias
        , %para18 : Ref[Tensor(F32)][]    # momentum
        , %para19 : Ref[Tensor(F32)][]    # learning_rate
    ) {
    %1 = UnpackCall::unpack_call(FuncGraph::fg_22, %para1)    #(Undefined, Undefined)    # fg_22=construct.22 #scope: Default
#[CNode]20
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(366)/        return loss/#[CNode]23
}
# order:
#   1: construct_wrapper.1:[CNode]20{[0]: ValueNode<UnpackCall> unpack_call.21, [1]: ValueNode<FuncGraph> construct.22, [2]: inputs}
#   2: construct_wrapper.1:[CNode]23{[0]: ValueNode<Primitive> Return, [1]: [CNode]20}


# [No.2] construct.22
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(360)/    def construct(self, *inputs):/
funcgraph fg_22[fg_1](
        %para20    # inputs
    ) {
    %1 = UnpackCall::unpack_call(FuncGraph::fg_275, %para20)    #(Undefined, Undefined)    # fg_275=construct.275 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(361)/        loss = self.network(*inputs)/#loss
    %2 = Primitive::getattr{prim_type=1}(%1, "dtype")    #(Undefined, Undefined) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(362)/        sens = F.fill(loss.dtype, loss.shape, self.sens)/#[CNode]14
    %3 = Primitive::getattr{prim_type=1}(%1, "shape")    #(Undefined, Undefined) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(362)/        sens = F.fill(loss.dtype, loss.shape, self.sens)/#[CNode]15
    %4 = DoSignaturePrimitive::S-Prim-Fill{prim_type=1}(%2, %3, F32(1))    #(Undefined, Undefined, Undefined) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(362)/        sens = F.fill(loss.dtype, loss.shape, self.sens)/#sens
    %5 = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%4)    #(Undefined) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#[CNode]17
    %6 = UnpackGraphPrimitive::UnpackGraph{prim_type=1}(FuncGraph::fg_275, %para20, %5)    #(Undefined, Undefined, Undefined)    # fg_275=construct.275 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %7 = Primitive::MakeTuple{prim_type=1}(%para2, %para3, %para4, %para5, %para6, %para7, %para8, %para9)    #(Ref[Tensor(F32)][6, 1, 5, 5], Ref[Tensor(F32)][16, 6, 5, 5], Ref[Tensor(F32)][120, 400], Ref[Tensor(F32)][120], Ref[Tensor(F32)][84, 120], Ref[Tensor(F32)][84], Ref[Tensor(F32)][10, 84], Ref[Tensor(F32)][10]) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#[CNode]394
    %8 = DoSignaturePrimitive::S-Prim-grad{prim_type=1}(%6, %7)    #(Undefined, Undefined) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %9 = UnpackCall::unpack_call(%8, %para20, %5)    #(Undefined, Undefined, Undefined) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(363)/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %10 = DoSignaturePrimitive::S-Prim-identity{prim_type=1}[side_effect_propagate=I64(1)](%9)    #(Undefined) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(364)/        grads = self.grad_reducer(grads)/#grads
    %11 = FuncGraph::fg_385(%10)    #(Undefined)    # fg_385=construct.385 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(365)/        loss = F.depend(loss, self.optimizer(grads))/#[CNode]19
    %12 = DoSignaturePrimitive::S-Prim-Depend{prim_type=1}[side_effect_propagate=I64(1)](%1, %11)    #(Undefined, Undefined) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(365)/        loss = F.depend(loss, self.optimizer(grads))/#loss
    Primitive::Return{prim_type=1}(%12)    #(Undefined) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(366)/        return loss/#[CNode]24
}
# order:
#   1: construct.22:loss{[0]: ValueNode<UnpackCall> unpack_call.5, [1]: ValueNode<FuncGraph> construct.275, [2]: inputs}
#   2: construct.22:[CNode]14{[0]: ValueNode<Primitive> getattr, [1]: loss, [2]: ValueNode<StringImm> dtype}
#   3: construct.22:[CNode]15{[0]: ValueNode<Primitive> getattr, [1]: loss, [2]: ValueNode<StringImm> shape}
#   4: construct.22:sens{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Fill, [1]: [CNode]14, [2]: [CNode]15, [3]: ValueNode<FP32Imm> 1.000000}
#   5: construct.22:[CNode]17{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: sens}
#   6: construct.22:grads{[0]: ValueNode<UnpackGraphPrimitive> UnpackGraph, [1]: ValueNode<FuncGraph> construct.275, [2]: inputs, [3]: [CNode]17}
#   7: construct.22:grads{[0]: ValueNode<DoSignaturePrimitive> S-Prim-grad, [1]: grads, [2]: [CNode]394}
#   8: construct.22:grads{[0]: ValueNode<UnpackCall> unpack_call.18, [1]: grads, [2]: inputs, [3]: [CNode]17}
#   9: construct.22:grads{[0]: ValueNode<DoSignaturePrimitive> S-Prim-identity, [1]: grads}
#  10: construct.22:[CNode]19{[0]: ValueNode<FuncGraph> construct.385, [1]: grads}
#  11: construct.22:loss{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Depend, [1]: loss, [2]: [CNode]19}
#  12: construct.22:[CNode]24{[0]: ValueNode<Primitive> Return, [1]: loss}


# [No.3] construct.275
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(109)/    def construct(self, data, label):/
funcgraph fg_275[fg_1](
        %para21    # data
        , %para22    # label
    ) {
    %1 = FuncGraph::fg_273(%para21)    #(Undefined)    # fg_273=construct.273 #scope: Default/network-WithLossCell
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(110)/        out = self._backbone(data)/#out
    %2 = FuncGraph::fg_45(%1, %para22)    #(Undefined, Undefined)    # fg_45=construct.45 #scope: Default/network-WithLossCell
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(111)/        return self._loss_fn(out, label)/#[CNode]274
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default/network-WithLossCell
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(111)/        return self._loss_fn(out, label)/#[CNode]395
}
# order:
#   1: construct.275:out{[0]: ValueNode<FuncGraph> construct.273, [1]: data}
#   2: construct.275:[CNode]274{[0]: ValueNode<FuncGraph> construct.45, [1]: out, [2]: label}
#   3: construct.275:[CNode]395{[0]: ValueNode<Primitive> Return, [1]: [CNode]274}


# [No.4] construct.385
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(170)/    def construct(self, gradients):/
funcgraph fg_385[fg_1](
        %para23    # gradients
    ) {
    %1 = FuncGraph::fg_42(Bool(0))    #(Undefined)    # fg_42=bool_.42 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(177)/        if self.is_group_lr:/#[CNode]276
    %2 = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_391, FuncGraph::fg_392)    #(Undefined, Undefined, Undefined)    # fg_391=✓construct.391, fg_392=✗construct.392 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(177)/        if self.is_group_lr:/#[CNode]390
    %3 = %2() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(177)/        if self.is_group_lr:/#[CNode]393
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(177)/        if self.is_group_lr:/#[CNode]396
}
# order:
#   1: construct.385:gradients{[0]: ValueNode<FuncGraph> decay_weight.369, [1]: gradients}
#   2: construct.385:gradients{[0]: ValueNode<FuncGraph> gradients_centralization.355, [1]: gradients}
#   3: construct.385:gradients{[0]: ValueNode<FuncGraph> scale_grad.345, [1]: gradients}
#   4: construct.385:lr{[0]: ValueNode<FuncGraph> get_lr.342}
#   5: construct.385:[CNode]276{[0]: ValueNode<FuncGraph> bool_.42, [1]: ValueNode<BoolImm> false}
#   6: construct.385:[CNode]390{[0]: ValueNode<Primitive> Switch, [1]: [CNode]276, [2]: ValueNode<FuncGraph> ✓construct.391, [3]: ValueNode<FuncGraph> ✗construct.392}
#   7: construct.385:[CNode]393{[0]: [CNode]390}
#   8: construct.385:[CNode]396{[0]: ValueNode<Primitive> Return, [1]: [CNode]393}


# [No.5] construct.273
# In file D:\PythonCode\LeNet\lenet.py(39)/    def construct(self, x):/
funcgraph fg_273[fg_1](
        %para24    # x
    ) {
    %1 = FuncGraph::fg_262(%para24)    #(Undefined)    # fg_262=construct.262 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(41)/        x = self.conv1(x)/#x
    %2 = FuncGraph::fg_270(%1)    #(Undefined)    # fg_270=construct.270 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(42)/        x = self.relu(x)/#x
    %3 = FuncGraph::fg_271(%2)    #(Undefined)    # fg_271=construct.271 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(43)/        x = self.max_pool2d(x)/#x
    %4 = FuncGraph::fg_253(%3)    #(Undefined)    # fg_253=construct.253 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(44)/        x = self.conv2(x)/#x
    %5 = FuncGraph::fg_270(%4)    #(Undefined)    # fg_270=construct.270 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(45)/        x = self.relu(x)/#x
    %6 = FuncGraph::fg_271(%5)    #(Undefined)    # fg_271=construct.271 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(46)/        x = self.max_pool2d(x)/#x
    %7 = FuncGraph::fg_272(%6)    #(Undefined)    # fg_272=construct.272 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(47)/        x = self.flatten(x)/#x
    %8 = FuncGraph::fg_206(%7)    #(Undefined)    # fg_206=construct.206 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(48)/        x = self.fc1(x)/#x
    %9 = FuncGraph::fg_270(%8)    #(Undefined)    # fg_270=construct.270 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(49)/        x = self.relu(x)/#x
    %10 = FuncGraph::fg_157(%9)    #(Undefined)    # fg_157=construct.157 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(50)/        x = self.fc2(x)/#x
    %11 = FuncGraph::fg_270(%10)    #(Undefined)    # fg_270=construct.270 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(51)/        x = self.relu(x)/#x
    %12 = FuncGraph::fg_107(%11)    #(Undefined)    # fg_107=construct.107 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(52)/        x = self.fc3(x)/#x
    Primitive::Return{prim_type=1}(%12)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(53)/        return x/#[CNode]397
}
# order:
#   1: construct.273:x{[0]: ValueNode<FuncGraph> construct.262, [1]: x}
#   2: construct.273:x{[0]: ValueNode<FuncGraph> construct.270, [1]: x}
#   3: construct.273:x{[0]: ValueNode<FuncGraph> construct.271, [1]: x}
#   4: construct.273:x{[0]: ValueNode<FuncGraph> construct.253, [1]: x}
#   5: construct.273:x{[0]: ValueNode<FuncGraph> construct.270, [1]: x}
#   6: construct.273:x{[0]: ValueNode<FuncGraph> construct.271, [1]: x}
#   7: construct.273:x{[0]: ValueNode<FuncGraph> construct.272, [1]: x}
#   8: construct.273:x{[0]: ValueNode<FuncGraph> construct.206, [1]: x}
#   9: construct.273:x{[0]: ValueNode<FuncGraph> construct.270, [1]: x}
#  10: construct.273:x{[0]: ValueNode<FuncGraph> construct.157, [1]: x}
#  11: construct.273:x{[0]: ValueNode<FuncGraph> construct.270, [1]: x}
#  12: construct.273:x{[0]: ValueNode<FuncGraph> construct.107, [1]: x}
#  13: construct.273:[CNode]397{[0]: ValueNode<Primitive> Return, [1]: x}


# [No.6] construct.45
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(622)/    def construct(self, logits, labels):/
funcgraph fg_45(
        %para25    # Φlogits
        , %para26    # labels
    ) {
    %1 = DoSignaturePrimitive::S-Prim-_check_is_tensor{prim_type=1}("logits", %para25, "SoftmaxCrossEntropyWithLogits")    #(Undefined, Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(623)/        _check_is_tensor('logits', logits, self.cls_name)/#[CNode]35
    %2 = DoSignaturePrimitive::S-Prim-_check_is_tensor{prim_type=1}("labels", %para26, "SoftmaxCrossEntropyWithLogits")    #(Undefined, Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(624)/        _check_is_tensor('labels', labels, self.cls_name)/#[CNode]36
    %3 = Primitive::MakeTuple{prim_type=1}(%1, %2)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(111)/        return self._loss_fn(out, label)/#[CNode]37
    %4 = Primitive::stop_gradient{prim_type=1}(%3)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(111)/        return self._loss_fn(out, label)/#[CNode]38
    %5 = FuncGraph::fg_42(Bool(1))    #(Undefined)    # fg_42=bool_.42 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/#[CNode]41
    %6 = Primitive::Switch{prim_type=1}(%5, FuncGraph::fg_92, FuncGraph::fg_93)    #(Undefined, Undefined, Undefined)    # fg_92=✓construct.92, fg_93=✗construct.93 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/#[CNode]91
    %7 = %6() #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/#[CNode]94
    %8 = Primitive::Depend{prim_type=1}[side_effect_propagate=I64(1)](%7, %4)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(111)/        return self._loss_fn(out, label)/#[CNode]95
    Primitive::Return{prim_type=1}(%8)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/#[CNode]398
}
# order:
#   1: construct.45:[CNode]35{[0]: ValueNode<DoSignaturePrimitive> S-Prim-_check_is_tensor, [1]: ValueNode<StringImm> logits, [2]: Φlogits, [3]: ValueNode<StringImm> SoftmaxCrossEntropyWithLogits}
#   2: construct.45:[CNode]36{[0]: ValueNode<DoSignaturePrimitive> S-Prim-_check_is_tensor, [1]: ValueNode<StringImm> labels, [2]: labels, [3]: ValueNode<StringImm> SoftmaxCrossEntropyWithLogits}
#   3: construct.45:[CNode]41{[0]: ValueNode<FuncGraph> bool_.42, [1]: ValueNode<BoolImm> true}
#   4: construct.45:[CNode]91{[0]: ValueNode<Primitive> Switch, [1]: [CNode]41, [2]: ValueNode<FuncGraph> ✓construct.92, [3]: ValueNode<FuncGraph> ✗construct.93}
#   5: construct.45:[CNode]94{[0]: [CNode]91}
#   6: construct.45:[CNode]398{[0]: ValueNode<Primitive> Return, [1]: [CNode]95}


# [No.7] bool_.42
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1479)/def bool_(x):/
funcgraph fg_42(
        %para27    # x
    ) {
    %1 = Primitive::getattr{prim_type=1}(%para27, "__bool__")    #(Undefined, Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1481)/    return x.__bool__()/#[CNode]39
    %2 = %1() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1481)/    return x.__bool__()/#[CNode]40
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1481)/    return x.__bool__()/#[CNode]399
}
# order:
#   1: bool_.42:[CNode]39{[0]: ValueNode<Primitive> getattr, [1]: x, [2]: ValueNode<StringImm> __bool__}
#   2: bool_.42:[CNode]40{[0]: [CNode]39}
#   3: bool_.42:[CNode]399{[0]: ValueNode<Primitive> Return, [1]: [CNode]40}


# [No.8] ✓construct.391
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(177)/        if self.is_group_lr:/
funcgraph fg_391[fg_385](
) {
    %1 = DoSignaturePrimitive::S-Prim-Partial{prim_type=1}[side_effect_propagate=I64(1)](DoSignaturePrimitive::S-Prim-momentum_opt{prim_type=1}, DoSignaturePrimitive::S-Prim-ApplyMomentum{prim_type=1}[output_names=["output"], side_effect_mem=Bool(1), use_nesterov=Bool(0), input_names=["variable", "accumulation", "learning_rate", "gradient", "momentum"], use_locking=Bool(0), gradient_scale=F32(1)], %para18)    #(Undefined, Undefined, Ref[Tensor(F32)][]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(178)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum),/#[CNode]277
    %2 = $(construct.385):FuncGraph::fg_342()    # fg_342=get_lr.342 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(176)/        lr = self.get_lr()/#lr
    %3 = $(construct.385):FuncGraph::fg_369(%para23)    #(Undefined)    # fg_369=decay_weight.369 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(173)/        gradients = self.decay_weight(gradients)/#gradients
    %4 = $(construct.385):FuncGraph::fg_355(%3)    #(Undefined)    # fg_355=gradients_centralization.355 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(174)/        gradients = self.gradients_centralization(gradients)/#gradients
    %5 = $(construct.385):FuncGraph::fg_345(%4)    #(Undefined)    # fg_345=scale_grad.345 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(175)/        gradients = self.scale_grad(gradients)/#gradients
    %6 = $(construct.385):Primitive::MakeTuple{prim_type=1}(%para2, %para3, %para4, %para5, %para6, %para7, %para8, %para9)    #(Ref[Tensor(F32)][6, 1, 5, 5], Ref[Tensor(F32)][16, 6, 5, 5], Ref[Tensor(F32)][120, 400], Ref[Tensor(F32)][120], Ref[Tensor(F32)][84, 120], Ref[Tensor(F32)][84], Ref[Tensor(F32)][10, 84], Ref[Tensor(F32)][10]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(171)/        params = self.params/#[CNode]383
    %7 = $(construct.385):Primitive::MakeTuple{prim_type=1}(%para10, %para11, %para12, %para13, %para14, %para15, %para16, %para17)    #(Ref[Tensor(F32)][6, 1, 5, 5], Ref[Tensor(F32)][16, 6, 5, 5], Ref[Tensor(F32)][120, 400], Ref[Tensor(F32)][120], Ref[Tensor(F32)][84, 120], Ref[Tensor(F32)][84], Ref[Tensor(F32)][10, 84], Ref[Tensor(F32)][10]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(172)/        moments = self.moments/#[CNode]384
    %8 = DoSignaturePrimitive::S-Prim-hyper_map{prim_type=1}(%1, %2, %5, %6, %7, (Bool(0), Bool(0), Bool(0), Bool(0), Bool(0), Bool(0), Bool(0), Bool(0)), (Bool(0), Bool(0), Bool(0), Bool(0), Bool(0), Bool(0), Bool(0), Bool(0)))    #(Undefined, Undefined, Undefined, Undefined, Undefined, Undefined, Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(178)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum),/#success
    %9 = FuncGraph::fg_387(%8)    #(Undefined)    # fg_387=↓construct.387 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(177)/        if self.is_group_lr:/#[CNode]386
    Primitive::Return{prim_type=1}(%9)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(177)/        if self.is_group_lr:/#[CNode]400
}
# order:
#   1: ✓construct.391:[CNode]277{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Partial, [1]: ValueNode<DoSignaturePrimitive> S-Prim-momentum_opt, [2]: ValueNode<DoSignaturePrimitive> S-Prim-ApplyMomentum, [3]: momentum}
#   2: ✓construct.391:success{[0]: ValueNode<DoSignaturePrimitive> S-Prim-hyper_map, [1]: [CNode]277, [2]: lr, [3]: gradients, [4]: [CNode]383, [5]: [CNode]384, [6]: ValueNode<ValueTuple> (false, false, false, false, false, false, false, false), [7]: ValueNode<ValueTuple> (false, false, false, false, false, false, false, false)}
#   3: ✓construct.391:[CNode]386{[0]: ValueNode<FuncGraph> ↓construct.387, [1]: success}
#   4: ✓construct.391:[CNode]400{[0]: ValueNode<Primitive> Return, [1]: [CNode]386}


# [No.9] ✗construct.392
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(177)/        if self.is_group_lr:/
funcgraph fg_392[fg_385](
) {
    %1 = $(construct.385):FuncGraph::fg_342()    # fg_342=get_lr.342 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(176)/        lr = self.get_lr()/#lr
    %2 = DoSignaturePrimitive::S-Prim-Partial{prim_type=1}[side_effect_propagate=I64(1)](DoSignaturePrimitive::S-Prim-momentum_opt{prim_type=1}, DoSignaturePrimitive::S-Prim-ApplyMomentum{prim_type=1}[output_names=["output"], side_effect_mem=Bool(1), use_nesterov=Bool(0), input_names=["variable", "accumulation", "learning_rate", "gradient", "momentum"], use_locking=Bool(0), gradient_scale=F32(1)], %para18, %1)    #(Undefined, Undefined, Ref[Tensor(F32)][], Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#[CNode]388
    %3 = $(construct.385):FuncGraph::fg_369(%para23)    #(Undefined)    # fg_369=decay_weight.369 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(173)/        gradients = self.decay_weight(gradients)/#gradients
    %4 = $(construct.385):FuncGraph::fg_355(%3)    #(Undefined)    # fg_355=gradients_centralization.355 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(174)/        gradients = self.gradients_centralization(gradients)/#gradients
    %5 = $(construct.385):FuncGraph::fg_345(%4)    #(Undefined)    # fg_345=scale_grad.345 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(175)/        gradients = self.scale_grad(gradients)/#gradients
    %6 = $(construct.385):Primitive::MakeTuple{prim_type=1}(%para2, %para3, %para4, %para5, %para6, %para7, %para8, %para9)    #(Ref[Tensor(F32)][6, 1, 5, 5], Ref[Tensor(F32)][16, 6, 5, 5], Ref[Tensor(F32)][120, 400], Ref[Tensor(F32)][120], Ref[Tensor(F32)][84, 120], Ref[Tensor(F32)][84], Ref[Tensor(F32)][10, 84], Ref[Tensor(F32)][10]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(171)/        params = self.params/#[CNode]383
    %7 = $(construct.385):Primitive::MakeTuple{prim_type=1}(%para10, %para11, %para12, %para13, %para14, %para15, %para16, %para17)    #(Ref[Tensor(F32)][6, 1, 5, 5], Ref[Tensor(F32)][16, 6, 5, 5], Ref[Tensor(F32)][120, 400], Ref[Tensor(F32)][120], Ref[Tensor(F32)][84, 120], Ref[Tensor(F32)][84], Ref[Tensor(F32)][10, 84], Ref[Tensor(F32)][10]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(172)/        moments = self.moments/#[CNode]384
    %8 = DoSignaturePrimitive::S-Prim-hyper_map{prim_type=1}(%2, %5, %6, %7, (Bool(0), Bool(0), Bool(0), Bool(0), Bool(0), Bool(0), Bool(0), Bool(0)), (Bool(0), Bool(0), Bool(0), Bool(0), Bool(0), Bool(0), Bool(0), Bool(0)))    #(Undefined, Undefined, Undefined, Undefined, Undefined, Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(181)/            success = self.hyper_map_reverse(F.partial(_momentum_opt, self.opt, self.momentum, lr),/#success
    %9 = FuncGraph::fg_387(%8)    #(Undefined)    # fg_387=↓construct.387 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(177)/        if self.is_group_lr:/#[CNode]389
    Primitive::Return{prim_type=1}(%9)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(177)/        if self.is_group_lr:/#[CNode]401
}
# order:
#   1: ✗construct.392:[CNode]388{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Partial, [1]: ValueNode<DoSignaturePrimitive> S-Prim-momentum_opt, [2]: ValueNode<DoSignaturePrimitive> S-Prim-ApplyMomentum, [3]: momentum, [4]: lr}
#   2: ✗construct.392:success{[0]: ValueNode<DoSignaturePrimitive> S-Prim-hyper_map, [1]: [CNode]388, [2]: gradients, [3]: [CNode]383, [4]: [CNode]384, [5]: ValueNode<ValueTuple> (false, false, false, false, false, false, false, false), [6]: ValueNode<ValueTuple> (false, false, false, false, false, false, false, false)}
#   3: ✗construct.392:[CNode]389{[0]: ValueNode<FuncGraph> ↓construct.387, [1]: success}
#   4: ✗construct.392:[CNode]401{[0]: ValueNode<Primitive> Return, [1]: [CNode]389}


# [No.10] construct.262
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(265)/    def construct(self, x):/
funcgraph fg_262[fg_1](
        %para28    # x
    ) {
    %1 = FuncGraph::fg_42(Bool(0))    #(Undefined)    # fg_42=bool_.42 #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]261
    %2 = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_267, FuncGraph::fg_268)    #(Undefined, Undefined, Undefined)    # fg_267=✓construct.267, fg_268=✗construct.268 #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]266
    %3 = %2() #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]269
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]402
}
# order:
#   1: construct.262:output{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Conv2D, [1]: x, [2]: conv1.weight}
#   2: construct.262:[CNode]261{[0]: ValueNode<FuncGraph> bool_.42, [1]: ValueNode<BoolImm> false}
#   3: construct.262:[CNode]266{[0]: ValueNode<Primitive> Switch, [1]: [CNode]261, [2]: ValueNode<FuncGraph> ✓construct.267, [3]: ValueNode<FuncGraph> ✗construct.268}
#   4: construct.262:[CNode]269{[0]: [CNode]266}
#   5: construct.262:[CNode]402{[0]: ValueNode<Primitive> Return, [1]: [CNode]269}


# [No.11] construct.270
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(294)/    def construct(self, x):/
funcgraph fg_270(
        %para29    # x
    ) {
    %1 = DoSignaturePrimitive::S-Prim-ReLU{prim_type=1}[output_names=["output"], input_names=["x"]](%para29)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/relu-ReLU
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(295)/        return self.relu(x)/#[CNode]148
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/relu-ReLU
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(295)/        return self.relu(x)/#[CNode]403
}
# order:
#   1: construct.270:[CNode]148{[0]: ValueNode<DoSignaturePrimitive> S-Prim-ReLU, [1]: x}
#   2: construct.270:[CNode]403{[0]: ValueNode<Primitive> Return, [1]: [CNode]148}


# [No.12] construct.271
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\pooling.py(141)/    def construct(self, x):/
funcgraph fg_271(
        %para30    # x
    ) {
    %1 = DoSignaturePrimitive::S-Prim-MaxPool{prim_type=1}[pad_mode=I64(2), output_names=["output"], kernel_size=(I64(1), I64(1), I64(2), I64(2)), format="NCHW", strides=(I64(1), I64(1), I64(2), I64(2)), input_names=["x"]](%para30)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/max_pool2d-MaxPool2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\pooling.py(142)/        out = self.max_pool(x)/#out
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/max_pool2d-MaxPool2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\pooling.py(143)/        return out/#[CNode]404
}
# order:
#   1: construct.271:out{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MaxPool, [1]: x}
#   2: construct.271:[CNode]404{[0]: ValueNode<Primitive> Return, [1]: out}


# [No.13] construct.253
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(265)/    def construct(self, x):/
funcgraph fg_253[fg_1](
        %para31    # x
    ) {
    %1 = FuncGraph::fg_42(Bool(0))    #(Undefined)    # fg_42=bool_.42 #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]252
    %2 = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_258, FuncGraph::fg_259)    #(Undefined, Undefined, Undefined)    # fg_258=✓construct.258, fg_259=✗construct.259 #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]257
    %3 = %2() #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]260
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]405
}
# order:
#   1: construct.253:output{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Conv2D, [1]: x, [2]: conv2.weight}
#   2: construct.253:[CNode]252{[0]: ValueNode<FuncGraph> bool_.42, [1]: ValueNode<BoolImm> false}
#   3: construct.253:[CNode]257{[0]: ValueNode<Primitive> Switch, [1]: [CNode]252, [2]: ValueNode<FuncGraph> ✓construct.258, [3]: ValueNode<FuncGraph> ✗construct.259}
#   4: construct.253:[CNode]260{[0]: [CNode]257}
#   5: construct.253:[CNode]405{[0]: ValueNode<Primitive> Return, [1]: [CNode]260}


# [No.14] construct.272
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(214)/    def construct(self, x):/
funcgraph fg_272(
        %para32    # x
    ) {
    %1 = DoSignaturePrimitive::S-Prim-Shape{prim_type=1}(%para32)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/flatten-Flatten
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(215)/        return F.reshape(x, (F.shape(x)[0], -1))/#[CNode]247
    %2 = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%1, I64(0))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/flatten-Flatten
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(215)/        return F.reshape(x, (F.shape(x)[0], -1))/#[CNode]248
    %3 = DoSignaturePrimitive::S-Prim-negative{prim_type=1}(I64(1))    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/flatten-Flatten
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(215)/        return F.reshape(x, (F.shape(x)[0], -1))/#[CNode]249
    %4 = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%2, %3)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/flatten-Flatten
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(215)/        return F.reshape(x, (F.shape(x)[0], -1))/#[CNode]250
    %5 = DoSignaturePrimitive::S-Prim-Reshape{prim_type=1}[output_names=["output"], input_names=["tensor", "shape"]](%para32, %4)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/flatten-Flatten
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(215)/        return F.reshape(x, (F.shape(x)[0], -1))/#[CNode]251
    Primitive::Return{prim_type=1}(%5)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/flatten-Flatten
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(215)/        return F.reshape(x, (F.shape(x)[0], -1))/#[CNode]406
}
# order:
#   1: construct.272:[CNode]247{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Shape, [1]: x}
#   2: construct.272:[CNode]248{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: [CNode]247, [2]: ValueNode<Int64Imm> 0}
#   3: construct.272:[CNode]249{[0]: ValueNode<DoSignaturePrimitive> S-Prim-negative, [1]: ValueNode<Int64Imm> 1}
#   4: construct.272:[CNode]250{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: [CNode]248, [2]: [CNode]249}
#   5: construct.272:[CNode]251{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Reshape, [1]: x, [2]: [CNode]250}
#   6: construct.272:[CNode]406{[0]: ValueNode<Primitive> Return, [1]: [CNode]251}


# [No.15] construct.206
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(319)/    def construct(self, x):/
funcgraph fg_206[fg_1](
        %para33    # x
    ) {
    %1 = FuncGraph::fg_508(%para33, %para5, %para4)    #(Undefined, Ref[Tensor(F32)][120], Ref[Tensor(F32)][120, 400])    # fg_508=L-construct.508 #scope: Default
#[CNode]523
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc1-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]407
}
# order:
#   1: construct.206:[CNode]523{[0]: ValueNode<FuncGraph> L-construct.508, [1]: x, [2]: fc1.bias, [3]: fc1.weight}
#   2: construct.206:[CNode]407{[0]: ValueNode<Primitive> Return, [1]: [CNode]523}


# [No.16] construct.157
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(319)/    def construct(self, x):/
funcgraph fg_157[fg_1](
        %para34    # x
    ) {
    %1 = FuncGraph::fg_508(%para34, %para7, %para6)    #(Undefined, Ref[Tensor(F32)][84], Ref[Tensor(F32)][84, 120])    # fg_508=L-construct.508 #scope: Default
#[CNode]522
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc2-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]408
}
# order:
#   1: construct.157:[CNode]522{[0]: ValueNode<FuncGraph> L-construct.508, [1]: x, [2]: fc2.bias, [3]: fc2.weight}
#   2: construct.157:[CNode]408{[0]: ValueNode<Primitive> Return, [1]: [CNode]522}


# [No.17] construct.107
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(319)/    def construct(self, x):/
funcgraph fg_107[fg_1](
        %para35    # x
    ) {
    %1 = FuncGraph::fg_508(%para35, %para9, %para8)    #(Undefined, Ref[Tensor(F32)][10], Ref[Tensor(F32)][10, 84])    # fg_508=L-construct.508 #scope: Default
#[CNode]521
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]409
}
# order:
#   1: construct.107:[CNode]521{[0]: ValueNode<FuncGraph> L-construct.508, [1]: x, [2]: fc3.bias, [3]: fc3.weight}
#   2: construct.107:[CNode]409{[0]: ValueNode<Primitive> Return, [1]: [CNode]521}


# [No.18] ✓construct.92
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/
funcgraph fg_92[fg_45](
) {
    %1 = DoSignaturePrimitive::S-Prim-equal{prim_type=1}("mean", "mean")    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/#[CNode]43
    %2 = FuncGraph::fg_42(%1)    #(Undefined)    # fg_42=bool_.42 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/#[CNode]44
    %3 = Primitive::Switch{prim_type=1}(%2, FuncGraph::fg_87, FuncGraph::fg_88)    #(Undefined, Undefined, Undefined)    # fg_87=✓✓construct.87, fg_88=✗✓construct.88 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/#[CNode]86
    %4 = %3() #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/#[CNode]89
    Primitive::Return{prim_type=1}(%4)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/#[CNode]410
}
# order:
#   1: ✓construct.92:[CNode]43{[0]: ValueNode<DoSignaturePrimitive> S-Prim-equal, [1]: ValueNode<StringImm> mean, [2]: ValueNode<StringImm> mean}
#   2: ✓construct.92:[CNode]44{[0]: ValueNode<FuncGraph> bool_.42, [1]: [CNode]43}
#   3: ✓construct.92:[CNode]86{[0]: ValueNode<Primitive> Switch, [1]: [CNode]44, [2]: ValueNode<FuncGraph> ✓✓construct.87, [3]: ValueNode<FuncGraph> ✗✓construct.88}
#   4: ✓construct.92:[CNode]89{[0]: [CNode]86}
#   5: ✓construct.92:[CNode]410{[0]: ValueNode<Primitive> Return, [1]: [CNode]89}


# [No.19] ✗construct.93
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/
funcgraph fg_93[fg_45](
) {
    %1 = FuncGraph::fg_83(%para26)    #(Undefined)    # fg_83=↓construct.83 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/#[CNode]90
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/#[CNode]411
}
# order:
#   1: ✗construct.93:[CNode]90{[0]: ValueNode<FuncGraph> ↓construct.83, [1]: labels}
#   2: ✗construct.93:[CNode]411{[0]: ValueNode<Primitive> Return, [1]: [CNode]90}


# [No.20] get_lr.342
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(578)/    def get_lr(self):/
funcgraph fg_342[fg_1](
) {
    %1 = FuncGraph::fg_42(Bool(0))    #(Undefined)    # fg_42=bool_.42 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(587)/        if self.dynamic_lr:/#[CNode]278
    %2 = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_339, FuncGraph::fg_340)    #(Undefined, Undefined, Undefined)    # fg_339=✓get_lr.339, fg_340=✗get_lr.340 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(587)/        if self.dynamic_lr:/#[CNode]338
    %3 = %2() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(587)/        if self.dynamic_lr:/#[CNode]341
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(587)/        if self.dynamic_lr:/#[CNode]412
}
# order:
#   1: get_lr.342:[CNode]278{[0]: ValueNode<FuncGraph> bool_.42, [1]: ValueNode<BoolImm> false}
#   2: get_lr.342:[CNode]338{[0]: ValueNode<Primitive> Switch, [1]: [CNode]278, [2]: ValueNode<FuncGraph> ✓get_lr.339, [3]: ValueNode<FuncGraph> ✗get_lr.340}
#   3: get_lr.342:[CNode]341{[0]: [CNode]338}
#   4: get_lr.342:[CNode]412{[0]: ValueNode<Primitive> Return, [1]: [CNode]341}


# [No.21] decay_weight.369
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(304)/    def decay_weight(self, gradients):/
funcgraph fg_369[fg_1](
        %para36    # gradients
    ) {
    %1 = FuncGraph::fg_42(Bool(0))    #(Undefined)    # fg_42=bool_.42 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(317)/        if self.exec_weight_decay:/#[CNode]363
    %2 = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_380, FuncGraph::fg_381)    #(Undefined, Undefined, Undefined)    # fg_380=✓decay_weight.380, fg_381=✗decay_weight.381 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(317)/        if self.exec_weight_decay:/#[CNode]379
    %3 = %2() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(317)/        if self.exec_weight_decay:/#[CNode]382
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(317)/        if self.exec_weight_decay:/#[CNode]413
}
# order:
#   1: decay_weight.369:[CNode]363{[0]: ValueNode<FuncGraph> bool_.42, [1]: ValueNode<BoolImm> false}
#   2: decay_weight.369:[CNode]379{[0]: ValueNode<Primitive> Switch, [1]: [CNode]363, [2]: ValueNode<FuncGraph> ✓decay_weight.380, [3]: ValueNode<FuncGraph> ✗decay_weight.381}
#   3: decay_weight.369:[CNode]382{[0]: [CNode]379}
#   4: decay_weight.369:[CNode]413{[0]: ValueNode<Primitive> Return, [1]: [CNode]382}


# [No.22] gradients_centralization.355
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(328)/    def gradients_centralization(self, gradients):/
funcgraph fg_355(
        %para37    # gradients
    ) {
    %1 = FuncGraph::fg_42(Bool(0))    #(Undefined)    # fg_42=bool_.42 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(342)/        if self.is_group:/#[CNode]353
    %2 = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_360, FuncGraph::fg_361)    #(Undefined, Undefined, Undefined)    # fg_360=✓gradients_centralization.360, fg_361=✗gradients_centralization.361 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(342)/        if self.is_group:/#[CNode]359
    %3 = %2() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(342)/        if self.is_group:/#[CNode]362
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(342)/        if self.is_group:/#[CNode]414
}
# order:
#   1: gradients_centralization.355:[CNode]353{[0]: ValueNode<FuncGraph> bool_.42, [1]: ValueNode<BoolImm> false}
#   2: gradients_centralization.355:[CNode]359{[0]: ValueNode<Primitive> Switch, [1]: [CNode]353, [2]: ValueNode<FuncGraph> ✓gradients_centralization.360, [3]: ValueNode<FuncGraph> ✗gradients_centralization.361}
#   3: gradients_centralization.355:[CNode]362{[0]: [CNode]359}
#   4: gradients_centralization.355:[CNode]414{[0]: ValueNode<Primitive> Return, [1]: [CNode]362}


# [No.23] scale_grad.345
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(347)/    def scale_grad(self, gradients):/
funcgraph fg_345(
        %para38    # gradients
    ) {
    %1 = FuncGraph::fg_42(Bool(0))    #(Undefined)    # fg_42=bool_.42 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(361)/        if self.need_scale:/#[CNode]343
    %2 = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_350, FuncGraph::fg_351)    #(Undefined, Undefined, Undefined)    # fg_350=✓scale_grad.350, fg_351=✗scale_grad.351 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(361)/        if self.need_scale:/#[CNode]349
    %3 = %2() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(361)/        if self.need_scale:/#[CNode]352
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(361)/        if self.need_scale:/#[CNode]415
}
# order:
#   1: scale_grad.345:[CNode]343{[0]: ValueNode<FuncGraph> bool_.42, [1]: ValueNode<BoolImm> false}
#   2: scale_grad.345:[CNode]349{[0]: ValueNode<Primitive> Switch, [1]: [CNode]343, [2]: ValueNode<FuncGraph> ✓scale_grad.350, [3]: ValueNode<FuncGraph> ✗scale_grad.351}
#   3: scale_grad.345:[CNode]352{[0]: [CNode]349}
#   4: scale_grad.345:[CNode]415{[0]: ValueNode<Primitive> Return, [1]: [CNode]352}


# [No.24] ↓construct.387
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(177)/        if self.is_group_lr:/
funcgraph fg_387(
        %para39    # Φsuccess
    ) {
    Primitive::Return{prim_type=1}(%para39)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(183)/        return success/#[CNode]416
}
# order:
#   1: ↓construct.387:[CNode]416{[0]: ValueNode<Primitive> Return, [1]: Φsuccess}


# [No.25] ✓construct.267
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
funcgraph fg_267[fg_262](
) {
    %1 = $(construct.262):DoSignaturePrimitive::S-Prim-Conv2D{prim_type=1}[kernel_size=(I64(5), I64(5)), stride=(I64(1), I64(1), I64(1), I64(1)), mode=I64(1), out_channel=I64(6), group=I64(1), input_names=["x", "w"], pad=(I64(0), I64(0), I64(0), I64(0)), dilation=(I64(1), I64(1), I64(1), I64(1)), pad_mode=I64(2), output_names=["output"], format="NCHW", groups=I64(1)](%para28, %para2)    #(Undefined, Ref[Tensor(F32)][6, 1, 5, 5]) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(266)/        output = self.conv2d(x, self.weight)/#output
    %2 = DoSignaturePrimitive::S-Prim-BiasAdd{prim_type=1}[output_names=["output"], format="NCHW", input_names=["x", "b"]](%1, None)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(268)/            output = self.bias_add(output, self.bias)/#output
    %3 = FuncGraph::fg_264(%2)    #(Undefined)    # fg_264=↓construct.264 #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]263
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]417
}
# order:
#   1: ✓construct.267:output{[0]: ValueNode<DoSignaturePrimitive> S-Prim-BiasAdd, [1]: output, [2]: ValueNode<None> None}
#   2: ✓construct.267:[CNode]263{[0]: ValueNode<FuncGraph> ↓construct.264, [1]: output}
#   3: ✓construct.267:[CNode]417{[0]: ValueNode<Primitive> Return, [1]: [CNode]263}


# [No.26] ✗construct.268
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
funcgraph fg_268[fg_262](
) {
    %1 = $(construct.262):DoSignaturePrimitive::S-Prim-Conv2D{prim_type=1}[kernel_size=(I64(5), I64(5)), stride=(I64(1), I64(1), I64(1), I64(1)), mode=I64(1), out_channel=I64(6), group=I64(1), input_names=["x", "w"], pad=(I64(0), I64(0), I64(0), I64(0)), dilation=(I64(1), I64(1), I64(1), I64(1)), pad_mode=I64(2), output_names=["output"], format="NCHW", groups=I64(1)](%para28, %para2)    #(Undefined, Ref[Tensor(F32)][6, 1, 5, 5]) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(266)/        output = self.conv2d(x, self.weight)/#output
    %2 = FuncGraph::fg_264(%1)    #(Undefined)    # fg_264=↓construct.264 #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]265
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]418
}
# order:
#   1: ✗construct.268:[CNode]265{[0]: ValueNode<FuncGraph> ↓construct.264, [1]: output}
#   2: ✗construct.268:[CNode]418{[0]: ValueNode<Primitive> Return, [1]: [CNode]265}


# [No.27] ✓construct.258
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
funcgraph fg_258[fg_253](
) {
    %1 = $(construct.253):DoSignaturePrimitive::S-Prim-Conv2D{prim_type=1}[kernel_size=(I64(5), I64(5)), stride=(I64(1), I64(1), I64(1), I64(1)), mode=I64(1), out_channel=I64(16), group=I64(1), input_names=["x", "w"], pad=(I64(0), I64(0), I64(0), I64(0)), dilation=(I64(1), I64(1), I64(1), I64(1)), pad_mode=I64(2), output_names=["output"], format="NCHW", groups=I64(1)](%para31, %para3)    #(Undefined, Ref[Tensor(F32)][16, 6, 5, 5]) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(266)/        output = self.conv2d(x, self.weight)/#output
    %2 = DoSignaturePrimitive::S-Prim-BiasAdd{prim_type=1}[output_names=["output"], format="NCHW", input_names=["x", "b"]](%1, None)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(268)/            output = self.bias_add(output, self.bias)/#output
    %3 = FuncGraph::fg_255(%2)    #(Undefined)    # fg_255=↓construct.255 #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]254
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]419
}
# order:
#   1: ✓construct.258:output{[0]: ValueNode<DoSignaturePrimitive> S-Prim-BiasAdd, [1]: output, [2]: ValueNode<None> None}
#   2: ✓construct.258:[CNode]254{[0]: ValueNode<FuncGraph> ↓construct.255, [1]: output}
#   3: ✓construct.258:[CNode]419{[0]: ValueNode<Primitive> Return, [1]: [CNode]254}


# [No.28] ✗construct.259
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
funcgraph fg_259[fg_253](
) {
    %1 = $(construct.253):DoSignaturePrimitive::S-Prim-Conv2D{prim_type=1}[kernel_size=(I64(5), I64(5)), stride=(I64(1), I64(1), I64(1), I64(1)), mode=I64(1), out_channel=I64(16), group=I64(1), input_names=["x", "w"], pad=(I64(0), I64(0), I64(0), I64(0)), dilation=(I64(1), I64(1), I64(1), I64(1)), pad_mode=I64(2), output_names=["output"], format="NCHW", groups=I64(1)](%para31, %para3)    #(Undefined, Ref[Tensor(F32)][16, 6, 5, 5]) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(266)/        output = self.conv2d(x, self.weight)/#output
    %2 = FuncGraph::fg_255(%1)    #(Undefined)    # fg_255=↓construct.255 #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]256
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]420
}
# order:
#   1: ✗construct.259:[CNode]256{[0]: ValueNode<FuncGraph> ↓construct.255, [1]: output}
#   2: ✗construct.259:[CNode]420{[0]: ValueNode<Primitive> Return, [1]: [CNode]256}


# [No.29] L-construct.508
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(319)/    def construct(self, x):/
funcgraph fg_508(
        %para40    # x
        , %para41    # L-fc3.bias
        , %para42    # L-fc3.weight
    ) {
    %1 = DoSignaturePrimitive::S-Prim-Shape{prim_type=1}(%para40)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#Φx_shape
    %2 = DoSignaturePrimitive::S-Prim-check_dense_input_shape{prim_type=1}(%1, "Dense")    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(321)/        check_dense_input_shape(x_shape, self.cls_name)/#[CNode]96
    %3 = Primitive::stop_gradient{prim_type=1}(%2)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\PythonCode\LeNet\lenet.py(52)/        x = self.fc3(x)/#[CNode]97
    %4 = FuncGraph::fg_506(%1)    #(Undefined)    # fg_506=L-ms_len.506 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]100
    %5 = DoSignaturePrimitive::S-Prim-not_equal{prim_type=1}(%4, I64(2))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]102
    %6 = FuncGraph::fg_507(%5)    #(Undefined)    # fg_507=L-bool_.507 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]103
    %7 = Primitive::Switch{prim_type=1}(%6, FuncGraph::fg_519, FuncGraph::fg_520)    #(Undefined, Undefined, Undefined)    # fg_519=L-✓construct.519, fg_520=L-✗construct.520 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]143
    %8 = %7() #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]146
    %9 = Primitive::Depend{prim_type=1}[side_effect_propagate=I64(1)](%8, %3)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\PythonCode\LeNet\lenet.py(52)/        x = self.fc3(x)/#[CNode]147
    Primitive::Return{prim_type=1}(%9)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]409
}
# order:
#   1: L-construct.508:Φx_shape{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Shape, [1]: x}
#   2: L-construct.508:[CNode]96{[0]: ValueNode<DoSignaturePrimitive> S-Prim-check_dense_input_shape, [1]: Φx_shape, [2]: ValueNode<StringImm> Dense}
#   3: L-construct.508:[CNode]100{[0]: ValueNode<FuncGraph> L-ms_len.506, [1]: Φx_shape}
#   4: L-construct.508:[CNode]102{[0]: ValueNode<DoSignaturePrimitive> S-Prim-not_equal, [1]: [CNode]100, [2]: ValueNode<Int64Imm> 2}
#   5: L-construct.508:[CNode]103{[0]: ValueNode<FuncGraph> L-bool_.507, [1]: [CNode]102}
#   6: L-construct.508:[CNode]143{[0]: ValueNode<Primitive> Switch, [1]: [CNode]103, [2]: ValueNode<FuncGraph> L-✓construct.519, [3]: ValueNode<FuncGraph> L-✗construct.520}
#   7: L-construct.508:[CNode]146{[0]: [CNode]143}
#   8: L-construct.508:[CNode]409{[0]: ValueNode<Primitive> Return, [1]: [CNode]147}


# [No.30] ✓✓construct.87
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/
funcgraph fg_87[fg_45](
) {
    %1 = DoSignaturePrimitive::S-Prim-SparseSoftmaxCrossEntropyWithLogits{prim_type=1}[output_names=["output"], input_names=["features", "labels"], sens=F32(1), is_grad=Bool(0)](%para25, %para26)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(627)/                x = self.sparse_softmax_cross_entropy(logits, labels)/#x
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(628)/                return x/#[CNode]428
}
# order:
#   1: ✓✓construct.87:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-SparseSoftmaxCrossEntropyWithLogits, [1]: Φlogits, [2]: labels}
#   2: ✓✓construct.87:[CNode]428{[0]: ValueNode<Primitive> Return, [1]: x}


# [No.31] ✗✓construct.88
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/
funcgraph fg_88[fg_45](
) {
    %1 = FuncGraph::fg_85()    # fg_85=↓✓construct.85 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/#[CNode]84
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/#[CNode]429
}
# order:
#   1: ✗✓construct.88:[CNode]84{[0]: ValueNode<FuncGraph> ↓✓construct.85}
#   2: ✗✓construct.88:[CNode]429{[0]: ValueNode<Primitive> Return, [1]: [CNode]84}


# [No.32] ↓construct.83
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/
funcgraph fg_83[fg_45](
        %para43    # Φlabels
    ) {
    %1 = DoSignaturePrimitive::S-Prim-SoftmaxCrossEntropyWithLogits{prim_type=1}(%para25, %para43)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(630)/        x = self.softmax_cross_entropy(logits, labels)[0]/#[CNode]77
    %2 = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%1, I64(0))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(630)/        x = self.softmax_cross_entropy(logits, labels)[0]/#x
    %3 = FuncGraph::fg_59(%2)    #(Undefined)    # fg_59=get_loss.59 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(631)/        return self.get_loss(x)/#[CNode]78
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(631)/        return self.get_loss(x)/#[CNode]430
}
# order:
#   1: ↓construct.83:[CNode]77{[0]: ValueNode<DoSignaturePrimitive> S-Prim-SoftmaxCrossEntropyWithLogits, [1]: Φlogits, [2]: Φlabels}
#   2: ↓construct.83:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: [CNode]77, [2]: ValueNode<Int64Imm> 0}
#   3: ↓construct.83:[CNode]78{[0]: ValueNode<FuncGraph> get_loss.59, [1]: x}
#   4: ↓construct.83:[CNode]430{[0]: ValueNode<Primitive> Return, [1]: [CNode]78}


# [No.33] ✓get_lr.339
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(587)/        if self.dynamic_lr:/
funcgraph fg_339[fg_1](
) {
    %1 = FuncGraph::fg_42(Bool(0))    #(Undefined)    # fg_42=bool_.42 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(588)/            if self.is_group_lr:/#[CNode]279
    %2 = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_334, FuncGraph::fg_335)    #(Undefined, Undefined, Undefined)    # fg_334=✓✓get_lr.334, fg_335=✗✓get_lr.335 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(588)/            if self.is_group_lr:/#[CNode]333
    %3 = %2() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(588)/            if self.is_group_lr:/#[CNode]336
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(588)/            if self.is_group_lr:/#[CNode]431
}
# order:
#   1: ✓get_lr.339:[CNode]279{[0]: ValueNode<FuncGraph> bool_.42, [1]: ValueNode<BoolImm> false}
#   2: ✓get_lr.339:[CNode]333{[0]: ValueNode<Primitive> Switch, [1]: [CNode]279, [2]: ValueNode<FuncGraph> ✓✓get_lr.334, [3]: ValueNode<FuncGraph> ✗✓get_lr.335}
#   3: ✓get_lr.339:[CNode]336{[0]: [CNode]333}
#   4: ✓get_lr.339:[CNode]431{[0]: ValueNode<Primitive> Return, [1]: [CNode]336}


# [No.34] ✗get_lr.340
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(587)/        if self.dynamic_lr:/
funcgraph fg_340[fg_1](
) {
    %1 = FuncGraph::fg_296(%para19)    #(Ref[Tensor(F32)][])    # fg_296=↓get_lr.296 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(587)/        if self.dynamic_lr:/#[CNode]337
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(587)/        if self.dynamic_lr:/#[CNode]432
}
# order:
#   1: ✗get_lr.340:[CNode]337{[0]: ValueNode<FuncGraph> ↓get_lr.296, [1]: learning_rate}
#   2: ✗get_lr.340:[CNode]432{[0]: ValueNode<Primitive> Return, [1]: [CNode]337}


# [No.35] ✓decay_weight.380
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(317)/        if self.exec_weight_decay:/
funcgraph fg_380[fg_369](
) {
    %1 = FuncGraph::fg_42(Bool(0))    #(Undefined)    # fg_42=bool_.42 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(319)/            if self.is_group:/#[CNode]364
    %2 = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_375, FuncGraph::fg_376)    #(Undefined, Undefined, Undefined)    # fg_375=✓✓decay_weight.375, fg_376=✗✓decay_weight.376 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(319)/            if self.is_group:/#[CNode]374
    %3 = %2() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(319)/            if self.is_group:/#[CNode]377
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(319)/            if self.is_group:/#[CNode]433
}
# order:
#   1: ✓decay_weight.380:[CNode]364{[0]: ValueNode<FuncGraph> bool_.42, [1]: ValueNode<BoolImm> false}
#   2: ✓decay_weight.380:[CNode]374{[0]: ValueNode<Primitive> Switch, [1]: [CNode]364, [2]: ValueNode<FuncGraph> ✓✓decay_weight.375, [3]: ValueNode<FuncGraph> ✗✓decay_weight.376}
#   3: ✓decay_weight.380:[CNode]377{[0]: [CNode]374}
#   4: ✓decay_weight.380:[CNode]433{[0]: ValueNode<Primitive> Return, [1]: [CNode]377}


# [No.36] ✗decay_weight.381
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(317)/        if self.exec_weight_decay:/
funcgraph fg_381[fg_369](
) {
    %1 = FuncGraph::fg_366(%para36)    #(Undefined)    # fg_366=↓decay_weight.366 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(317)/        if self.exec_weight_decay:/#[CNode]378
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(317)/        if self.exec_weight_decay:/#[CNode]434
}
# order:
#   1: ✗decay_weight.381:[CNode]378{[0]: ValueNode<FuncGraph> ↓decay_weight.366, [1]: gradients}
#   2: ✗decay_weight.381:[CNode]434{[0]: ValueNode<Primitive> Return, [1]: [CNode]378}


# [No.37] ✓gradients_centralization.360
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(342)/        if self.is_group:/
funcgraph fg_360[fg_355](
) {
    %1 = DoSignaturePrimitive::S-Prim-Partial{prim_type=1}[side_effect_propagate=I64(1)](DoSignaturePrimitive::S-Prim-apply_grad_centralization{prim_type=1})    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(343)/            gradients = self.map_(F.partial(_apply_grad_centralization), self.grad_centralization_flags, gradients)/#[CNode]354
    %2 = DoSignaturePrimitive::S-Prim-map{prim_type=1}(%1, None, %para37)    #(Undefined, Undefined, Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(343)/            gradients = self.map_(F.partial(_apply_grad_centralization), self.grad_centralization_flags, gradients)/#gradients
    %3 = FuncGraph::fg_357(%2)    #(Undefined)    # fg_357=↓gradients_centralization.357 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(342)/        if self.is_group:/#[CNode]356
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(342)/        if self.is_group:/#[CNode]435
}
# order:
#   1: ✓gradients_centralization.360:[CNode]354{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Partial, [1]: ValueNode<DoSignaturePrimitive> S-Prim-apply_grad_centralization}
#   2: ✓gradients_centralization.360:gradients{[0]: ValueNode<DoSignaturePrimitive> S-Prim-map, [1]: [CNode]354, [2]: ValueNode<None> None, [3]: gradients}
#   3: ✓gradients_centralization.360:[CNode]356{[0]: ValueNode<FuncGraph> ↓gradients_centralization.357, [1]: gradients}
#   4: ✓gradients_centralization.360:[CNode]435{[0]: ValueNode<Primitive> Return, [1]: [CNode]356}


# [No.38] ✗gradients_centralization.361
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(342)/        if self.is_group:/
funcgraph fg_361[fg_355](
) {
    %1 = FuncGraph::fg_357(%para37)    #(Undefined)    # fg_357=↓gradients_centralization.357 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(342)/        if self.is_group:/#[CNode]358
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(342)/        if self.is_group:/#[CNode]436
}
# order:
#   1: ✗gradients_centralization.361:[CNode]358{[0]: ValueNode<FuncGraph> ↓gradients_centralization.357, [1]: gradients}
#   2: ✗gradients_centralization.361:[CNode]436{[0]: ValueNode<Primitive> Return, [1]: [CNode]358}


# [No.39] ✓scale_grad.350
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(361)/        if self.need_scale:/
funcgraph fg_350[fg_345](
) {
    %1 = DoSignaturePrimitive::S-Prim-Partial{prim_type=1}[side_effect_propagate=I64(1)](DoSignaturePrimitive::S-Prim-grad_scale{prim_type=1}, Tensor(43)[])    #(Undefined, Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(362)/            gradients = self.map_(F.partial(_grad_scale, self.reciprocal_scale), gradients)/#[CNode]344
    %2 = DoSignaturePrimitive::S-Prim-map{prim_type=1}(%1, %para38)    #(Undefined, Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(362)/            gradients = self.map_(F.partial(_grad_scale, self.reciprocal_scale), gradients)/#gradients
    %3 = FuncGraph::fg_347(%2)    #(Undefined)    # fg_347=↓scale_grad.347 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(361)/        if self.need_scale:/#[CNode]346
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(361)/        if self.need_scale:/#[CNode]437
}
# order:
#   1: ✓scale_grad.350:[CNode]344{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Partial, [1]: ValueNode<DoSignaturePrimitive> S-Prim-grad_scale, [2]: ValueNode<Tensor> Tensor(shape=[], dtype=Float32, value=1)}
#   2: ✓scale_grad.350:gradients{[0]: ValueNode<DoSignaturePrimitive> S-Prim-map, [1]: [CNode]344, [2]: gradients}
#   3: ✓scale_grad.350:[CNode]346{[0]: ValueNode<FuncGraph> ↓scale_grad.347, [1]: gradients}
#   4: ✓scale_grad.350:[CNode]437{[0]: ValueNode<Primitive> Return, [1]: [CNode]346}


# [No.40] ✗scale_grad.351
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(361)/        if self.need_scale:/
funcgraph fg_351[fg_345](
) {
    %1 = FuncGraph::fg_347(%para38)    #(Undefined)    # fg_347=↓scale_grad.347 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(361)/        if self.need_scale:/#[CNode]348
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(361)/        if self.need_scale:/#[CNode]438
}
# order:
#   1: ✗scale_grad.351:[CNode]348{[0]: ValueNode<FuncGraph> ↓scale_grad.347, [1]: gradients}
#   2: ✗scale_grad.351:[CNode]438{[0]: ValueNode<Primitive> Return, [1]: [CNode]348}


# [No.41] ↓construct.264
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
funcgraph fg_264(
        %para44    # Φoutput
    ) {
    Primitive::Return{prim_type=1}(%para44)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(269)/        return output/#[CNode]439
}
# order:
#   1: ↓construct.264:[CNode]439{[0]: ValueNode<Primitive> Return, [1]: Φoutput}


# [No.42] ↓construct.255
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
funcgraph fg_255(
        %para45    # Φoutput
    ) {
    Primitive::Return{prim_type=1}(%para45)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(269)/        return output/#[CNode]440
}
# order:
#   1: ↓construct.255:[CNode]440{[0]: ValueNode<Primitive> Return, [1]: Φoutput}


# [No.43] L-ms_len.506
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1444)/def ms_len(data):/
funcgraph fg_506(
        %para46    # data
    ) {
    %1 = Primitive::getattr{prim_type=1}(%para46, "__len__")    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1446)/    return data.__len__()/#[CNode]98
    %2 = %1() #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1446)/    return data.__len__()/#[CNode]99
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1446)/    return data.__len__()/#[CNode]421
}
# order:
#   1: L-ms_len.506:[CNode]98{[0]: ValueNode<Primitive> getattr, [1]: data, [2]: ValueNode<StringImm> __len__}
#   2: L-ms_len.506:[CNode]99{[0]: [CNode]98}
#   3: L-ms_len.506:[CNode]421{[0]: ValueNode<Primitive> Return, [1]: [CNode]99}


# [No.44] L-bool_.507
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1479)/def bool_(x):/
funcgraph fg_507(
        %para47    # x
    ) {
    %1 = Primitive::getattr{prim_type=1}(%para47, "__bool__")    #(Undefined, Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1481)/    return x.__bool__()/#[CNode]39
    %2 = %1() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1481)/    return x.__bool__()/#[CNode]40
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1481)/    return x.__bool__()/#[CNode]399
}
# order:
#   1: L-bool_.507:[CNode]39{[0]: ValueNode<Primitive> getattr, [1]: x, [2]: ValueNode<StringImm> __bool__}
#   2: L-bool_.507:[CNode]40{[0]: [CNode]39}
#   3: L-bool_.507:[CNode]399{[0]: ValueNode<Primitive> Return, [1]: [CNode]40}


# [No.45] L-✓construct.519
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
funcgraph fg_519[fg_508](
) {
    %1 = DoSignaturePrimitive::S-Prim-negative{prim_type=1}(I64(1))    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(323)/            x = self.reshape(x, (-1, x_shape[-1]))/#[CNode]137
    %2 = $(L-construct.508):DoSignaturePrimitive::S-Prim-Shape{prim_type=1}(%para40)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#Φx_shape
    %3 = DoSignaturePrimitive::S-Prim-negative{prim_type=1}(I64(1))    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(323)/            x = self.reshape(x, (-1, x_shape[-1]))/#[CNode]138
    %4 = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%2, %3)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(323)/            x = self.reshape(x, (-1, x_shape[-1]))/#[CNode]139
    %5 = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%1, %4)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(323)/            x = self.reshape(x, (-1, x_shape[-1]))/#[CNode]140
    %6 = DoSignaturePrimitive::S-Prim-Reshape{prim_type=1}[output_names=["output"], input_names=["tensor", "shape"]](%para40, %5)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(323)/            x = self.reshape(x, (-1, x_shape[-1]))/#x
    %7 = FuncGraph::fg_516(%6)    #(Undefined)    # fg_516=L-↓construct.516 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]141
    Primitive::Return{prim_type=1}(%7)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]426
}
# order:
#   1: L-✓construct.519:[CNode]137{[0]: ValueNode<DoSignaturePrimitive> S-Prim-negative, [1]: ValueNode<Int64Imm> 1}
#   2: L-✓construct.519:[CNode]138{[0]: ValueNode<DoSignaturePrimitive> S-Prim-negative, [1]: ValueNode<Int64Imm> 1}
#   3: L-✓construct.519:[CNode]139{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: Φx_shape, [2]: [CNode]138}
#   4: L-✓construct.519:[CNode]140{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: [CNode]137, [2]: [CNode]139}
#   5: L-✓construct.519:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Reshape, [1]: x, [2]: [CNode]140}
#   6: L-✓construct.519:[CNode]141{[0]: ValueNode<FuncGraph> L-↓construct.516, [1]: x}
#   7: L-✓construct.519:[CNode]426{[0]: ValueNode<Primitive> Return, [1]: [CNode]141}


# [No.46] L-✗construct.520
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
funcgraph fg_520[fg_508](
) {
    %1 = FuncGraph::fg_516(%para40)    #(Undefined)    # fg_516=L-↓construct.516 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]142
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]427
}
# order:
#   1: L-✗construct.520:[CNode]142{[0]: ValueNode<FuncGraph> L-↓construct.516, [1]: x}
#   2: L-✗construct.520:[CNode]427{[0]: ValueNode<Primitive> Return, [1]: [CNode]142}


# [No.47] ↓✓construct.85
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/
funcgraph fg_85[fg_45](
) {
    %1 = DoSignaturePrimitive::S-Prim-Shape{prim_type=1}(%para25)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(629)/            labels = self.one_hot(labels, F.shape(logits)[-1], self.on_value, self.off_value)/#[CNode]79
    %2 = DoSignaturePrimitive::S-Prim-negative{prim_type=1}(I64(1))    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(629)/            labels = self.one_hot(labels, F.shape(logits)[-1], self.on_value, self.off_value)/#[CNode]80
    %3 = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%1, %2)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(629)/            labels = self.one_hot(labels, F.shape(logits)[-1], self.on_value, self.off_value)/#[CNode]81
    %4 = DoSignaturePrimitive::S-Prim-OneHot{prim_type=1}[output_names=["output"], input_names=["indices", "depth", "on_value", "off_value"], axis=I64(-1)](%para26, %3, Tensor(43)[], Tensor(43)[])    #(Undefined, Undefined, Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(629)/            labels = self.one_hot(labels, F.shape(logits)[-1], self.on_value, self.off_value)/#labels
    %5 = FuncGraph::fg_83(%4)    #(Undefined)    # fg_83=↓construct.83 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/#[CNode]82
    Primitive::Return{prim_type=1}(%5)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/#[CNode]444
}
# order:
#   1: ↓✓construct.85:[CNode]79{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Shape, [1]: Φlogits}
#   2: ↓✓construct.85:[CNode]80{[0]: ValueNode<DoSignaturePrimitive> S-Prim-negative, [1]: ValueNode<Int64Imm> 1}
#   3: ↓✓construct.85:[CNode]81{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: [CNode]79, [2]: [CNode]80}
#   4: ↓✓construct.85:labels{[0]: ValueNode<DoSignaturePrimitive> S-Prim-OneHot, [1]: labels, [2]: [CNode]81, [3]: ValueNode<Tensor> Tensor(shape=[], dtype=Float32, value=1), [4]: ValueNode<Tensor> Tensor(shape=[], dtype=Float32, value=0)}
#   5: ↓✓construct.85:[CNode]82{[0]: ValueNode<FuncGraph> ↓construct.83, [1]: labels}
#   6: ↓✓construct.85:[CNode]444{[0]: ValueNode<Primitive> Return, [1]: [CNode]82}


# [No.48] get_loss.59
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(105)/    def get_loss(self, x, weights=1.0):/
funcgraph fg_59(
        %para48    # x
        , %para49    # weights
    ) {
    %1 = FuncGraph::fg_42(Bool(1))    #(Undefined)    # fg_42=bool_.42 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]46
    %2 = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_48, FuncGraph::fg_49)    #(Undefined, Undefined, Undefined)    # fg_48=↰get_loss.48, fg_49=↱get_loss.49 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]47
    %3 = %2() #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]50
    %4 = FuncGraph::fg_42(%3)    #(Undefined)    # fg_42=bool_.42 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]51
    %5 = Primitive::Switch{prim_type=1}(%4, FuncGraph::fg_74, FuncGraph::fg_75)    #(Undefined, Undefined, Undefined)    # fg_74=✓get_loss.74, fg_75=✗get_loss.75 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]73
    %6 = %5() #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]76
    Primitive::Return{prim_type=1}(%6)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]445
}
# order:
#   1: get_loss.59:Φinput_dtype{[0]: ValueNode<Primitive> getattr, [1]: x, [2]: ValueNode<StringImm> dtype}
#   2: get_loss.59:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Cast, [1]: x, [2]: ValueNode<Float> Float32}
#   3: get_loss.59:weights{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Cast, [1]: weights, [2]: ValueNode<Float> Float32}
#   4: get_loss.59:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Mul, [1]: weights, [2]: x}
#   5: get_loss.59:[CNode]46{[0]: ValueNode<FuncGraph> bool_.42, [1]: ValueNode<BoolImm> true}
#   6: get_loss.59:[CNode]47{[0]: ValueNode<Primitive> Switch, [1]: [CNode]46, [2]: ValueNode<FuncGraph> ↰get_loss.48, [3]: ValueNode<FuncGraph> ↱get_loss.49}
#   7: get_loss.59:[CNode]50{[0]: [CNode]47}
#   8: get_loss.59:[CNode]51{[0]: ValueNode<FuncGraph> bool_.42, [1]: [CNode]50}
#   9: get_loss.59:[CNode]73{[0]: ValueNode<Primitive> Switch, [1]: [CNode]51, [2]: ValueNode<FuncGraph> ✓get_loss.74, [3]: ValueNode<FuncGraph> ✗get_loss.75}
#  10: get_loss.59:[CNode]76{[0]: [CNode]73}
#  11: get_loss.59:[CNode]445{[0]: ValueNode<Primitive> Return, [1]: [CNode]76}


# [No.49] ✓✓get_lr.334
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(588)/            if self.is_group_lr:/
funcgraph fg_334[fg_1](
) {
    %1 = FuncGraph::fg_101(%para19)    #(Ref[Tensor(F32)][])    # fg_101=ms_len.101 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]280
    %2 = Primitive::scalar_lt{prim_type=1}(%1, I64(9223372036854775807))    #(Undefined, Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]281
    %3 = Primitive::Switch{prim_type=1}(%2, FuncGraph::fg_330, FuncGraph::fg_315)    #(Undefined, Undefined, Undefined)    # fg_330=✓✓✓get_lr.330, fg_315=✗✓✓get_lr.315 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]329
    %4 = %3() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]331
    Primitive::Return{prim_type=1}(%4)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]446
}
# order:
#   1: ✓✓get_lr.334:[CNode]280{[0]: ValueNode<FuncGraph> ms_len.101, [1]: learning_rate}
#   2: ✓✓get_lr.334:[CNode]281{[0]: ValueNode<Primitive> scalar_lt, [1]: [CNode]280, [2]: ValueNode<Int64Imm> 9223372036854775807}
#   3: ✓✓get_lr.334:[CNode]329{[0]: ValueNode<Primitive> Switch, [1]: [CNode]281, [2]: ValueNode<FuncGraph> ✓✓✓get_lr.330, [3]: ValueNode<FuncGraph> ✗✓✓get_lr.315}
#   4: ✓✓get_lr.334:[CNode]331{[0]: [CNode]329}
#   5: ✓✓get_lr.334:[CNode]446{[0]: ValueNode<Primitive> Return, [1]: [CNode]331}


# [No.50] ✗✓get_lr.335
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(588)/            if self.is_group_lr:/
funcgraph fg_335[fg_1](
) {
    %1 = %para19(None)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(594)/                lr = self.learning_rate(self.global_step)/#lr
    %2 = FuncGraph::fg_299(None, None, Tensor(34)[], %1)    #(Undefined, Undefined, Undefined, Undefined)    # fg_299=↓✓get_lr.299 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(588)/            if self.is_group_lr:/#[CNode]332
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(588)/            if self.is_group_lr:/#[CNode]447
}
# order:
#   1: ✗✓get_lr.335:lr{[0]: learning_rate, [1]: ValueNode<None> None}
#   2: ✗✓get_lr.335:[CNode]332{[0]: ValueNode<FuncGraph> ↓✓get_lr.299, [1]: ValueNode<None> None, [2]: ValueNode<None> None, [3]: ValueNode<Tensor> Tensor(shape=[], dtype=Int32, value=1), [4]: lr}
#   3: ✗✓get_lr.335:[CNode]447{[0]: ValueNode<Primitive> Return, [1]: [CNode]332}


# [No.51] ↓get_lr.296
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(587)/        if self.dynamic_lr:/
funcgraph fg_296(
        %para50    # Φlr
    ) {
    Primitive::Return{prim_type=1}(%para50)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(597)/        return lr/#[CNode]448
}
# order:
#   1: ↓get_lr.296:[CNode]448{[0]: ValueNode<Primitive> Return, [1]: Φlr}


# [No.52] ✓✓decay_weight.375
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(319)/            if self.is_group:/
funcgraph fg_375[fg_369](
) {
    %1 = DoSignaturePrimitive::S-Prim-Partial{prim_type=1}[side_effect_propagate=I64(1)](DoSignaturePrimitive::S-Prim-apply_decay{prim_type=1})    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(320)/                gradients = self.map_(F.partial(_apply_decay), self.weight_decay_tensor_tuple, self.decay_flags,/#[CNode]367
    %2 = $(decay_weight.369):Primitive::MakeTuple{prim_type=1}(%para2, %para3, %para4, %para5, %para6, %para7, %para8, %para9)    #(Ref[Tensor(F32)][6, 1, 5, 5], Ref[Tensor(F32)][16, 6, 5, 5], Ref[Tensor(F32)][120, 400], Ref[Tensor(F32)][120], Ref[Tensor(F32)][84, 120], Ref[Tensor(F32)][84], Ref[Tensor(F32)][10, 84], Ref[Tensor(F32)][10]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(318)/            params = self.parameters/#[CNode]368
    %3 = DoSignaturePrimitive::S-Prim-map{prim_type=1}(%1, None, (Bool(1), Bool(1), Bool(1), Bool(1), Bool(1), Bool(1), Bool(1), Bool(1)), %2, %para36)    #(Undefined, Undefined, Undefined, Undefined, Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(320)/                gradients = self.map_(F.partial(_apply_decay), self.weight_decay_tensor_tuple, self.decay_flags,/#gradients
    %4 = FuncGraph::fg_371(%3)    #(Undefined)    # fg_371=↓✓decay_weight.371 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(319)/            if self.is_group:/#[CNode]370
    Primitive::Return{prim_type=1}(%4)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(319)/            if self.is_group:/#[CNode]449
}
# order:
#   1: ✓✓decay_weight.375:[CNode]367{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Partial, [1]: ValueNode<DoSignaturePrimitive> S-Prim-apply_decay}
#   2: ✓✓decay_weight.375:gradients{[0]: ValueNode<DoSignaturePrimitive> S-Prim-map, [1]: [CNode]367, [2]: ValueNode<None> None, [3]: ValueNode<ValueTuple> (true, true, true, true, true, true, true, true), [4]: [CNode]368, [5]: gradients}
#   3: ✓✓decay_weight.375:[CNode]370{[0]: ValueNode<FuncGraph> ↓✓decay_weight.371, [1]: gradients}
#   4: ✓✓decay_weight.375:[CNode]449{[0]: ValueNode<Primitive> Return, [1]: [CNode]370}


# [No.53] ✗✓decay_weight.376
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(319)/            if self.is_group:/
funcgraph fg_376[fg_369](
) {
    %1 = DoSignaturePrimitive::S-Prim-Partial{prim_type=1}[side_effect_propagate=I64(1)](DoSignaturePrimitive::S-Prim-apply_decay{prim_type=1}, Tensor(43)[])    #(Undefined, Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(323)/                gradients = self.map_(F.partial(_apply_decay, self.weight_decay_tensor), self.decay_flags,/#[CNode]372
    %2 = $(decay_weight.369):Primitive::MakeTuple{prim_type=1}(%para2, %para3, %para4, %para5, %para6, %para7, %para8, %para9)    #(Ref[Tensor(F32)][6, 1, 5, 5], Ref[Tensor(F32)][16, 6, 5, 5], Ref[Tensor(F32)][120, 400], Ref[Tensor(F32)][120], Ref[Tensor(F32)][84, 120], Ref[Tensor(F32)][84], Ref[Tensor(F32)][10, 84], Ref[Tensor(F32)][10]) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(318)/            params = self.parameters/#[CNode]368
    %3 = DoSignaturePrimitive::S-Prim-map{prim_type=1}(%1, (Bool(1), Bool(1), Bool(1), Bool(1), Bool(1), Bool(1), Bool(1), Bool(1)), %2, %para36)    #(Undefined, Undefined, Undefined, Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(323)/                gradients = self.map_(F.partial(_apply_decay, self.weight_decay_tensor), self.decay_flags,/#gradients
    %4 = FuncGraph::fg_371(%3)    #(Undefined)    # fg_371=↓✓decay_weight.371 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(319)/            if self.is_group:/#[CNode]373
    Primitive::Return{prim_type=1}(%4)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(319)/            if self.is_group:/#[CNode]450
}
# order:
#   1: ✗✓decay_weight.376:[CNode]372{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Partial, [1]: ValueNode<DoSignaturePrimitive> S-Prim-apply_decay, [2]: ValueNode<Tensor> Tensor(shape=[], dtype=Float32, value=0)}
#   2: ✗✓decay_weight.376:gradients{[0]: ValueNode<DoSignaturePrimitive> S-Prim-map, [1]: [CNode]372, [2]: ValueNode<ValueTuple> (true, true, true, true, true, true, true, true), [3]: [CNode]368, [4]: gradients}
#   3: ✗✓decay_weight.376:[CNode]373{[0]: ValueNode<FuncGraph> ↓✓decay_weight.371, [1]: gradients}
#   4: ✗✓decay_weight.376:[CNode]450{[0]: ValueNode<Primitive> Return, [1]: [CNode]373}


# [No.54] ↓decay_weight.366
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(317)/        if self.exec_weight_decay:/
funcgraph fg_366(
        %para51    # Φgradients
    ) {
    Primitive::Return{prim_type=1}(%para51)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(326)/        return gradients/#[CNode]451
}
# order:
#   1: ↓decay_weight.366:[CNode]451{[0]: ValueNode<Primitive> Return, [1]: Φgradients}


# [No.55] ↓gradients_centralization.357
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(342)/        if self.is_group:/
funcgraph fg_357(
        %para52    # Φgradients
    ) {
    Primitive::Return{prim_type=1}(%para52)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(345)/        return gradients/#[CNode]452
}
# order:
#   1: ↓gradients_centralization.357:[CNode]452{[0]: ValueNode<Primitive> Return, [1]: Φgradients}


# [No.56] ↓scale_grad.347
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(361)/        if self.need_scale:/
funcgraph fg_347(
        %para53    # Φgradients
    ) {
    Primitive::Return{prim_type=1}(%para53)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(364)/        return gradients/#[CNode]453
}
# order:
#   1: ↓scale_grad.347:[CNode]453{[0]: ValueNode<Primitive> Return, [1]: Φgradients}


# [No.57] L-↓construct.516
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
funcgraph fg_516[fg_508](
        %para54    # Φx
    ) {
    %1 = FuncGraph::fg_507(Bool(1))    #(Undefined)    # fg_507=L-bool_.507 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]104
    %2 = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_517, FuncGraph::fg_518)    #(Undefined, Undefined, Undefined)    # fg_517=L-✓↓construct.517, fg_518=L-✗↓construct.518 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]133
    %3 = %2() #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]136
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]443
}
# order:
#   1: L-↓construct.516:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MatMul, [1]: Φx, [2]: L-fc3.weight}
#   2: L-↓construct.516:[CNode]104{[0]: ValueNode<FuncGraph> L-bool_.507, [1]: ValueNode<BoolImm> true}
#   3: L-↓construct.516:[CNode]133{[0]: ValueNode<Primitive> Switch, [1]: [CNode]104, [2]: ValueNode<FuncGraph> L-✓↓construct.517, [3]: ValueNode<FuncGraph> L-✗↓construct.518}
#   4: L-↓construct.516:[CNode]136{[0]: [CNode]133}
#   5: L-↓construct.516:[CNode]443{[0]: ValueNode<Primitive> Return, [1]: [CNode]136}


# [No.58] ↰get_loss.48
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/
funcgraph fg_48(
) {
    Primitive::Return{prim_type=1}(Bool(1))    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]460
}
# order:
#   1: ↰get_loss.48:[CNode]460{[0]: ValueNode<Primitive> Return, [1]: ValueNode<BoolImm> true}


# [No.59] ↱get_loss.49
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/
funcgraph fg_49(
) {
    Primitive::Return{prim_type=1}(Bool(1))    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]461
}
# order:
#   1: ↱get_loss.49:[CNode]461{[0]: ValueNode<Primitive> Return, [1]: ValueNode<BoolImm> true}


# [No.60] ✓get_loss.74
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/
funcgraph fg_74[fg_59](
) {
    %1 = $(get_loss.59):DoSignaturePrimitive::S-Prim-Cast{prim_type=1}[output_names=["output"], input_names=["x", "dst_type"]](%para49, F32)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(142)/        weights = self.cast(weights, mstype.float32)/#weights
    %2 = $(get_loss.59):DoSignaturePrimitive::S-Prim-Cast{prim_type=1}[output_names=["output"], input_names=["x", "dst_type"]](%para48, F32)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(141)/        x = self.cast(x, mstype.float32)/#x
    %3 = $(get_loss.59):DoSignaturePrimitive::S-Prim-Mul{prim_type=1}[output_names=["output"], input_names=["x", "y"]](%1, %2)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(143)/        x = self.mul(weights, x)/#x
    %4 = FuncGraph::fg_61(%3)    #(Undefined)    # fg_61=get_axis.61 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(145)/            x = self.reduce_mean(x, self.get_axis(x))/#[CNode]70
    %5 = DoSignaturePrimitive::S-Prim-ReduceMean{prim_type=1}[output_names=["y"], keep_dims=Bool(0), input_names=["input_x", "axis"]](%3, %4)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(145)/            x = self.reduce_mean(x, self.get_axis(x))/#x
    %6 = FuncGraph::fg_62(%5)    #(Undefined)    # fg_62=↓get_loss.62 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]71
    Primitive::Return{prim_type=1}(%6)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]462
}
# order:
#   1: ✓get_loss.74:[CNode]70{[0]: ValueNode<FuncGraph> get_axis.61, [1]: x}
#   2: ✓get_loss.74:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-ReduceMean, [1]: x, [2]: [CNode]70}
#   3: ✓get_loss.74:[CNode]71{[0]: ValueNode<FuncGraph> ↓get_loss.62, [1]: x}
#   4: ✓get_loss.74:[CNode]462{[0]: ValueNode<Primitive> Return, [1]: [CNode]71}


# [No.61] ✗get_loss.75
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/
funcgraph fg_75[fg_59](
) {
    %1 = $(get_loss.59):DoSignaturePrimitive::S-Prim-Cast{prim_type=1}[output_names=["output"], input_names=["x", "dst_type"]](%para49, F32)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(142)/        weights = self.cast(weights, mstype.float32)/#weights
    %2 = $(get_loss.59):DoSignaturePrimitive::S-Prim-Cast{prim_type=1}[output_names=["output"], input_names=["x", "dst_type"]](%para48, F32)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(141)/        x = self.cast(x, mstype.float32)/#x
    %3 = $(get_loss.59):DoSignaturePrimitive::S-Prim-Mul{prim_type=1}[output_names=["output"], input_names=["x", "y"]](%1, %2)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(143)/        x = self.mul(weights, x)/#x
    %4 = FuncGraph::fg_62(%3)    #(Undefined)    # fg_62=↓get_loss.62 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]72
    Primitive::Return{prim_type=1}(%4)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]463
}
# order:
#   1: ✗get_loss.75:[CNode]72{[0]: ValueNode<FuncGraph> ↓get_loss.62, [1]: x}
#   2: ✗get_loss.75:[CNode]463{[0]: ValueNode<Primitive> Return, [1]: [CNode]72}


# [No.62] ms_len.101
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1444)/def ms_len(data):/
funcgraph fg_101(
        %para55    # data
    ) {
    %1 = Primitive::getattr{prim_type=1}(%para55, "__len__")    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1446)/    return data.__len__()/#[CNode]98
    %2 = %1() #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1446)/    return data.__len__()/#[CNode]99
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1446)/    return data.__len__()/#[CNode]421
}
# order:
#   1: ms_len.101:[CNode]98{[0]: ValueNode<Primitive> getattr, [1]: data, [2]: ValueNode<StringImm> __len__}
#   2: ms_len.101:[CNode]99{[0]: [CNode]98}
#   3: ms_len.101:[CNode]421{[0]: ValueNode<Primitive> Return, [1]: [CNode]99}


# [No.63] ✓✓✓get_lr.330
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/
funcgraph fg_330[fg_1](
) {
    %1 = FuncGraph::fg_308(%para19)    #(Ref[Tensor(F32)][])    # fg_308=ms_iter.308 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#@learning_rate
    %2 = FuncGraph::fg_290(%1, ())    #(Undefined, Undefined)    # fg_290=⤾✓✓✓get_lr.290 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]309
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]464
}
# order:
#   1: ✓✓✓get_lr.330:@learning_rate{[0]: ValueNode<FuncGraph> ms_iter.308, [1]: learning_rate}
#   2: ✓✓✓get_lr.330:[CNode]309{[0]: ValueNode<FuncGraph> ⤾✓✓✓get_lr.290, [1]: @learning_rate, [2]: ValueNode<ValueTuple> ()}
#   3: ✓✓✓get_lr.330:[CNode]464{[0]: ValueNode<Primitive> Return, [1]: [CNode]309}


# [No.64] ✗✓✓get_lr.315
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/
funcgraph fg_315[fg_1](
) {
    %1 = ClassType() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]311
    %2 = %1(I64(0))    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]327
    %3 = FuncGraph::fg_319(%2, ())    #(Undefined, Undefined)    # fg_319=⤾✗✓✓get_lr.319 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]328
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]465
}
# order:
#   1: ✗✓✓get_lr.315:[CNode]312{[0]: ValueNode<FuncGraph> ms_len.101, [1]: learning_rate}
#   2: ✗✓✓get_lr.315:[CNode]311{[0]: ValueNode<ClassType> class 'mindspore.ops.operations.array_ops.ScalarToTensor'}
#   3: ✗✓✓get_lr.315:@[CNode]313{[0]: [CNode]311, [1]: [CNode]312}
#   4: ✗✓✓get_lr.315:[CNode]327{[0]: [CNode]311, [1]: ValueNode<Int64Imm> 0}
#   5: ✗✓✓get_lr.315:[CNode]328{[0]: ValueNode<FuncGraph> ⤾✗✓✓get_lr.319, [1]: [CNode]327, [2]: ValueNode<ValueTuple> ()}
#   6: ✗✓✓get_lr.315:[CNode]465{[0]: ValueNode<Primitive> Return, [1]: [CNode]328}


# [No.65] ↓✓get_lr.299
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(588)/            if self.is_group_lr:/
funcgraph fg_299(
        %para56    # Φself.assignadd
        , %para57    # Φself.global_step
        , %para58    # Φself.global_step_increase_tensor
        , %para59    # Φlr
    ) {
    %1 = %para56(%para57, %para58)    #(Undefined, Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(596)/            self.assignadd(self.global_step, self.global_step_increase_tensor)/#[CNode]293
    %2 = Primitive::stop_gradient{prim_type=1}(%1)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(176)/        lr = self.get_lr()/#[CNode]294
    %3 = FuncGraph::fg_296(%para59)    #(Undefined)    # fg_296=↓get_lr.296 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(587)/        if self.dynamic_lr:/#[CNode]295
    %4 = Primitive::Depend{prim_type=1}[side_effect_propagate=I64(1)](%3, %2)    #(Undefined, Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\momentum.py(176)/        lr = self.get_lr()/#[CNode]297
    Primitive::Return{prim_type=1}(%4)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(587)/        if self.dynamic_lr:/#[CNode]466
}
# order:
#   1: ↓✓get_lr.299:[CNode]293{[0]: Φself.assignadd, [1]: Φself.global_step, [2]: Φself.global_step_increase_tensor}
#   2: ↓✓get_lr.299:[CNode]295{[0]: ValueNode<FuncGraph> ↓get_lr.296, [1]: Φlr}
#   3: ↓✓get_lr.299:[CNode]466{[0]: ValueNode<Primitive> Return, [1]: [CNode]297}


# [No.66] ↓✓decay_weight.371
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(319)/            if self.is_group:/
funcgraph fg_371(
        %para60    # Φgradients
    ) {
    %1 = FuncGraph::fg_366(%para60)    #(Undefined)    # fg_366=↓decay_weight.366 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(317)/        if self.exec_weight_decay:/#[CNode]365
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(317)/        if self.exec_weight_decay:/#[CNode]467
}
# order:
#   1: ↓✓decay_weight.371:[CNode]365{[0]: ValueNode<FuncGraph> ↓decay_weight.366, [1]: Φgradients}
#   2: ↓✓decay_weight.371:[CNode]467{[0]: ValueNode<Primitive> Return, [1]: [CNode]365}


# [No.67] L-✓↓construct.517
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
funcgraph fg_517[fg_516](
) {
    %1 = $(L-↓construct.516):DoSignaturePrimitive::S-Prim-MatMul{prim_type=1}[output_names=["output"], transpose_a=Bool(0), input_names=["x1", "x2"], transpose_b=Bool(1)](%para54, %para42)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(324)/        x = self.matmul(x, self.weight)/#x
    %2 = DoSignaturePrimitive::S-Prim-BiasAdd{prim_type=1}[output_names=["output"], format="NCHW", input_names=["x", "b"]](%1, %para41)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(326)/            x = self.bias_add(x, self.bias)/#x
    %3 = FuncGraph::fg_513(%2)    #(Undefined)    # fg_513=L-↓↓construct.513 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]131
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]458
}
# order:
#   1: L-✓↓construct.517:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-BiasAdd, [1]: x, [2]: L-fc3.bias}
#   2: L-✓↓construct.517:[CNode]131{[0]: ValueNode<FuncGraph> L-↓↓construct.513, [1]: x}
#   3: L-✓↓construct.517:[CNode]458{[0]: ValueNode<Primitive> Return, [1]: [CNode]131}


# [No.68] L-✗↓construct.518
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
funcgraph fg_518[fg_516](
) {
    %1 = $(L-↓construct.516):DoSignaturePrimitive::S-Prim-MatMul{prim_type=1}[output_names=["output"], transpose_a=Bool(0), input_names=["x1", "x2"], transpose_b=Bool(1)](%para54, %para42)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(324)/        x = self.matmul(x, self.weight)/#x
    %2 = FuncGraph::fg_513(%1)    #(Undefined)    # fg_513=L-↓↓construct.513 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]132
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]459
}
# order:
#   1: L-✗↓construct.518:[CNode]132{[0]: ValueNode<FuncGraph> L-↓↓construct.513, [1]: x}
#   2: L-✗↓construct.518:[CNode]459{[0]: ValueNode<Primitive> Return, [1]: [CNode]132}


# [No.69] get_axis.61
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(69)/    def get_axis(self, x):/
funcgraph fg_61(
        %para61    # x
    ) {
    %1 = DoSignaturePrimitive::S-Prim-Shape{prim_type=1}(%para61)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(100)/        shape = F.shape(x)/#shape
    %2 = DoSignaturePrimitive::S-Prim-tuple_len{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(101)/        length = F.tuple_len(shape)/#length
    %3 = DoSignaturePrimitive::S-Prim-make_range{prim_type=1}(I64(0), %2)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(102)/        perm = F.make_range(0, length)/#perm
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(103)/        return perm/#[CNode]471
}
# order:
#   1: get_axis.61:shape{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Shape, [1]: x}
#   2: get_axis.61:length{[0]: ValueNode<DoSignaturePrimitive> S-Prim-tuple_len, [1]: shape}
#   3: get_axis.61:perm{[0]: ValueNode<DoSignaturePrimitive> S-Prim-make_range, [1]: ValueNode<Int64Imm> 0, [2]: length}
#   4: get_axis.61:[CNode]471{[0]: ValueNode<Primitive> Return, [1]: perm}


# [No.70] ↓get_loss.62
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/
funcgraph fg_62[fg_59](
        %para62    # Φx
    ) {
    %1 = FuncGraph::fg_42(Bool(1))    #(Undefined)    # fg_42=bool_.42 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]52
    %2 = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_55, FuncGraph::fg_56)    #(Undefined, Undefined, Undefined)    # fg_55=↰↓get_loss.55, fg_56=↱↓get_loss.56 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]54
    %3 = %2() #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]57
    %4 = FuncGraph::fg_42(%3)    #(Undefined)    # fg_42=bool_.42 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]58
    %5 = Primitive::Switch{prim_type=1}(%4, FuncGraph::fg_67, FuncGraph::fg_68)    #(Undefined, Undefined, Undefined)    # fg_67=✓↓get_loss.67, fg_68=✗↓get_loss.68 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]66
    %6 = %5() #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]69
    Primitive::Return{prim_type=1}(%6)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]472
}
# order:
#   1: ↓get_loss.62:[CNode]52{[0]: ValueNode<FuncGraph> bool_.42, [1]: ValueNode<BoolImm> true}
#   2: ↓get_loss.62:[CNode]54{[0]: ValueNode<Primitive> Switch, [1]: [CNode]52, [2]: ValueNode<FuncGraph> ↰↓get_loss.55, [3]: ValueNode<FuncGraph> ↱↓get_loss.56}
#   3: ↓get_loss.62:[CNode]57{[0]: [CNode]54}
#   4: ↓get_loss.62:[CNode]58{[0]: ValueNode<FuncGraph> bool_.42, [1]: [CNode]57}
#   5: ↓get_loss.62:[CNode]66{[0]: ValueNode<Primitive> Switch, [1]: [CNode]58, [2]: ValueNode<FuncGraph> ✓↓get_loss.67, [3]: ValueNode<FuncGraph> ✗↓get_loss.68}
#   6: ↓get_loss.62:[CNode]69{[0]: [CNode]66}
#   7: ↓get_loss.62:[CNode]472{[0]: ValueNode<Primitive> Return, [1]: [CNode]69}


# [No.71] ms_iter.308
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1429)/def ms_iter(xs):/
funcgraph fg_308(
        %para63    # xs
    ) {
    %1 = Primitive::getattr{prim_type=1}(%para63, "__ms_iter__")    #(Undefined, Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1431)/    return xs.__ms_iter__()/#[CNode]306
    %2 = %1() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1431)/    return xs.__ms_iter__()/#[CNode]307
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1431)/    return xs.__ms_iter__()/#[CNode]473
}
# order:
#   1: ms_iter.308:[CNode]306{[0]: ValueNode<Primitive> getattr, [1]: xs, [2]: ValueNode<StringImm> __ms_iter__}
#   2: ms_iter.308:[CNode]307{[0]: [CNode]306}
#   3: ms_iter.308:[CNode]473{[0]: ValueNode<Primitive> Return, [1]: [CNode]307}


# [No.72] ⤾✓✓✓get_lr.290
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/
funcgraph fg_290(
        %para64    # @learning_rate
        , %para65    # Φlr
    ) {
    %1 = FuncGraph::fg_285(%para64)    #(Undefined)    # fg_285=hasnext.285 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]284
    %2 = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_303, FuncGraph::fg_304)    #(Undefined, Undefined, Undefined)    # fg_303=⥁✓✓✓get_lr.303, fg_304=↓✓✓✓get_lr.304 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]302
    %3 = %2() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]305
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]474
}
# order:
#   1: ⤾✓✓✓get_lr.290:[CNode]284{[0]: ValueNode<FuncGraph> hasnext.285, [1]: @learning_rate}
#   2: ⤾✓✓✓get_lr.290:[CNode]302{[0]: ValueNode<Primitive> Switch, [1]: [CNode]284, [2]: ValueNode<FuncGraph> ⥁✓✓✓get_lr.303, [3]: ValueNode<FuncGraph> ↓✓✓✓get_lr.304}
#   3: ⤾✓✓✓get_lr.290:[CNode]305{[0]: [CNode]302}
#   4: ⤾✓✓✓get_lr.290:[CNode]474{[0]: ValueNode<Primitive> Return, [1]: [CNode]305}


# [No.73] ⤾✗✓✓get_lr.319
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/
funcgraph fg_319[fg_315](
        %para66    # @[CNode]313
        , %para67    # Φlr
    ) {
    %1 = ClassType() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]310
    %2 = $(✗✓✓get_lr.315):ClassType() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]311
    %3 = $(✗✓✓get_lr.315):FuncGraph::fg_101(%para19)    #(Ref[Tensor(F32)][])    # fg_101=ms_len.101 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]312
    %4 = $(✗✓✓get_lr.315):%2(%3)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#@[CNode]313
    %5 = %1(%para66, %4)    #(Undefined, Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]314
    %6 = Primitive::Switch{prim_type=1}(%5, FuncGraph::fg_324, FuncGraph::fg_325)    #(Undefined, Undefined, Undefined)    # fg_324=⥁✗✓✓get_lr.324, fg_325=↓✗✓✓get_lr.325 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]323
    %7 = %6() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]326
    Primitive::Return{prim_type=1}(%7)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]475
}
# order:
#   1: ⤾✗✓✓get_lr.319:[CNode]310{[0]: ValueNode<ClassType> class 'mindspore.ops.operations.math_ops.Less'}
#   2: ⤾✗✓✓get_lr.319:[CNode]314{[0]: [CNode]310, [1]: @[CNode]313, [2]: @[CNode]313}
#   3: ⤾✗✓✓get_lr.319:[CNode]323{[0]: ValueNode<Primitive> Switch, [1]: [CNode]314, [2]: ValueNode<FuncGraph> ⥁✗✓✓get_lr.324, [3]: ValueNode<FuncGraph> ↓✗✓✓get_lr.325}
#   4: ⤾✗✓✓get_lr.319:[CNode]326{[0]: [CNode]323}
#   5: ⤾✗✓✓get_lr.319:[CNode]475{[0]: ValueNode<Primitive> Return, [1]: [CNode]326}


# [No.74] L-↓↓construct.513
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
funcgraph fg_513[fg_508](
        %para68    # Φx
    ) {
    %1 = FuncGraph::fg_507(Bool(0))    #(Undefined)    # fg_507=L-bool_.507 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]105
    %2 = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_514, FuncGraph::fg_515)    #(Undefined, Undefined, Undefined)    # fg_514=L-✓↓↓construct.514, fg_515=L-✗↓↓construct.515 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]126
    %3 = %2() #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]129
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]470
}
# order:
#   1: L-↓↓construct.513:[CNode]105{[0]: ValueNode<FuncGraph> L-bool_.507, [1]: ValueNode<BoolImm> false}
#   2: L-↓↓construct.513:[CNode]126{[0]: ValueNode<Primitive> Switch, [1]: [CNode]105, [2]: ValueNode<FuncGraph> L-✓↓↓construct.514, [3]: ValueNode<FuncGraph> L-✗↓↓construct.515}
#   3: L-↓↓construct.513:[CNode]129{[0]: [CNode]126}
#   4: L-↓↓construct.513:[CNode]470{[0]: ValueNode<Primitive> Return, [1]: [CNode]129}


# [No.75] ↰↓get_loss.55
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/
funcgraph fg_55(
) {
    %1 = DoSignaturePrimitive::S-Prim-logical_not{prim_type=1}(Bool(1))    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]53
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]482
}
# order:
#   1: ↰↓get_loss.55:[CNode]53{[0]: ValueNode<DoSignaturePrimitive> S-Prim-logical_not, [1]: ValueNode<BoolImm> true}
#   2: ↰↓get_loss.55:[CNode]482{[0]: ValueNode<Primitive> Return, [1]: [CNode]53}


# [No.76] ↱↓get_loss.56
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/
funcgraph fg_56(
) {
    Primitive::Return{prim_type=1}(Bool(1))    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]483
}
# order:
#   1: ↱↓get_loss.56:[CNode]483{[0]: ValueNode<Primitive> Return, [1]: ValueNode<BoolImm> true}


# [No.77] ✓↓get_loss.67
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/
funcgraph fg_67[fg_62](
) {
    %1 = FuncGraph::fg_61(%para62)    #(Undefined)    # fg_61=get_axis.61 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(147)/            x = self.reduce_sum(x, self.get_axis(x))/#[CNode]60
    %2 = DoSignaturePrimitive::S-Prim-ReduceSum{prim_type=1}[output_names=["y"], keep_dims=Bool(0), input_names=["input_x", "axis"]](%para62, %1)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(147)/            x = self.reduce_sum(x, self.get_axis(x))/#x
    %3 = FuncGraph::fg_64(%2)    #(Undefined)    # fg_64=↓↓get_loss.64 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]63
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]484
}
# order:
#   1: ✓↓get_loss.67:[CNode]60{[0]: ValueNode<FuncGraph> get_axis.61, [1]: Φx}
#   2: ✓↓get_loss.67:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-ReduceSum, [1]: Φx, [2]: [CNode]60}
#   3: ✓↓get_loss.67:[CNode]63{[0]: ValueNode<FuncGraph> ↓↓get_loss.64, [1]: x}
#   4: ✓↓get_loss.67:[CNode]484{[0]: ValueNode<Primitive> Return, [1]: [CNode]63}


# [No.78] ✗↓get_loss.68
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/
funcgraph fg_68[fg_62](
) {
    %1 = FuncGraph::fg_64(%para62)    #(Undefined)    # fg_64=↓↓get_loss.64 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]65
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]485
}
# order:
#   1: ✗↓get_loss.68:[CNode]65{[0]: ValueNode<FuncGraph> ↓↓get_loss.64, [1]: Φx}
#   2: ✗↓get_loss.68:[CNode]485{[0]: ValueNode<Primitive> Return, [1]: [CNode]65}


# [No.79] hasnext.285
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1439)/def hasnext(it):/
funcgraph fg_285(
        %para69    # it
    ) {
    %1 = Primitive::getattr{prim_type=1}(%para69, "__ms_hasnext__")    #(Undefined, Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1441)/    return it.__ms_hasnext__()/#[CNode]282
    %2 = %1() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1441)/    return it.__ms_hasnext__()/#[CNode]283
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1441)/    return it.__ms_hasnext__()/#[CNode]486
}
# order:
#   1: hasnext.285:[CNode]282{[0]: ValueNode<Primitive> getattr, [1]: it, [2]: ValueNode<StringImm> __ms_hasnext__}
#   2: hasnext.285:[CNode]283{[0]: [CNode]282}
#   3: hasnext.285:[CNode]486{[0]: ValueNode<Primitive> Return, [1]: [CNode]283}


# [No.80] ⥁✓✓✓get_lr.303
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/
funcgraph fg_303[fg_290](
) {
    %1 = FuncGraph::fg_289(%para64)    #(Undefined)    # fg_289=ms_next.289 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]288
    %2 = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%1, I64(1))    #(Undefined, Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#@learning_rate
    %3 = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%1, I64(0))    #(Undefined, Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#learning_rate
    %4 = %3(None)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(591)/                    current_dynamic_lr = learning_rate(self.global_step)/#current_dynamic_lr
    %5 = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%4)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(592)/                    lr += (current_dynamic_lr,)/#[CNode]291
    %6 = DoSignaturePrimitive::S-Prim-add{prim_type=1}(%para65, %5)    #(Undefined, Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(592)/                    lr += (current_dynamic_lr,)/#lr
    %7 = FuncGraph::fg_290(%2, %6)    #(Undefined, Undefined)    # fg_290=⤾✓✓✓get_lr.290 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]292
    Primitive::Return{prim_type=1}(%7)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]487
}
# order:
#   1: ⥁✓✓✓get_lr.303:[CNode]288{[0]: ValueNode<FuncGraph> ms_next.289, [1]: @learning_rate}
#   2: ⥁✓✓✓get_lr.303:learning_rate{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: [CNode]288, [2]: ValueNode<Int64Imm> 0}
#   3: ⥁✓✓✓get_lr.303:@learning_rate{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: [CNode]288, [2]: ValueNode<Int64Imm> 1}
#   4: ⥁✓✓✓get_lr.303:current_dynamic_lr{[0]: learning_rate, [1]: ValueNode<None> None}
#   5: ⥁✓✓✓get_lr.303:[CNode]291{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: current_dynamic_lr}
#   6: ⥁✓✓✓get_lr.303:lr{[0]: ValueNode<DoSignaturePrimitive> S-Prim-add, [1]: Φlr, [2]: [CNode]291}
#   7: ⥁✓✓✓get_lr.303:[CNode]292{[0]: ValueNode<FuncGraph> ⤾✓✓✓get_lr.290, [1]: @learning_rate, [2]: lr}
#   8: ⥁✓✓✓get_lr.303:[CNode]487{[0]: ValueNode<Primitive> Return, [1]: [CNode]292}


# [No.81] ↓✓✓✓get_lr.304
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/
funcgraph fg_304[fg_290](
) {
    %1 = FuncGraph::fg_301(None, None, Tensor(34)[], %para65)    #(Undefined, Undefined, Undefined, Undefined)    # fg_301=↓✓✓get_lr.301 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]300
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]488
}
# order:
#   1: ↓✓✓✓get_lr.304:[CNode]300{[0]: ValueNode<FuncGraph> ↓✓✓get_lr.301, [1]: ValueNode<None> None, [2]: ValueNode<None> None, [3]: ValueNode<Tensor> Tensor(shape=[], dtype=Int32, value=1), [4]: Φlr}
#   2: ↓✓✓✓get_lr.304:[CNode]488{[0]: ValueNode<Primitive> Return, [1]: [CNode]300}


# [No.82] ⥁✗✓✓get_lr.324
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/
funcgraph fg_324[fg_319](
) {
    %1 = ClassType() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]316
    %2 = ClassType() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]317
    %3 = %2(I64(1))    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]318
    %4 = %1(%para66, %3)    #(Undefined, Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]313
    %5 = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%para19, %para66)    #(Ref[Tensor(F32)][], Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#learning_rate
    %6 = %5(None)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(591)/                    current_dynamic_lr = learning_rate(self.global_step)/#current_dynamic_lr
    %7 = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%6)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(592)/                    lr += (current_dynamic_lr,)/#[CNode]320
    %8 = DoSignaturePrimitive::S-Prim-add{prim_type=1}(%para67, %7)    #(Undefined, Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(592)/                    lr += (current_dynamic_lr,)/#lr
    %9 = FuncGraph::fg_319(%4, %8)    #(Undefined, Undefined)    # fg_319=⤾✗✓✓get_lr.319 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]321
    Primitive::Return{prim_type=1}(%9)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]489
}
# order:
#   1: ⥁✗✓✓get_lr.324:learning_rate{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: learning_rate, [2]: @[CNode]313}
#   2: ⥁✗✓✓get_lr.324:[CNode]316{[0]: ValueNode<ClassType> class 'mindspore.ops.operations.math_ops.Add'}
#   3: ⥁✗✓✓get_lr.324:[CNode]317{[0]: ValueNode<ClassType> class 'mindspore.ops.operations.array_ops.ScalarToTensor'}
#   4: ⥁✗✓✓get_lr.324:[CNode]318{[0]: [CNode]317, [1]: ValueNode<Int64Imm> 1}
#   5: ⥁✗✓✓get_lr.324:[CNode]313{[0]: [CNode]316, [1]: @[CNode]313, [2]: [CNode]318}
#   6: ⥁✗✓✓get_lr.324:current_dynamic_lr{[0]: learning_rate, [1]: ValueNode<None> None}
#   7: ⥁✗✓✓get_lr.324:[CNode]320{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: current_dynamic_lr}
#   8: ⥁✗✓✓get_lr.324:lr{[0]: ValueNode<DoSignaturePrimitive> S-Prim-add, [1]: Φlr, [2]: [CNode]320}
#   9: ⥁✗✓✓get_lr.324:[CNode]321{[0]: ValueNode<FuncGraph> ⤾✗✓✓get_lr.319, [1]: [CNode]313, [2]: lr}
#  10: ⥁✗✓✓get_lr.324:[CNode]489{[0]: ValueNode<Primitive> Return, [1]: [CNode]321}


# [No.83] ↓✗✓✓get_lr.325
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/
funcgraph fg_325[fg_319](
) {
    %1 = FuncGraph::fg_301(None, None, Tensor(34)[], %para67)    #(Undefined, Undefined, Undefined, Undefined)    # fg_301=↓✓✓get_lr.301 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]322
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/#[CNode]490
}
# order:
#   1: ↓✗✓✓get_lr.325:[CNode]322{[0]: ValueNode<FuncGraph> ↓✓✓get_lr.301, [1]: ValueNode<None> None, [2]: ValueNode<None> None, [3]: ValueNode<Tensor> Tensor(shape=[], dtype=Int32, value=1), [4]: Φlr}
#   2: ↓✗✓✓get_lr.325:[CNode]490{[0]: ValueNode<Primitive> Return, [1]: [CNode]322}


# [No.84] L-✓↓↓construct.514
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
funcgraph fg_514[fg_513](
) {
    %1 = None(%para68)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(328)/            x = self.activation(x)/#x
    %2 = FuncGraph::fg_509(%1)    #(Undefined)    # fg_509=L-↓↓↓construct.509 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]124
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]480
}
# order:
#   1: L-✓↓↓construct.514:x{[0]: ValueNode<None> None, [1]: Φx}
#   2: L-✓↓↓construct.514:[CNode]124{[0]: ValueNode<FuncGraph> L-↓↓↓construct.509, [1]: x}
#   3: L-✓↓↓construct.514:[CNode]480{[0]: ValueNode<Primitive> Return, [1]: [CNode]124}


# [No.85] L-✗↓↓construct.515
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
funcgraph fg_515[fg_513](
) {
    %1 = FuncGraph::fg_509(%para68)    #(Undefined)    # fg_509=L-↓↓↓construct.509 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]125
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]481
}
# order:
#   1: L-✗↓↓construct.515:[CNode]125{[0]: ValueNode<FuncGraph> L-↓↓↓construct.509, [1]: Φx}
#   2: L-✗↓↓construct.515:[CNode]481{[0]: ValueNode<Primitive> Return, [1]: [CNode]125}


# [No.86] ↓↓get_loss.64
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/
funcgraph fg_64[fg_59](
        %para70    # Φx
    ) {
    %1 = $(get_loss.59):Primitive::getattr{prim_type=1}(%para48, "dtype")    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(148)/        x = self.cast(x, input_dtype)/#Φinput_dtype
    %2 = DoSignaturePrimitive::S-Prim-Cast{prim_type=1}[output_names=["output"], input_names=["x", "dst_type"]](%para70, %1)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(148)/        x = self.cast(x, input_dtype)/#x
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(149)/        return x/#[CNode]494
}
# order:
#   1: ↓↓get_loss.64:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Cast, [1]: Φx, [2]: Φinput_dtype}
#   2: ↓↓get_loss.64:[CNode]494{[0]: ValueNode<Primitive> Return, [1]: x}


# [No.87] ms_next.289
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1434)/def ms_next(it):/
funcgraph fg_289(
        %para71    # it
    ) {
    %1 = Primitive::getattr{prim_type=1}(%para71, "__ms_next__")    #(Undefined, Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1436)/    return it.__ms_next__()/#[CNode]286
    %2 = %1() #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1436)/    return it.__ms_next__()/#[CNode]287
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1436)/    return it.__ms_next__()/#[CNode]495
}
# order:
#   1: ms_next.289:[CNode]286{[0]: ValueNode<Primitive> getattr, [1]: it, [2]: ValueNode<StringImm> __ms_next__}
#   2: ms_next.289:[CNode]287{[0]: [CNode]286}
#   3: ms_next.289:[CNode]495{[0]: ValueNode<Primitive> Return, [1]: [CNode]287}


# [No.88] ↓✓✓get_lr.301
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(590)/                for learning_rate in self.learning_rate:/
funcgraph fg_301(
        %para72    # Φself.assignadd
        , %para73    # Φself.global_step
        , %para74    # Φself.global_step_increase_tensor
        , %para75    # Φlr
    ) {
    %1 = FuncGraph::fg_299(%para72, %para73, %para74, %para75)    #(Undefined, Undefined, Undefined, Undefined)    # fg_299=↓✓get_lr.299 #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(588)/            if self.is_group_lr:/#[CNode]298
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/optimizer-Momentum
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\optim\optimizer.py(588)/            if self.is_group_lr:/#[CNode]496
}
# order:
#   1: ↓✓✓get_lr.301:[CNode]298{[0]: ValueNode<FuncGraph> ↓✓get_lr.299, [1]: Φself.assignadd, [2]: Φself.global_step, [3]: Φself.global_step_increase_tensor, [4]: Φlr}
#   2: ↓✓✓get_lr.301:[CNode]496{[0]: ValueNode<Primitive> Return, [1]: [CNode]298}


# [No.89] L-↓↓↓construct.509
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
funcgraph fg_509[fg_508](
        %para76    # Φx
    ) {
    %1 = $(L-construct.508):DoSignaturePrimitive::S-Prim-Shape{prim_type=1}(%para40)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#Φx_shape
    %2 = FuncGraph::fg_506(%1)    #(Undefined)    # fg_506=L-ms_len.506 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]106
    %3 = DoSignaturePrimitive::S-Prim-not_equal{prim_type=1}(%2, I64(2))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]108
    %4 = FuncGraph::fg_507(%3)    #(Undefined)    # fg_507=L-bool_.507 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]109
    %5 = Primitive::Switch{prim_type=1}(%4, FuncGraph::fg_511, FuncGraph::fg_512)    #(Undefined, Undefined, Undefined)    # fg_511=L-✓↓↓↓construct.511, fg_512=L-✗↓↓↓construct.512 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]119
    %6 = %5() #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]122
    Primitive::Return{prim_type=1}(%6)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]493
}
# order:
#   1: L-↓↓↓construct.509:[CNode]106{[0]: ValueNode<FuncGraph> L-ms_len.506, [1]: Φx_shape}
#   2: L-↓↓↓construct.509:[CNode]108{[0]: ValueNode<DoSignaturePrimitive> S-Prim-not_equal, [1]: [CNode]106, [2]: ValueNode<Int64Imm> 2}
#   3: L-↓↓↓construct.509:[CNode]109{[0]: ValueNode<FuncGraph> L-bool_.507, [1]: [CNode]108}
#   4: L-↓↓↓construct.509:[CNode]119{[0]: ValueNode<Primitive> Switch, [1]: [CNode]109, [2]: ValueNode<FuncGraph> L-✓↓↓↓construct.511, [3]: ValueNode<FuncGraph> L-✗↓↓↓construct.512}
#   5: L-↓↓↓construct.509:[CNode]122{[0]: [CNode]119}
#   6: L-↓↓↓construct.509:[CNode]493{[0]: ValueNode<Primitive> Return, [1]: [CNode]122}


# [No.90] L-✓↓↓↓construct.511
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
funcgraph fg_511[fg_509](
) {
    %1 = $(L-construct.508):DoSignaturePrimitive::S-Prim-Shape{prim_type=1}(%para40)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#Φx_shape
    %2 = DoSignaturePrimitive::S-Prim-negative{prim_type=1}(I64(1))    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(330)/            out_shape = x_shape[:-1] + (-1,)/#[CNode]110
    %3 = DoSignaturePrimitive::S-Prim-make_slice{prim_type=1}(None, %2, None)    #(Undefined, Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(330)/            out_shape = x_shape[:-1] + (-1,)/#[CNode]111
    %4 = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%1, %3)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(330)/            out_shape = x_shape[:-1] + (-1,)/#[CNode]112
    %5 = DoSignaturePrimitive::S-Prim-negative{prim_type=1}(I64(1))    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(330)/            out_shape = x_shape[:-1] + (-1,)/#[CNode]113
    %6 = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%5)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(330)/            out_shape = x_shape[:-1] + (-1,)/#[CNode]114
    %7 = DoSignaturePrimitive::S-Prim-add{prim_type=1}(%4, %6)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(330)/            out_shape = x_shape[:-1] + (-1,)/#out_shape
    %8 = DoSignaturePrimitive::S-Prim-Reshape{prim_type=1}[output_names=["output"], input_names=["tensor", "shape"]](%para76, %7)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(331)/            x = self.reshape(x, out_shape)/#x
    %9 = FuncGraph::fg_510(%8)    #(Undefined)    # fg_510=L-↓↓↓↓construct.510 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]116
    Primitive::Return{prim_type=1}(%9)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]501
}
# order:
#   1: L-✓↓↓↓construct.511:[CNode]110{[0]: ValueNode<DoSignaturePrimitive> S-Prim-negative, [1]: ValueNode<Int64Imm> 1}
#   2: L-✓↓↓↓construct.511:[CNode]111{[0]: ValueNode<DoSignaturePrimitive> S-Prim-make_slice, [1]: ValueNode<None> None, [2]: [CNode]110, [3]: ValueNode<None> None}
#   3: L-✓↓↓↓construct.511:[CNode]112{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: Φx_shape, [2]: [CNode]111}
#   4: L-✓↓↓↓construct.511:[CNode]113{[0]: ValueNode<DoSignaturePrimitive> S-Prim-negative, [1]: ValueNode<Int64Imm> 1}
#   5: L-✓↓↓↓construct.511:[CNode]114{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: [CNode]113}
#   6: L-✓↓↓↓construct.511:out_shape{[0]: ValueNode<DoSignaturePrimitive> S-Prim-add, [1]: [CNode]112, [2]: [CNode]114}
#   7: L-✓↓↓↓construct.511:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Reshape, [1]: Φx, [2]: out_shape}
#   8: L-✓↓↓↓construct.511:[CNode]116{[0]: ValueNode<FuncGraph> L-↓↓↓↓construct.510, [1]: x}
#   9: L-✓↓↓↓construct.511:[CNode]501{[0]: ValueNode<Primitive> Return, [1]: [CNode]116}


# [No.91] L-✗↓↓↓construct.512
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
funcgraph fg_512[fg_509](
) {
    %1 = FuncGraph::fg_510(%para76)    #(Undefined)    # fg_510=L-↓↓↓↓construct.510 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]118
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]502
}
# order:
#   1: L-✗↓↓↓construct.512:[CNode]118{[0]: ValueNode<FuncGraph> L-↓↓↓↓construct.510, [1]: Φx}
#   2: L-✗↓↓↓construct.512:[CNode]502{[0]: ValueNode<Primitive> Return, [1]: [CNode]118}


# [No.92] L-↓↓↓↓construct.510
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
funcgraph fg_510(
        %para77    # Φx
    ) {
    Primitive::Return{prim_type=1}(%para77)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(332)/        return x/#[CNode]505
}
# order:
#   1: L-↓↓↓↓construct.510:[CNode]505{[0]: ValueNode<Primitive> Return, [1]: Φx}


# num of total function graphs: 92