# [No.1] construct_wrapper.911
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(665)/    def construct(self, data, label):/
funcgraph fg_911(
        %para1    # data
        , %para2    # label
        , %para3 : Ref[Tensor(F32)][10]    # fc3.bias
        , %para4 : Ref[Tensor(F32)][10, 84]    # fc3.weight
        , %para5 : Ref[Tensor(F32)][84]    # fc2.bias
        , %para6 : Ref[Tensor(F32)][84, 120]    # fc2.weight
        , %para7 : Ref[Tensor(F32)][16, 6, 5, 5]    # conv2.weight
        , %para8 : Ref[Tensor(F32)][120]    # fc1.bias
        , %para9 : Ref[Tensor(F32)][120, 400]    # fc1.weight
        , %para10 : Ref[Tensor(F32)][6, 1, 5, 5]    # conv1.weight
    ) {
    %1 = FuncGraph::fg_920(%para1, %para2)    #(Undefined, Undefined)    # fg_920=construct.920 #scope: Default
#[CNode]933
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(667)/        if self.add_cast_fp32:/#[CNode]934
}
# order:
#   1: construct_wrapper.911:[CNode]933{[0]: ValueNode<FuncGraph> construct.920, [1]: data, [2]: label}
#   2: construct_wrapper.911:[CNode]934{[0]: ValueNode<Primitive> Return, [1]: [CNode]933}


# [No.2] construct.920
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(665)/    def construct(self, data, label):/
funcgraph fg_920[fg_911](
        %para11    # data
        , %para12    # label
    ) {
    %1 = FuncGraph::fg_949(Bool(0))    #(Undefined)    # fg_949=bool_.949 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(667)/        if self.add_cast_fp32:/#[CNode]914
    %2 = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_930, FuncGraph::fg_931)    #(Undefined, Undefined, Undefined)    # fg_930=✓construct.930, fg_931=✗construct.931 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(667)/        if self.add_cast_fp32:/#[CNode]929
    %3 = %2() #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(667)/        if self.add_cast_fp32:/#[CNode]932
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(667)/        if self.add_cast_fp32:/#[CNode]935
}
# order:
#   1: construct.920:outputs{[0]: ValueNode<FuncGraph> construct.1185, [1]: data}
#   2: construct.920:[CNode]914{[0]: ValueNode<FuncGraph> bool_.949, [1]: ValueNode<BoolImm> false}
#   3: construct.920:[CNode]929{[0]: ValueNode<Primitive> Switch, [1]: [CNode]914, [2]: ValueNode<FuncGraph> ✓construct.930, [3]: ValueNode<FuncGraph> ✗construct.931}
#   4: construct.920:[CNode]932{[0]: [CNode]929}
#   5: construct.920:[CNode]935{[0]: ValueNode<Primitive> Return, [1]: [CNode]932}


# [No.3] bool_.949
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1479)/def bool_(x):/
funcgraph fg_949(
        %para13    # x
    ) {
    %1 = Primitive::getattr{prim_type=1}(%para13, "__bool__")    #(Undefined, Undefined) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1481)/    return x.__bool__()/#[CNode]947
    %2 = %1() #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1481)/    return x.__bool__()/#[CNode]948
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1481)/    return x.__bool__()/#[CNode]1186
}
# order:
#   1: bool_.949:[CNode]947{[0]: ValueNode<Primitive> getattr, [1]: x, [2]: ValueNode<StringImm> __bool__}
#   2: bool_.949:[CNode]948{[0]: [CNode]947}
#   3: bool_.949:[CNode]1186{[0]: ValueNode<Primitive> Return, [1]: [CNode]948}


# [No.4] ✓construct.930
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(667)/        if self.add_cast_fp32:/
funcgraph fg_930[fg_920](
) {
    %1 = $(construct.920):FuncGraph::fg_1185(%para11)    #(Undefined)    # fg_1185=construct.1185 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(666)/        outputs = self._network(data)/#outputs
    %2 = DoSignaturePrimitive::S-Prim-Cast{prim_type=1}[output_names=["output"], input_names=["x", "dst_type"]](%1, F32)    #(Undefined, Undefined) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(669)/            outputs = F.cast(outputs, mstype.float32)/#outputs
    %3 = DoSignaturePrimitive::S-Prim-mixed_precision_cast{prim_type=1}(F32, %para12)    #(Undefined, Undefined) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(668)/            label = F.mixed_precision_cast(mstype.float32, label)/#label
    %4 = FuncGraph::fg_927(%2, %3)    #(Undefined, Undefined)    # fg_927=↓construct.927 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(667)/        if self.add_cast_fp32:/#[CNode]926
    Primitive::Return{prim_type=1}(%4)    #(Undefined) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(667)/        if self.add_cast_fp32:/#[CNode]938
}
# order:
#   1: ✓construct.930:label{[0]: ValueNode<DoSignaturePrimitive> S-Prim-mixed_precision_cast, [1]: ValueNode<Float> Float32, [2]: label}
#   2: ✓construct.930:outputs{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Cast, [1]: outputs, [2]: ValueNode<Float> Float32}
#   3: ✓construct.930:[CNode]926{[0]: ValueNode<FuncGraph> ↓construct.927, [1]: outputs, [2]: label}
#   4: ✓construct.930:[CNode]938{[0]: ValueNode<Primitive> Return, [1]: [CNode]926}


# [No.5] ✗construct.931
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(667)/        if self.add_cast_fp32:/
funcgraph fg_931[fg_920](
) {
    %1 = $(construct.920):FuncGraph::fg_1185(%para11)    #(Undefined)    # fg_1185=construct.1185 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(666)/        outputs = self._network(data)/#outputs
    %2 = FuncGraph::fg_927(%1, %para12)    #(Undefined, Undefined)    # fg_927=↓construct.927 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(667)/        if self.add_cast_fp32:/#[CNode]928
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(667)/        if self.add_cast_fp32:/#[CNode]943
}
# order:
#   1: ✗construct.931:[CNode]928{[0]: ValueNode<FuncGraph> ↓construct.927, [1]: outputs, [2]: label}
#   2: ✗construct.931:[CNode]943{[0]: ValueNode<Primitive> Return, [1]: [CNode]928}


# [No.6] construct.1185
# In file D:\PythonCode\LeNet\lenet.py(39)/    def construct(self, x):/
funcgraph fg_1185[fg_911](
        %para14    # x
    ) {
    %1 = FuncGraph::fg_1174(%para14)    #(Undefined)    # fg_1174=construct.1174 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(41)/        x = self.conv1(x)/#x
    %2 = FuncGraph::fg_1182(%1)    #(Undefined)    # fg_1182=construct.1182 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(42)/        x = self.relu(x)/#x
    %3 = FuncGraph::fg_1183(%2)    #(Undefined)    # fg_1183=construct.1183 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(43)/        x = self.max_pool2d(x)/#x
    %4 = FuncGraph::fg_1165(%3)    #(Undefined)    # fg_1165=construct.1165 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(44)/        x = self.conv2(x)/#x
    %5 = FuncGraph::fg_1182(%4)    #(Undefined)    # fg_1182=construct.1182 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(45)/        x = self.relu(x)/#x
    %6 = FuncGraph::fg_1183(%5)    #(Undefined)    # fg_1183=construct.1183 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(46)/        x = self.max_pool2d(x)/#x
    %7 = FuncGraph::fg_1184(%6)    #(Undefined)    # fg_1184=construct.1184 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(47)/        x = self.flatten(x)/#x
    %8 = FuncGraph::fg_1118(%7)    #(Undefined)    # fg_1118=construct.1118 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(48)/        x = self.fc1(x)/#x
    %9 = FuncGraph::fg_1182(%8)    #(Undefined)    # fg_1182=construct.1182 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(49)/        x = self.relu(x)/#x
    %10 = FuncGraph::fg_1069(%9)    #(Undefined)    # fg_1069=construct.1069 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(50)/        x = self.fc2(x)/#x
    %11 = FuncGraph::fg_1182(%10)    #(Undefined)    # fg_1182=construct.1182 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(51)/        x = self.relu(x)/#x
    %12 = FuncGraph::fg_1019(%11)    #(Undefined)    # fg_1019=construct.1019 #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(52)/        x = self.fc3(x)/#x
    Primitive::Return{prim_type=1}(%12)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5
      # In file D:\PythonCode\LeNet\lenet.py(53)/        return x/#[CNode]1187
}
# order:
#   1: construct.1185:x{[0]: ValueNode<FuncGraph> construct.1174, [1]: x}
#   2: construct.1185:x{[0]: ValueNode<FuncGraph> construct.1182, [1]: x}
#   3: construct.1185:x{[0]: ValueNode<FuncGraph> construct.1183, [1]: x}
#   4: construct.1185:x{[0]: ValueNode<FuncGraph> construct.1165, [1]: x}
#   5: construct.1185:x{[0]: ValueNode<FuncGraph> construct.1182, [1]: x}
#   6: construct.1185:x{[0]: ValueNode<FuncGraph> construct.1183, [1]: x}
#   7: construct.1185:x{[0]: ValueNode<FuncGraph> construct.1184, [1]: x}
#   8: construct.1185:x{[0]: ValueNode<FuncGraph> construct.1118, [1]: x}
#   9: construct.1185:x{[0]: ValueNode<FuncGraph> construct.1182, [1]: x}
#  10: construct.1185:x{[0]: ValueNode<FuncGraph> construct.1069, [1]: x}
#  11: construct.1185:x{[0]: ValueNode<FuncGraph> construct.1182, [1]: x}
#  12: construct.1185:x{[0]: ValueNode<FuncGraph> construct.1019, [1]: x}
#  13: construct.1185:[CNode]1187{[0]: ValueNode<Primitive> Return, [1]: x}


# [No.7] ↓construct.927
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(667)/        if self.add_cast_fp32:/
funcgraph fg_927(
        %para15    # Φoutputs
        , %para16    # Φlabel
    ) {
    %1 = FuncGraph::fg_957(%para15, %para16)    #(Undefined, Undefined)    # fg_957=construct.957 #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(670)/        loss = self._loss_fn(outputs, label)/#loss
    %2 = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%1, %para15, %para16)    #(Undefined, Undefined, Undefined) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(671)/        return loss, outputs, label/#[CNode]917
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(671)/        return loss, outputs, label/#[CNode]944
}
# order:
#   1: ↓construct.927:loss{[0]: ValueNode<FuncGraph> construct.957, [1]: Φoutputs, [2]: Φlabel}
#   2: ↓construct.927:[CNode]917{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: loss, [2]: Φoutputs, [3]: Φlabel}
#   3: ↓construct.927:[CNode]944{[0]: ValueNode<Primitive> Return, [1]: [CNode]917}


# [No.8] construct.1174
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(265)/    def construct(self, x):/
funcgraph fg_1174[fg_911](
        %para17    # x
    ) {
    %1 = FuncGraph::fg_949(Bool(0))    #(Undefined)    # fg_949=bool_.949 #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]1173
    %2 = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_1179, FuncGraph::fg_1180)    #(Undefined, Undefined, Undefined)    # fg_1179=✓construct.1179, fg_1180=✗construct.1180 #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]1178
    %3 = %2() #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]1181
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]1188
}
# order:
#   1: construct.1174:output{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Conv2D, [1]: x, [2]: conv1.weight}
#   2: construct.1174:[CNode]1173{[0]: ValueNode<FuncGraph> bool_.949, [1]: ValueNode<BoolImm> false}
#   3: construct.1174:[CNode]1178{[0]: ValueNode<Primitive> Switch, [1]: [CNode]1173, [2]: ValueNode<FuncGraph> ✓construct.1179, [3]: ValueNode<FuncGraph> ✗construct.1180}
#   4: construct.1174:[CNode]1181{[0]: [CNode]1178}
#   5: construct.1174:[CNode]1188{[0]: ValueNode<Primitive> Return, [1]: [CNode]1181}


# [No.9] construct.1182
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(294)/    def construct(self, x):/
funcgraph fg_1182(
        %para18    # x
    ) {
    %1 = DoSignaturePrimitive::S-Prim-ReLU{prim_type=1}[output_names=["output"], input_names=["x"]](%para18)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/relu-ReLU
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(295)/        return self.relu(x)/#[CNode]1060
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/relu-ReLU
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\activation.py(295)/        return self.relu(x)/#[CNode]1189
}
# order:
#   1: construct.1182:[CNode]1060{[0]: ValueNode<DoSignaturePrimitive> S-Prim-ReLU, [1]: x}
#   2: construct.1182:[CNode]1189{[0]: ValueNode<Primitive> Return, [1]: [CNode]1060}


# [No.10] construct.1183
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\pooling.py(141)/    def construct(self, x):/
funcgraph fg_1183(
        %para19    # x
    ) {
    %1 = DoSignaturePrimitive::S-Prim-MaxPool{prim_type=1}[pad_mode=I64(2), output_names=["output"], kernel_size=(I64(1), I64(1), I64(2), I64(2)), format="NCHW", strides=(I64(1), I64(1), I64(2), I64(2)), input_names=["x"]](%para19)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/max_pool2d-MaxPool2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\pooling.py(142)/        out = self.max_pool(x)/#out
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/max_pool2d-MaxPool2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\pooling.py(143)/        return out/#[CNode]1190
}
# order:
#   1: construct.1183:out{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MaxPool, [1]: x}
#   2: construct.1183:[CNode]1190{[0]: ValueNode<Primitive> Return, [1]: out}


# [No.11] construct.1165
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(265)/    def construct(self, x):/
funcgraph fg_1165[fg_911](
        %para20    # x
    ) {
    %1 = FuncGraph::fg_949(Bool(0))    #(Undefined)    # fg_949=bool_.949 #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]1164
    %2 = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_1170, FuncGraph::fg_1171)    #(Undefined, Undefined, Undefined)    # fg_1170=✓construct.1170, fg_1171=✗construct.1171 #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]1169
    %3 = %2() #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]1172
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]1191
}
# order:
#   1: construct.1165:output{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Conv2D, [1]: x, [2]: conv2.weight}
#   2: construct.1165:[CNode]1164{[0]: ValueNode<FuncGraph> bool_.949, [1]: ValueNode<BoolImm> false}
#   3: construct.1165:[CNode]1169{[0]: ValueNode<Primitive> Switch, [1]: [CNode]1164, [2]: ValueNode<FuncGraph> ✓construct.1170, [3]: ValueNode<FuncGraph> ✗construct.1171}
#   4: construct.1165:[CNode]1172{[0]: [CNode]1169}
#   5: construct.1165:[CNode]1191{[0]: ValueNode<Primitive> Return, [1]: [CNode]1172}


# [No.12] construct.1184
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(214)/    def construct(self, x):/
funcgraph fg_1184(
        %para21    # x
    ) {
    %1 = DoSignaturePrimitive::S-Prim-Shape{prim_type=1}(%para21)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/flatten-Flatten
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(215)/        return F.reshape(x, (F.shape(x)[0], -1))/#[CNode]1159
    %2 = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%1, I64(0))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/flatten-Flatten
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(215)/        return F.reshape(x, (F.shape(x)[0], -1))/#[CNode]1160
    %3 = DoSignaturePrimitive::S-Prim-negative{prim_type=1}(I64(1))    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/flatten-Flatten
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(215)/        return F.reshape(x, (F.shape(x)[0], -1))/#[CNode]1161
    %4 = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%2, %3)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/flatten-Flatten
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(215)/        return F.reshape(x, (F.shape(x)[0], -1))/#[CNode]1162
    %5 = DoSignaturePrimitive::S-Prim-Reshape{prim_type=1}[output_names=["output"], input_names=["tensor", "shape"]](%para21, %4)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/flatten-Flatten
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(215)/        return F.reshape(x, (F.shape(x)[0], -1))/#[CNode]1163
    Primitive::Return{prim_type=1}(%5)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/flatten-Flatten
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(215)/        return F.reshape(x, (F.shape(x)[0], -1))/#[CNode]1192
}
# order:
#   1: construct.1184:[CNode]1159{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Shape, [1]: x}
#   2: construct.1184:[CNode]1160{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: [CNode]1159, [2]: ValueNode<Int64Imm> 0}
#   3: construct.1184:[CNode]1161{[0]: ValueNode<DoSignaturePrimitive> S-Prim-negative, [1]: ValueNode<Int64Imm> 1}
#   4: construct.1184:[CNode]1162{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: [CNode]1160, [2]: [CNode]1161}
#   5: construct.1184:[CNode]1163{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Reshape, [1]: x, [2]: [CNode]1162}
#   6: construct.1184:[CNode]1192{[0]: ValueNode<Primitive> Return, [1]: [CNode]1163}


# [No.13] construct.1118
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(319)/    def construct(self, x):/
funcgraph fg_1118[fg_911](
        %para22    # x
    ) {
    %1 = FuncGraph::fg_1260(%para22, %para8, %para9)    #(Undefined, Ref[Tensor(F32)][120], Ref[Tensor(F32)][120, 400])    # fg_1260=L-construct.1260 #scope: Default
#[CNode]1275
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc1-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]1193
}
# order:
#   1: construct.1118:[CNode]1275{[0]: ValueNode<FuncGraph> L-construct.1260, [1]: x, [2]: fc1.bias, [3]: fc1.weight}
#   2: construct.1118:[CNode]1193{[0]: ValueNode<Primitive> Return, [1]: [CNode]1275}


# [No.14] construct.1069
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(319)/    def construct(self, x):/
funcgraph fg_1069[fg_911](
        %para23    # x
    ) {
    %1 = FuncGraph::fg_1260(%para23, %para5, %para6)    #(Undefined, Ref[Tensor(F32)][84], Ref[Tensor(F32)][84, 120])    # fg_1260=L-construct.1260 #scope: Default
#[CNode]1274
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc2-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]1194
}
# order:
#   1: construct.1069:[CNode]1274{[0]: ValueNode<FuncGraph> L-construct.1260, [1]: x, [2]: fc2.bias, [3]: fc2.weight}
#   2: construct.1069:[CNode]1194{[0]: ValueNode<Primitive> Return, [1]: [CNode]1274}


# [No.15] construct.1019
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(319)/    def construct(self, x):/
funcgraph fg_1019[fg_911](
        %para24    # x
    ) {
    %1 = FuncGraph::fg_1260(%para24, %para3, %para4)    #(Undefined, Ref[Tensor(F32)][10], Ref[Tensor(F32)][10, 84])    # fg_1260=L-construct.1260 #scope: Default
#[CNode]1273
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]1195
}
# order:
#   1: construct.1019:[CNode]1273{[0]: ValueNode<FuncGraph> L-construct.1260, [1]: x, [2]: fc3.bias, [3]: fc3.weight}
#   2: construct.1019:[CNode]1195{[0]: ValueNode<Primitive> Return, [1]: [CNode]1273}


# [No.16] construct.957
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(622)/    def construct(self, logits, labels):/
funcgraph fg_957(
        %para25    # Φlogits
        , %para26    # labels
    ) {
    %1 = DoSignaturePrimitive::S-Prim-_check_is_tensor{prim_type=1}("logits", %para25, "SoftmaxCrossEntropyWithLogits")    #(Undefined, Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(623)/        _check_is_tensor('logits', logits, self.cls_name)/#[CNode]950
    %2 = DoSignaturePrimitive::S-Prim-_check_is_tensor{prim_type=1}("labels", %para26, "SoftmaxCrossEntropyWithLogits")    #(Undefined, Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(624)/        _check_is_tensor('labels', labels, self.cls_name)/#[CNode]951
    %3 = Primitive::MakeTuple{prim_type=1}(%1, %2)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(670)/        loss = self._loss_fn(outputs, label)/#[CNode]952
    %4 = Primitive::stop_gradient{prim_type=1}(%3)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(670)/        loss = self._loss_fn(outputs, label)/#[CNode]953
    %5 = FuncGraph::fg_949(Bool(1))    #(Undefined)    # fg_949=bool_.949 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/#[CNode]954
    %6 = Primitive::Switch{prim_type=1}(%5, FuncGraph::fg_1004, FuncGraph::fg_1005)    #(Undefined, Undefined, Undefined)    # fg_1004=✓construct.1004, fg_1005=✗construct.1005 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/#[CNode]1003
    %7 = %6() #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/#[CNode]1006
    %8 = Primitive::Depend{prim_type=1}[side_effect_propagate=I64(1)](%7, %4)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py(670)/        loss = self._loss_fn(outputs, label)/#[CNode]1007
    Primitive::Return{prim_type=1}(%8)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/#[CNode]1196
}
# order:
#   1: construct.957:[CNode]950{[0]: ValueNode<DoSignaturePrimitive> S-Prim-_check_is_tensor, [1]: ValueNode<StringImm> logits, [2]: Φlogits, [3]: ValueNode<StringImm> SoftmaxCrossEntropyWithLogits}
#   2: construct.957:[CNode]951{[0]: ValueNode<DoSignaturePrimitive> S-Prim-_check_is_tensor, [1]: ValueNode<StringImm> labels, [2]: labels, [3]: ValueNode<StringImm> SoftmaxCrossEntropyWithLogits}
#   3: construct.957:[CNode]954{[0]: ValueNode<FuncGraph> bool_.949, [1]: ValueNode<BoolImm> true}
#   4: construct.957:[CNode]1003{[0]: ValueNode<Primitive> Switch, [1]: [CNode]954, [2]: ValueNode<FuncGraph> ✓construct.1004, [3]: ValueNode<FuncGraph> ✗construct.1005}
#   5: construct.957:[CNode]1006{[0]: [CNode]1003}
#   6: construct.957:[CNode]1196{[0]: ValueNode<Primitive> Return, [1]: [CNode]1007}


# [No.17] ✓construct.1179
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
funcgraph fg_1179[fg_1174](
) {
    %1 = $(construct.1174):DoSignaturePrimitive::S-Prim-Conv2D{prim_type=1}[kernel_size=(I64(5), I64(5)), mode=I64(1), out_channel=I64(6), input_names=["x", "w"], pad=(I64(0), I64(0), I64(0), I64(0)), pad_mode=I64(2), format="NCHW", pad_list=(I64(0), I64(0), I64(0), I64(0)), groups=I64(1), stride=(I64(1), I64(1), I64(1), I64(1)), group=I64(1), dilation=(I64(1), I64(1), I64(1), I64(1)), output_names=["output"]](%para17, %para10)    #(Undefined, Ref[Tensor(F32)][6, 1, 5, 5]) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(266)/        output = self.conv2d(x, self.weight)/#output
    %2 = DoSignaturePrimitive::S-Prim-BiasAdd{prim_type=1}[output_names=["output"], format="NCHW", input_names=["x", "b"]](%1, None)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(268)/            output = self.bias_add(output, self.bias)/#output
    %3 = FuncGraph::fg_1176(%2)    #(Undefined)    # fg_1176=↓construct.1176 #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]1175
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]1197
}
# order:
#   1: ✓construct.1179:output{[0]: ValueNode<DoSignaturePrimitive> S-Prim-BiasAdd, [1]: output, [2]: ValueNode<None> None}
#   2: ✓construct.1179:[CNode]1175{[0]: ValueNode<FuncGraph> ↓construct.1176, [1]: output}
#   3: ✓construct.1179:[CNode]1197{[0]: ValueNode<Primitive> Return, [1]: [CNode]1175}


# [No.18] ✗construct.1180
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
funcgraph fg_1180[fg_1174](
) {
    %1 = $(construct.1174):DoSignaturePrimitive::S-Prim-Conv2D{prim_type=1}[kernel_size=(I64(5), I64(5)), mode=I64(1), out_channel=I64(6), input_names=["x", "w"], pad=(I64(0), I64(0), I64(0), I64(0)), pad_mode=I64(2), format="NCHW", pad_list=(I64(0), I64(0), I64(0), I64(0)), groups=I64(1), stride=(I64(1), I64(1), I64(1), I64(1)), group=I64(1), dilation=(I64(1), I64(1), I64(1), I64(1)), output_names=["output"]](%para17, %para10)    #(Undefined, Ref[Tensor(F32)][6, 1, 5, 5]) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(266)/        output = self.conv2d(x, self.weight)/#output
    %2 = FuncGraph::fg_1176(%1)    #(Undefined)    # fg_1176=↓construct.1176 #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]1177
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]1198
}
# order:
#   1: ✗construct.1180:[CNode]1177{[0]: ValueNode<FuncGraph> ↓construct.1176, [1]: output}
#   2: ✗construct.1180:[CNode]1198{[0]: ValueNode<Primitive> Return, [1]: [CNode]1177}


# [No.19] ✓construct.1170
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
funcgraph fg_1170[fg_1165](
) {
    %1 = $(construct.1165):DoSignaturePrimitive::S-Prim-Conv2D{prim_type=1}[kernel_size=(I64(5), I64(5)), mode=I64(1), out_channel=I64(16), input_names=["x", "w"], pad=(I64(0), I64(0), I64(0), I64(0)), pad_mode=I64(2), format="NCHW", pad_list=(I64(0), I64(0), I64(0), I64(0)), groups=I64(1), stride=(I64(1), I64(1), I64(1), I64(1)), group=I64(1), dilation=(I64(1), I64(1), I64(1), I64(1)), output_names=["output"]](%para20, %para7)    #(Undefined, Ref[Tensor(F32)][16, 6, 5, 5]) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(266)/        output = self.conv2d(x, self.weight)/#output
    %2 = DoSignaturePrimitive::S-Prim-BiasAdd{prim_type=1}[output_names=["output"], format="NCHW", input_names=["x", "b"]](%1, None)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(268)/            output = self.bias_add(output, self.bias)/#output
    %3 = FuncGraph::fg_1167(%2)    #(Undefined)    # fg_1167=↓construct.1167 #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]1166
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]1199
}
# order:
#   1: ✓construct.1170:output{[0]: ValueNode<DoSignaturePrimitive> S-Prim-BiasAdd, [1]: output, [2]: ValueNode<None> None}
#   2: ✓construct.1170:[CNode]1166{[0]: ValueNode<FuncGraph> ↓construct.1167, [1]: output}
#   3: ✓construct.1170:[CNode]1199{[0]: ValueNode<Primitive> Return, [1]: [CNode]1166}


# [No.20] ✗construct.1171
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
funcgraph fg_1171[fg_1165](
) {
    %1 = $(construct.1165):DoSignaturePrimitive::S-Prim-Conv2D{prim_type=1}[kernel_size=(I64(5), I64(5)), mode=I64(1), out_channel=I64(16), input_names=["x", "w"], pad=(I64(0), I64(0), I64(0), I64(0)), pad_mode=I64(2), format="NCHW", pad_list=(I64(0), I64(0), I64(0), I64(0)), groups=I64(1), stride=(I64(1), I64(1), I64(1), I64(1)), group=I64(1), dilation=(I64(1), I64(1), I64(1), I64(1)), output_names=["output"]](%para20, %para7)    #(Undefined, Ref[Tensor(F32)][16, 6, 5, 5]) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(266)/        output = self.conv2d(x, self.weight)/#output
    %2 = FuncGraph::fg_1167(%1)    #(Undefined)    # fg_1167=↓construct.1167 #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]1168
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/#[CNode]1200
}
# order:
#   1: ✗construct.1171:[CNode]1168{[0]: ValueNode<FuncGraph> ↓construct.1167, [1]: output}
#   2: ✗construct.1171:[CNode]1200{[0]: ValueNode<Primitive> Return, [1]: [CNode]1168}


# [No.21] L-construct.1260
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(319)/    def construct(self, x):/
funcgraph fg_1260(
        %para27    # x
        , %para28    # L-fc3.bias
        , %para29    # L-fc3.weight
    ) {
    %1 = DoSignaturePrimitive::S-Prim-Shape{prim_type=1}(%para27)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#Φx_shape
    %2 = DoSignaturePrimitive::S-Prim-check_dense_input_shape{prim_type=1}(%1, "Dense")    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(321)/        check_dense_input_shape(x_shape, self.cls_name)/#[CNode]1008
    %3 = Primitive::stop_gradient{prim_type=1}(%2)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\PythonCode\LeNet\lenet.py(52)/        x = self.fc3(x)/#[CNode]1009
    %4 = FuncGraph::fg_1258(%1)    #(Undefined)    # fg_1258=L-ms_len.1258 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]1012
    %5 = DoSignaturePrimitive::S-Prim-not_equal{prim_type=1}(%4, I64(2))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]1014
    %6 = FuncGraph::fg_1259(%5)    #(Undefined)    # fg_1259=L-bool_.1259 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]1015
    %7 = Primitive::Switch{prim_type=1}(%6, FuncGraph::fg_1271, FuncGraph::fg_1272)    #(Undefined, Undefined, Undefined)    # fg_1271=L-✓construct.1271, fg_1272=L-✗construct.1272 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]1055
    %8 = %7() #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]1058
    %9 = Primitive::Depend{prim_type=1}[side_effect_propagate=I64(1)](%8, %3)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\PythonCode\LeNet\lenet.py(52)/        x = self.fc3(x)/#[CNode]1059
    Primitive::Return{prim_type=1}(%9)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]1195
}
# order:
#   1: L-construct.1260:Φx_shape{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Shape, [1]: x}
#   2: L-construct.1260:[CNode]1008{[0]: ValueNode<DoSignaturePrimitive> S-Prim-check_dense_input_shape, [1]: Φx_shape, [2]: ValueNode<StringImm> Dense}
#   3: L-construct.1260:[CNode]1012{[0]: ValueNode<FuncGraph> L-ms_len.1258, [1]: Φx_shape}
#   4: L-construct.1260:[CNode]1014{[0]: ValueNode<DoSignaturePrimitive> S-Prim-not_equal, [1]: [CNode]1012, [2]: ValueNode<Int64Imm> 2}
#   5: L-construct.1260:[CNode]1015{[0]: ValueNode<FuncGraph> L-bool_.1259, [1]: [CNode]1014}
#   6: L-construct.1260:[CNode]1055{[0]: ValueNode<Primitive> Switch, [1]: [CNode]1015, [2]: ValueNode<FuncGraph> L-✓construct.1271, [3]: ValueNode<FuncGraph> L-✗construct.1272}
#   7: L-construct.1260:[CNode]1058{[0]: [CNode]1055}
#   8: L-construct.1260:[CNode]1195{[0]: ValueNode<Primitive> Return, [1]: [CNode]1059}


# [No.22] ✓construct.1004
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/
funcgraph fg_1004[fg_957](
) {
    %1 = DoSignaturePrimitive::S-Prim-equal{prim_type=1}("mean", "mean")    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/#[CNode]955
    %2 = FuncGraph::fg_949(%1)    #(Undefined)    # fg_949=bool_.949 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/#[CNode]956
    %3 = Primitive::Switch{prim_type=1}(%2, FuncGraph::fg_999, FuncGraph::fg_1000)    #(Undefined, Undefined, Undefined)    # fg_999=✓✓construct.999, fg_1000=✗✓construct.1000 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/#[CNode]998
    %4 = %3() #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/#[CNode]1001
    Primitive::Return{prim_type=1}(%4)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/#[CNode]1208
}
# order:
#   1: ✓construct.1004:[CNode]955{[0]: ValueNode<DoSignaturePrimitive> S-Prim-equal, [1]: ValueNode<StringImm> mean, [2]: ValueNode<StringImm> mean}
#   2: ✓construct.1004:[CNode]956{[0]: ValueNode<FuncGraph> bool_.949, [1]: [CNode]955}
#   3: ✓construct.1004:[CNode]998{[0]: ValueNode<Primitive> Switch, [1]: [CNode]956, [2]: ValueNode<FuncGraph> ✓✓construct.999, [3]: ValueNode<FuncGraph> ✗✓construct.1000}
#   4: ✓construct.1004:[CNode]1001{[0]: [CNode]998}
#   5: ✓construct.1004:[CNode]1208{[0]: ValueNode<Primitive> Return, [1]: [CNode]1001}


# [No.23] ✗construct.1005
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/
funcgraph fg_1005[fg_957](
) {
    %1 = FuncGraph::fg_995(%para26)    #(Undefined)    # fg_995=↓construct.995 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/#[CNode]1002
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/#[CNode]1209
}
# order:
#   1: ✗construct.1005:[CNode]1002{[0]: ValueNode<FuncGraph> ↓construct.995, [1]: labels}
#   2: ✗construct.1005:[CNode]1209{[0]: ValueNode<Primitive> Return, [1]: [CNode]1002}


# [No.24] ↓construct.1176
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
funcgraph fg_1176(
        %para30    # Φoutput
    ) {
    Primitive::Return{prim_type=1}(%para30)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv1-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(269)/        return output/#[CNode]1210
}
# order:
#   1: ↓construct.1176:[CNode]1210{[0]: ValueNode<Primitive> Return, [1]: Φoutput}


# [No.25] ↓construct.1167
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(267)/        if self.has_bias:/
funcgraph fg_1167(
        %para31    # Φoutput
    ) {
    Primitive::Return{prim_type=1}(%para31)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/conv2-Conv2d
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\conv.py(269)/        return output/#[CNode]1211
}
# order:
#   1: ↓construct.1167:[CNode]1211{[0]: ValueNode<Primitive> Return, [1]: Φoutput}


# [No.26] L-ms_len.1258
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1444)/def ms_len(data):/
funcgraph fg_1258(
        %para32    # data
    ) {
    %1 = Primitive::getattr{prim_type=1}(%para32, "__len__")    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1446)/    return data.__len__()/#[CNode]1010
    %2 = %1() #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1446)/    return data.__len__()/#[CNode]1011
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1446)/    return data.__len__()/#[CNode]1201
}
# order:
#   1: L-ms_len.1258:[CNode]1010{[0]: ValueNode<Primitive> getattr, [1]: data, [2]: ValueNode<StringImm> __len__}
#   2: L-ms_len.1258:[CNode]1011{[0]: [CNode]1010}
#   3: L-ms_len.1258:[CNode]1201{[0]: ValueNode<Primitive> Return, [1]: [CNode]1011}


# [No.27] L-bool_.1259
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1479)/def bool_(x):/
funcgraph fg_1259(
        %para33    # x
    ) {
    %1 = Primitive::getattr{prim_type=1}(%para33, "__bool__")    #(Undefined, Undefined) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1481)/    return x.__bool__()/#[CNode]947
    %2 = %1() #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1481)/    return x.__bool__()/#[CNode]948
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\_extends\parse\standard_method.py(1481)/    return x.__bool__()/#[CNode]1186
}
# order:
#   1: L-bool_.1259:[CNode]947{[0]: ValueNode<Primitive> getattr, [1]: x, [2]: ValueNode<StringImm> __bool__}
#   2: L-bool_.1259:[CNode]948{[0]: [CNode]947}
#   3: L-bool_.1259:[CNode]1186{[0]: ValueNode<Primitive> Return, [1]: [CNode]948}


# [No.28] L-✓construct.1271
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
funcgraph fg_1271[fg_1260](
) {
    %1 = DoSignaturePrimitive::S-Prim-negative{prim_type=1}(I64(1))    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(323)/            x = self.reshape(x, (-1, x_shape[-1]))/#[CNode]1049
    %2 = $(L-construct.1260):DoSignaturePrimitive::S-Prim-Shape{prim_type=1}(%para27)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#Φx_shape
    %3 = DoSignaturePrimitive::S-Prim-negative{prim_type=1}(I64(1))    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(323)/            x = self.reshape(x, (-1, x_shape[-1]))/#[CNode]1050
    %4 = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%2, %3)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(323)/            x = self.reshape(x, (-1, x_shape[-1]))/#[CNode]1051
    %5 = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%1, %4)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(323)/            x = self.reshape(x, (-1, x_shape[-1]))/#[CNode]1052
    %6 = DoSignaturePrimitive::S-Prim-Reshape{prim_type=1}[output_names=["output"], input_names=["tensor", "shape"]](%para27, %5)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(323)/            x = self.reshape(x, (-1, x_shape[-1]))/#x
    %7 = FuncGraph::fg_1268(%6)    #(Undefined)    # fg_1268=L-↓construct.1268 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]1053
    Primitive::Return{prim_type=1}(%7)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]1206
}
# order:
#   1: L-✓construct.1271:[CNode]1049{[0]: ValueNode<DoSignaturePrimitive> S-Prim-negative, [1]: ValueNode<Int64Imm> 1}
#   2: L-✓construct.1271:[CNode]1050{[0]: ValueNode<DoSignaturePrimitive> S-Prim-negative, [1]: ValueNode<Int64Imm> 1}
#   3: L-✓construct.1271:[CNode]1051{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: Φx_shape, [2]: [CNode]1050}
#   4: L-✓construct.1271:[CNode]1052{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: [CNode]1049, [2]: [CNode]1051}
#   5: L-✓construct.1271:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Reshape, [1]: x, [2]: [CNode]1052}
#   6: L-✓construct.1271:[CNode]1053{[0]: ValueNode<FuncGraph> L-↓construct.1268, [1]: x}
#   7: L-✓construct.1271:[CNode]1206{[0]: ValueNode<Primitive> Return, [1]: [CNode]1053}


# [No.29] L-✗construct.1272
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
funcgraph fg_1272[fg_1260](
) {
    %1 = FuncGraph::fg_1268(%para27)    #(Undefined)    # fg_1268=L-↓construct.1268 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]1054
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/#[CNode]1207
}
# order:
#   1: L-✗construct.1272:[CNode]1054{[0]: ValueNode<FuncGraph> L-↓construct.1268, [1]: x}
#   2: L-✗construct.1272:[CNode]1207{[0]: ValueNode<Primitive> Return, [1]: [CNode]1054}


# [No.30] ✓✓construct.999
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/
funcgraph fg_999[fg_957](
) {
    %1 = DoSignaturePrimitive::S-Prim-SparseSoftmaxCrossEntropyWithLogits{prim_type=1}[output_names=["output"], input_names=["features", "labels"], sens=F32(1), is_grad=Bool(0)](%para25, %para26)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(627)/                x = self.sparse_softmax_cross_entropy(logits, labels)/#x
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(628)/                return x/#[CNode]1215
}
# order:
#   1: ✓✓construct.999:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-SparseSoftmaxCrossEntropyWithLogits, [1]: Φlogits, [2]: labels}
#   2: ✓✓construct.999:[CNode]1215{[0]: ValueNode<Primitive> Return, [1]: x}


# [No.31] ✗✓construct.1000
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/
funcgraph fg_1000[fg_957](
) {
    %1 = FuncGraph::fg_997()    # fg_997=↓✓construct.997 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/#[CNode]996
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/#[CNode]1216
}
# order:
#   1: ✗✓construct.1000:[CNode]996{[0]: ValueNode<FuncGraph> ↓✓construct.997}
#   2: ✗✓construct.1000:[CNode]1216{[0]: ValueNode<Primitive> Return, [1]: [CNode]996}


# [No.32] ↓construct.995
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/
funcgraph fg_995[fg_957](
        %para34    # Φlabels
    ) {
    %1 = DoSignaturePrimitive::S-Prim-SoftmaxCrossEntropyWithLogits{prim_type=1}(%para25, %para34)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(630)/        x = self.softmax_cross_entropy(logits, labels)[0]/#[CNode]989
    %2 = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%1, I64(0))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(630)/        x = self.softmax_cross_entropy(logits, labels)[0]/#x
    %3 = FuncGraph::fg_971(%2)    #(Undefined)    # fg_971=get_loss.971 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(631)/        return self.get_loss(x)/#[CNode]990
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(631)/        return self.get_loss(x)/#[CNode]1217
}
# order:
#   1: ↓construct.995:[CNode]989{[0]: ValueNode<DoSignaturePrimitive> S-Prim-SoftmaxCrossEntropyWithLogits, [1]: Φlogits, [2]: Φlabels}
#   2: ↓construct.995:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: [CNode]989, [2]: ValueNode<Int64Imm> 0}
#   3: ↓construct.995:[CNode]990{[0]: ValueNode<FuncGraph> get_loss.971, [1]: x}
#   4: ↓construct.995:[CNode]1217{[0]: ValueNode<Primitive> Return, [1]: [CNode]990}


# [No.33] L-↓construct.1268
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(322)/        if len(x_shape) != 2:/
funcgraph fg_1268[fg_1260](
        %para35    # Φx
    ) {
    %1 = FuncGraph::fg_1259(Bool(1))    #(Undefined)    # fg_1259=L-bool_.1259 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]1016
    %2 = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_1269, FuncGraph::fg_1270)    #(Undefined, Undefined, Undefined)    # fg_1269=L-✓↓construct.1269, fg_1270=L-✗↓construct.1270 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]1045
    %3 = %2() #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]1048
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]1214
}
# order:
#   1: L-↓construct.1268:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MatMul, [1]: Φx, [2]: L-fc3.weight}
#   2: L-↓construct.1268:[CNode]1016{[0]: ValueNode<FuncGraph> L-bool_.1259, [1]: ValueNode<BoolImm> true}
#   3: L-↓construct.1268:[CNode]1045{[0]: ValueNode<Primitive> Switch, [1]: [CNode]1016, [2]: ValueNode<FuncGraph> L-✓↓construct.1269, [3]: ValueNode<FuncGraph> L-✗↓construct.1270}
#   4: L-↓construct.1268:[CNode]1048{[0]: [CNode]1045}
#   5: L-↓construct.1268:[CNode]1214{[0]: ValueNode<Primitive> Return, [1]: [CNode]1048}


# [No.34] ↓✓construct.997
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(626)/            if self.reduction == 'mean':/
funcgraph fg_997[fg_957](
) {
    %1 = DoSignaturePrimitive::S-Prim-Shape{prim_type=1}(%para25)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(629)/            labels = self.one_hot(labels, F.shape(logits)[-1], self.on_value, self.off_value)/#[CNode]991
    %2 = DoSignaturePrimitive::S-Prim-negative{prim_type=1}(I64(1))    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(629)/            labels = self.one_hot(labels, F.shape(logits)[-1], self.on_value, self.off_value)/#[CNode]992
    %3 = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%1, %2)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(629)/            labels = self.one_hot(labels, F.shape(logits)[-1], self.on_value, self.off_value)/#[CNode]993
    %4 = DoSignaturePrimitive::S-Prim-OneHot{prim_type=1}[output_names=["output"], input_names=["indices", "depth", "on_value", "off_value"], axis=I64(-1)](%para26, %3, Tensor(43)[], Tensor(43)[])    #(Undefined, Undefined, Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(629)/            labels = self.one_hot(labels, F.shape(logits)[-1], self.on_value, self.off_value)/#labels
    %5 = FuncGraph::fg_995(%4)    #(Undefined)    # fg_995=↓construct.995 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/#[CNode]994
    Primitive::Return{prim_type=1}(%5)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(625)/        if self.sparse:/#[CNode]1224
}
# order:
#   1: ↓✓construct.997:[CNode]991{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Shape, [1]: Φlogits}
#   2: ↓✓construct.997:[CNode]992{[0]: ValueNode<DoSignaturePrimitive> S-Prim-negative, [1]: ValueNode<Int64Imm> 1}
#   3: ↓✓construct.997:[CNode]993{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: [CNode]991, [2]: [CNode]992}
#   4: ↓✓construct.997:labels{[0]: ValueNode<DoSignaturePrimitive> S-Prim-OneHot, [1]: labels, [2]: [CNode]993, [3]: ValueNode<Tensor> Tensor(shape=[], dtype=Float32, value=1), [4]: ValueNode<Tensor> Tensor(shape=[], dtype=Float32, value=0)}
#   5: ↓✓construct.997:[CNode]994{[0]: ValueNode<FuncGraph> ↓construct.995, [1]: labels}
#   6: ↓✓construct.997:[CNode]1224{[0]: ValueNode<Primitive> Return, [1]: [CNode]994}


# [No.35] get_loss.971
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(105)/    def get_loss(self, x, weights=1.0):/
funcgraph fg_971(
        %para36    # x
        , %para37    # weights
    ) {
    %1 = FuncGraph::fg_949(Bool(1))    #(Undefined)    # fg_949=bool_.949 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]958
    %2 = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_960, FuncGraph::fg_961)    #(Undefined, Undefined, Undefined)    # fg_960=↰get_loss.960, fg_961=↱get_loss.961 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]959
    %3 = %2() #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]962
    %4 = FuncGraph::fg_949(%3)    #(Undefined)    # fg_949=bool_.949 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]963
    %5 = Primitive::Switch{prim_type=1}(%4, FuncGraph::fg_986, FuncGraph::fg_987)    #(Undefined, Undefined, Undefined)    # fg_986=✓get_loss.986, fg_987=✗get_loss.987 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]985
    %6 = %5() #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]988
    Primitive::Return{prim_type=1}(%6)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]1225
}
# order:
#   1: get_loss.971:Φinput_dtype{[0]: ValueNode<Primitive> getattr, [1]: x, [2]: ValueNode<StringImm> dtype}
#   2: get_loss.971:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Cast, [1]: x, [2]: ValueNode<Float> Float32}
#   3: get_loss.971:weights{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Cast, [1]: weights, [2]: ValueNode<Float> Float32}
#   4: get_loss.971:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Mul, [1]: weights, [2]: x}
#   5: get_loss.971:[CNode]958{[0]: ValueNode<FuncGraph> bool_.949, [1]: ValueNode<BoolImm> true}
#   6: get_loss.971:[CNode]959{[0]: ValueNode<Primitive> Switch, [1]: [CNode]958, [2]: ValueNode<FuncGraph> ↰get_loss.960, [3]: ValueNode<FuncGraph> ↱get_loss.961}
#   7: get_loss.971:[CNode]962{[0]: [CNode]959}
#   8: get_loss.971:[CNode]963{[0]: ValueNode<FuncGraph> bool_.949, [1]: [CNode]962}
#   9: get_loss.971:[CNode]985{[0]: ValueNode<Primitive> Switch, [1]: [CNode]963, [2]: ValueNode<FuncGraph> ✓get_loss.986, [3]: ValueNode<FuncGraph> ✗get_loss.987}
#  10: get_loss.971:[CNode]988{[0]: [CNode]985}
#  11: get_loss.971:[CNode]1225{[0]: ValueNode<Primitive> Return, [1]: [CNode]988}


# [No.36] L-✓↓construct.1269
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
funcgraph fg_1269[fg_1268](
) {
    %1 = $(L-↓construct.1268):DoSignaturePrimitive::S-Prim-MatMul{prim_type=1}[output_names=["output"], transpose_a=Bool(0), input_names=["x1", "x2"], transpose_x2=Bool(1), transpose_x1=Bool(0), transpose_b=Bool(1)](%para35, %para29)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(324)/        x = self.matmul(x, self.weight)/#x
    %2 = DoSignaturePrimitive::S-Prim-BiasAdd{prim_type=1}[output_names=["output"], format="NCHW", input_names=["x", "b"]](%1, %para28)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(326)/            x = self.bias_add(x, self.bias)/#x
    %3 = FuncGraph::fg_1265(%2)    #(Undefined)    # fg_1265=L-↓↓construct.1265 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]1043
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]1222
}
# order:
#   1: L-✓↓construct.1269:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-BiasAdd, [1]: x, [2]: L-fc3.bias}
#   2: L-✓↓construct.1269:[CNode]1043{[0]: ValueNode<FuncGraph> L-↓↓construct.1265, [1]: x}
#   3: L-✓↓construct.1269:[CNode]1222{[0]: ValueNode<Primitive> Return, [1]: [CNode]1043}


# [No.37] L-✗↓construct.1270
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
funcgraph fg_1270[fg_1268](
) {
    %1 = $(L-↓construct.1268):DoSignaturePrimitive::S-Prim-MatMul{prim_type=1}[output_names=["output"], transpose_a=Bool(0), input_names=["x1", "x2"], transpose_x2=Bool(1), transpose_x1=Bool(0), transpose_b=Bool(1)](%para35, %para29)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(324)/        x = self.matmul(x, self.weight)/#x
    %2 = FuncGraph::fg_1265(%1)    #(Undefined)    # fg_1265=L-↓↓construct.1265 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]1044
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/#[CNode]1223
}
# order:
#   1: L-✗↓construct.1270:[CNode]1044{[0]: ValueNode<FuncGraph> L-↓↓construct.1265, [1]: x}
#   2: L-✗↓construct.1270:[CNode]1223{[0]: ValueNode<Primitive> Return, [1]: [CNode]1044}


# [No.38] ↰get_loss.960
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/
funcgraph fg_960(
) {
    Primitive::Return{prim_type=1}(Bool(1))    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]1229
}
# order:
#   1: ↰get_loss.960:[CNode]1229{[0]: ValueNode<Primitive> Return, [1]: ValueNode<BoolImm> true}


# [No.39] ↱get_loss.961
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/
funcgraph fg_961(
) {
    Primitive::Return{prim_type=1}(Bool(1))    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]1230
}
# order:
#   1: ↱get_loss.961:[CNode]1230{[0]: ValueNode<Primitive> Return, [1]: ValueNode<BoolImm> true}


# [No.40] ✓get_loss.986
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/
funcgraph fg_986[fg_971](
) {
    %1 = $(get_loss.971):DoSignaturePrimitive::S-Prim-Cast{prim_type=1}[output_names=["output"], input_names=["x", "dst_type"]](%para37, F32)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(142)/        weights = self.cast(weights, mstype.float32)/#weights
    %2 = $(get_loss.971):DoSignaturePrimitive::S-Prim-Cast{prim_type=1}[output_names=["output"], input_names=["x", "dst_type"]](%para36, F32)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(141)/        x = self.cast(x, mstype.float32)/#x
    %3 = $(get_loss.971):DoSignaturePrimitive::S-Prim-Mul{prim_type=1}[output_names=["output"], input_names=["x", "y"]](%1, %2)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(143)/        x = self.mul(weights, x)/#x
    %4 = FuncGraph::fg_973(%3)    #(Undefined)    # fg_973=get_axis.973 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(145)/            x = self.reduce_mean(x, self.get_axis(x))/#[CNode]982
    %5 = DoSignaturePrimitive::S-Prim-ReduceMean{prim_type=1}[output_names=["y"], keep_dims=Bool(0), input_names=["input_x", "axis"]](%3, %4)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(145)/            x = self.reduce_mean(x, self.get_axis(x))/#x
    %6 = FuncGraph::fg_974(%5)    #(Undefined)    # fg_974=↓get_loss.974 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]983
    Primitive::Return{prim_type=1}(%6)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]1231
}
# order:
#   1: ✓get_loss.986:[CNode]982{[0]: ValueNode<FuncGraph> get_axis.973, [1]: x}
#   2: ✓get_loss.986:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-ReduceMean, [1]: x, [2]: [CNode]982}
#   3: ✓get_loss.986:[CNode]983{[0]: ValueNode<FuncGraph> ↓get_loss.974, [1]: x}
#   4: ✓get_loss.986:[CNode]1231{[0]: ValueNode<Primitive> Return, [1]: [CNode]983}


# [No.41] ✗get_loss.987
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/
funcgraph fg_987[fg_971](
) {
    %1 = $(get_loss.971):DoSignaturePrimitive::S-Prim-Cast{prim_type=1}[output_names=["output"], input_names=["x", "dst_type"]](%para37, F32)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(142)/        weights = self.cast(weights, mstype.float32)/#weights
    %2 = $(get_loss.971):DoSignaturePrimitive::S-Prim-Cast{prim_type=1}[output_names=["output"], input_names=["x", "dst_type"]](%para36, F32)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(141)/        x = self.cast(x, mstype.float32)/#x
    %3 = $(get_loss.971):DoSignaturePrimitive::S-Prim-Mul{prim_type=1}[output_names=["output"], input_names=["x", "y"]](%1, %2)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(143)/        x = self.mul(weights, x)/#x
    %4 = FuncGraph::fg_974(%3)    #(Undefined)    # fg_974=↓get_loss.974 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]984
    Primitive::Return{prim_type=1}(%4)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/#[CNode]1232
}
# order:
#   1: ✗get_loss.987:[CNode]984{[0]: ValueNode<FuncGraph> ↓get_loss.974, [1]: x}
#   2: ✗get_loss.987:[CNode]1232{[0]: ValueNode<Primitive> Return, [1]: [CNode]984}


# [No.42] L-↓↓construct.1265
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(325)/        if self.has_bias:/
funcgraph fg_1265[fg_1260](
        %para38    # Φx
    ) {
    %1 = FuncGraph::fg_1259(Bool(0))    #(Undefined)    # fg_1259=L-bool_.1259 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]1017
    %2 = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_1266, FuncGraph::fg_1267)    #(Undefined, Undefined, Undefined)    # fg_1266=L-✓↓↓construct.1266, fg_1267=L-✗↓↓construct.1267 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]1038
    %3 = %2() #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]1041
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]1228
}
# order:
#   1: L-↓↓construct.1265:[CNode]1017{[0]: ValueNode<FuncGraph> L-bool_.1259, [1]: ValueNode<BoolImm> false}
#   2: L-↓↓construct.1265:[CNode]1038{[0]: ValueNode<Primitive> Switch, [1]: [CNode]1017, [2]: ValueNode<FuncGraph> L-✓↓↓construct.1266, [3]: ValueNode<FuncGraph> L-✗↓↓construct.1267}
#   3: L-↓↓construct.1265:[CNode]1041{[0]: [CNode]1038}
#   4: L-↓↓construct.1265:[CNode]1228{[0]: ValueNode<Primitive> Return, [1]: [CNode]1041}


# [No.43] get_axis.973
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(69)/    def get_axis(self, x):/
funcgraph fg_973(
        %para39    # x
    ) {
    %1 = DoSignaturePrimitive::S-Prim-Shape{prim_type=1}(%para39)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(100)/        shape = F.shape(x)/#shape
    %2 = DoSignaturePrimitive::S-Prim-tuple_len{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(101)/        length = F.tuple_len(shape)/#length
    %3 = DoSignaturePrimitive::S-Prim-make_range{prim_type=1}(I64(0), %2)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(102)/        perm = F.make_range(0, length)/#perm
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(103)/        return perm/#[CNode]1239
}
# order:
#   1: get_axis.973:shape{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Shape, [1]: x}
#   2: get_axis.973:length{[0]: ValueNode<DoSignaturePrimitive> S-Prim-tuple_len, [1]: shape}
#   3: get_axis.973:perm{[0]: ValueNode<DoSignaturePrimitive> S-Prim-make_range, [1]: ValueNode<Int64Imm> 0, [2]: length}
#   4: get_axis.973:[CNode]1239{[0]: ValueNode<Primitive> Return, [1]: perm}


# [No.44] ↓get_loss.974
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(144)/        if self.reduce and self.average:/
funcgraph fg_974[fg_971](
        %para40    # Φx
    ) {
    %1 = FuncGraph::fg_949(Bool(1))    #(Undefined)    # fg_949=bool_.949 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]964
    %2 = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_967, FuncGraph::fg_968)    #(Undefined, Undefined, Undefined)    # fg_967=↰↓get_loss.967, fg_968=↱↓get_loss.968 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]966
    %3 = %2() #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]969
    %4 = FuncGraph::fg_949(%3)    #(Undefined)    # fg_949=bool_.949 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]970
    %5 = Primitive::Switch{prim_type=1}(%4, FuncGraph::fg_979, FuncGraph::fg_980)    #(Undefined, Undefined, Undefined)    # fg_979=✓↓get_loss.979, fg_980=✗↓get_loss.980 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]978
    %6 = %5() #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]981
    Primitive::Return{prim_type=1}(%6)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]1240
}
# order:
#   1: ↓get_loss.974:[CNode]964{[0]: ValueNode<FuncGraph> bool_.949, [1]: ValueNode<BoolImm> true}
#   2: ↓get_loss.974:[CNode]966{[0]: ValueNode<Primitive> Switch, [1]: [CNode]964, [2]: ValueNode<FuncGraph> ↰↓get_loss.967, [3]: ValueNode<FuncGraph> ↱↓get_loss.968}
#   3: ↓get_loss.974:[CNode]969{[0]: [CNode]966}
#   4: ↓get_loss.974:[CNode]970{[0]: ValueNode<FuncGraph> bool_.949, [1]: [CNode]969}
#   5: ↓get_loss.974:[CNode]978{[0]: ValueNode<Primitive> Switch, [1]: [CNode]970, [2]: ValueNode<FuncGraph> ✓↓get_loss.979, [3]: ValueNode<FuncGraph> ✗↓get_loss.980}
#   6: ↓get_loss.974:[CNode]981{[0]: [CNode]978}
#   7: ↓get_loss.974:[CNode]1240{[0]: ValueNode<Primitive> Return, [1]: [CNode]981}


# [No.45] L-✓↓↓construct.1266
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
funcgraph fg_1266[fg_1265](
) {
    %1 = None(%para38)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(328)/            x = self.activation(x)/#x
    %2 = FuncGraph::fg_1261(%1)    #(Undefined)    # fg_1261=L-↓↓↓construct.1261 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]1036
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]1237
}
# order:
#   1: L-✓↓↓construct.1266:x{[0]: ValueNode<None> None, [1]: Φx}
#   2: L-✓↓↓construct.1266:[CNode]1036{[0]: ValueNode<FuncGraph> L-↓↓↓construct.1261, [1]: x}
#   3: L-✓↓↓construct.1266:[CNode]1237{[0]: ValueNode<Primitive> Return, [1]: [CNode]1036}


# [No.46] L-✗↓↓construct.1267
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
funcgraph fg_1267[fg_1265](
) {
    %1 = FuncGraph::fg_1261(%para38)    #(Undefined)    # fg_1261=L-↓↓↓construct.1261 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]1037
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/#[CNode]1238
}
# order:
#   1: L-✗↓↓construct.1267:[CNode]1037{[0]: ValueNode<FuncGraph> L-↓↓↓construct.1261, [1]: Φx}
#   2: L-✗↓↓construct.1267:[CNode]1238{[0]: ValueNode<Primitive> Return, [1]: [CNode]1037}


# [No.47] ↰↓get_loss.967
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/
funcgraph fg_967(
) {
    %1 = DoSignaturePrimitive::S-Prim-logical_not{prim_type=1}(Bool(1))    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]965
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]1244
}
# order:
#   1: ↰↓get_loss.967:[CNode]965{[0]: ValueNode<DoSignaturePrimitive> S-Prim-logical_not, [1]: ValueNode<BoolImm> true}
#   2: ↰↓get_loss.967:[CNode]1244{[0]: ValueNode<Primitive> Return, [1]: [CNode]965}


# [No.48] ↱↓get_loss.968
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/
funcgraph fg_968(
) {
    Primitive::Return{prim_type=1}(Bool(1))    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]1245
}
# order:
#   1: ↱↓get_loss.968:[CNode]1245{[0]: ValueNode<Primitive> Return, [1]: ValueNode<BoolImm> true}


# [No.49] ✓↓get_loss.979
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/
funcgraph fg_979[fg_974](
) {
    %1 = FuncGraph::fg_973(%para40)    #(Undefined)    # fg_973=get_axis.973 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(147)/            x = self.reduce_sum(x, self.get_axis(x))/#[CNode]972
    %2 = DoSignaturePrimitive::S-Prim-ReduceSum{prim_type=1}[output_names=["y"], keep_dims=Bool(0), input_names=["input_x", "axis"]](%para40, %1)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(147)/            x = self.reduce_sum(x, self.get_axis(x))/#x
    %3 = FuncGraph::fg_976(%2)    #(Undefined)    # fg_976=↓↓get_loss.976 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]975
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]1246
}
# order:
#   1: ✓↓get_loss.979:[CNode]972{[0]: ValueNode<FuncGraph> get_axis.973, [1]: Φx}
#   2: ✓↓get_loss.979:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-ReduceSum, [1]: Φx, [2]: [CNode]972}
#   3: ✓↓get_loss.979:[CNode]975{[0]: ValueNode<FuncGraph> ↓↓get_loss.976, [1]: x}
#   4: ✓↓get_loss.979:[CNode]1246{[0]: ValueNode<Primitive> Return, [1]: [CNode]975}


# [No.50] ✗↓get_loss.980
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/
funcgraph fg_980[fg_974](
) {
    %1 = FuncGraph::fg_976(%para40)    #(Undefined)    # fg_976=↓↓get_loss.976 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]977
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/#[CNode]1247
}
# order:
#   1: ✗↓get_loss.980:[CNode]977{[0]: ValueNode<FuncGraph> ↓↓get_loss.976, [1]: Φx}
#   2: ✗↓get_loss.980:[CNode]1247{[0]: ValueNode<Primitive> Return, [1]: [CNode]977}


# [No.51] L-↓↓↓construct.1261
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(327)/        if self.activation_flag:/
funcgraph fg_1261[fg_1260](
        %para41    # Φx
    ) {
    %1 = $(L-construct.1260):DoSignaturePrimitive::S-Prim-Shape{prim_type=1}(%para27)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#Φx_shape
    %2 = FuncGraph::fg_1258(%1)    #(Undefined)    # fg_1258=L-ms_len.1258 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]1018
    %3 = DoSignaturePrimitive::S-Prim-not_equal{prim_type=1}(%2, I64(2))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]1020
    %4 = FuncGraph::fg_1259(%3)    #(Undefined)    # fg_1259=L-bool_.1259 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]1021
    %5 = Primitive::Switch{prim_type=1}(%4, FuncGraph::fg_1263, FuncGraph::fg_1264)    #(Undefined, Undefined, Undefined)    # fg_1263=L-✓↓↓↓construct.1263, fg_1264=L-✗↓↓↓construct.1264 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]1031
    %6 = %5() #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]1034
    Primitive::Return{prim_type=1}(%6)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]1243
}
# order:
#   1: L-↓↓↓construct.1261:[CNode]1018{[0]: ValueNode<FuncGraph> L-ms_len.1258, [1]: Φx_shape}
#   2: L-↓↓↓construct.1261:[CNode]1020{[0]: ValueNode<DoSignaturePrimitive> S-Prim-not_equal, [1]: [CNode]1018, [2]: ValueNode<Int64Imm> 2}
#   3: L-↓↓↓construct.1261:[CNode]1021{[0]: ValueNode<FuncGraph> L-bool_.1259, [1]: [CNode]1020}
#   4: L-↓↓↓construct.1261:[CNode]1031{[0]: ValueNode<Primitive> Switch, [1]: [CNode]1021, [2]: ValueNode<FuncGraph> L-✓↓↓↓construct.1263, [3]: ValueNode<FuncGraph> L-✗↓↓↓construct.1264}
#   5: L-↓↓↓construct.1261:[CNode]1034{[0]: [CNode]1031}
#   6: L-↓↓↓construct.1261:[CNode]1243{[0]: ValueNode<Primitive> Return, [1]: [CNode]1034}


# [No.52] ↓↓get_loss.976
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(146)/        if self.reduce and not self.average:/
funcgraph fg_976[fg_971](
        %para42    # Φx
    ) {
    %1 = $(get_loss.971):Primitive::getattr{prim_type=1}(%para36, "dtype")    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(148)/        x = self.cast(x, input_dtype)/#Φinput_dtype
    %2 = DoSignaturePrimitive::S-Prim-Cast{prim_type=1}[output_names=["output"], input_names=["x", "dst_type"]](%para42, %1)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(148)/        x = self.cast(x, input_dtype)/#x
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\loss\loss.py(149)/        return x/#[CNode]1254
}
# order:
#   1: ↓↓get_loss.976:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Cast, [1]: Φx, [2]: Φinput_dtype}
#   2: ↓↓get_loss.976:[CNode]1254{[0]: ValueNode<Primitive> Return, [1]: x}


# [No.53] L-✓↓↓↓construct.1263
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
funcgraph fg_1263[fg_1261](
) {
    %1 = $(L-construct.1260):DoSignaturePrimitive::S-Prim-Shape{prim_type=1}(%para27)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#Φx_shape
    %2 = DoSignaturePrimitive::S-Prim-negative{prim_type=1}(I64(1))    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(330)/            out_shape = x_shape[:-1] + (-1,)/#[CNode]1022
    %3 = DoSignaturePrimitive::S-Prim-make_slice{prim_type=1}(None, %2, None)    #(Undefined, Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(330)/            out_shape = x_shape[:-1] + (-1,)/#[CNode]1023
    %4 = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%1, %3)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(330)/            out_shape = x_shape[:-1] + (-1,)/#[CNode]1024
    %5 = DoSignaturePrimitive::S-Prim-negative{prim_type=1}(I64(1))    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(330)/            out_shape = x_shape[:-1] + (-1,)/#[CNode]1025
    %6 = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%5)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(330)/            out_shape = x_shape[:-1] + (-1,)/#[CNode]1026
    %7 = DoSignaturePrimitive::S-Prim-add{prim_type=1}(%4, %6)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(330)/            out_shape = x_shape[:-1] + (-1,)/#out_shape
    %8 = DoSignaturePrimitive::S-Prim-Reshape{prim_type=1}[output_names=["output"], input_names=["tensor", "shape"]](%para41, %7)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(331)/            x = self.reshape(x, out_shape)/#x
    %9 = FuncGraph::fg_1262(%8)    #(Undefined)    # fg_1262=L-↓↓↓↓construct.1262 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]1028
    Primitive::Return{prim_type=1}(%9)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]1252
}
# order:
#   1: L-✓↓↓↓construct.1263:[CNode]1022{[0]: ValueNode<DoSignaturePrimitive> S-Prim-negative, [1]: ValueNode<Int64Imm> 1}
#   2: L-✓↓↓↓construct.1263:[CNode]1023{[0]: ValueNode<DoSignaturePrimitive> S-Prim-make_slice, [1]: ValueNode<None> None, [2]: [CNode]1022, [3]: ValueNode<None> None}
#   3: L-✓↓↓↓construct.1263:[CNode]1024{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: Φx_shape, [2]: [CNode]1023}
#   4: L-✓↓↓↓construct.1263:[CNode]1025{[0]: ValueNode<DoSignaturePrimitive> S-Prim-negative, [1]: ValueNode<Int64Imm> 1}
#   5: L-✓↓↓↓construct.1263:[CNode]1026{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: [CNode]1025}
#   6: L-✓↓↓↓construct.1263:out_shape{[0]: ValueNode<DoSignaturePrimitive> S-Prim-add, [1]: [CNode]1024, [2]: [CNode]1026}
#   7: L-✓↓↓↓construct.1263:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Reshape, [1]: Φx, [2]: out_shape}
#   8: L-✓↓↓↓construct.1263:[CNode]1028{[0]: ValueNode<FuncGraph> L-↓↓↓↓construct.1262, [1]: x}
#   9: L-✓↓↓↓construct.1263:[CNode]1252{[0]: ValueNode<Primitive> Return, [1]: [CNode]1028}


# [No.54] L-✗↓↓↓construct.1264
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
funcgraph fg_1264[fg_1261](
) {
    %1 = FuncGraph::fg_1262(%para41)    #(Undefined)    # fg_1262=L-↓↓↓↓construct.1262 #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]1030
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/#[CNode]1253
}
# order:
#   1: L-✗↓↓↓construct.1264:[CNode]1030{[0]: ValueNode<FuncGraph> L-↓↓↓↓construct.1262, [1]: Φx}
#   2: L-✗↓↓↓construct.1264:[CNode]1253{[0]: ValueNode<Primitive> Return, [1]: [CNode]1030}


# [No.55] L-↓↓↓↓construct.1262
# In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(329)/        if len(x_shape) != 2:/
funcgraph fg_1262(
        %para43    # Φx
    ) {
    Primitive::Return{prim_type=1}(%para43)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-LeNet5/fc3-Dense
      # In file D:\Users\nol\anaconda3\envs\mindspore_py39\lib\site-packages\mindspore\nn\layer\basic.py(332)/        return x/#[CNode]1257
}
# order:
#   1: L-↓↓↓↓construct.1262:[CNode]1257{[0]: ValueNode<Primitive> Return, [1]: Φx}


# num of total function graphs: 55