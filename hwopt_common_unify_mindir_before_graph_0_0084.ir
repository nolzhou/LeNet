#IR entry      : @kernel_graph_0
#attrs         :
#Total params  : 20

%para1_fc3.bias : <Ref[Tensor(F32)], (10)>  :  <kTypeUnknownxDefaultFormat[const vector][10]>  :  IsWeight:true
%para2_fc3.weight : <Ref[Tensor(F32)], (10, 84)>  :  <kTypeUnknownxDefaultFormat[const vector][10, 84]>  :  IsWeight:true
%para3_fc2.bias : <Ref[Tensor(F32)], (84)>  :  <kTypeUnknownxDefaultFormat[const vector][84]>  :  IsWeight:true
%para4_fc2.weight : <Ref[Tensor(F32)], (84, 120)>  :  <kTypeUnknownxDefaultFormat[const vector][84, 120]>  :  IsWeight:true
%para5_fc1.bias : <Ref[Tensor(F32)], (120)>  :  <kTypeUnknownxDefaultFormat[const vector][120]>  :  IsWeight:true
%para6_fc1.weight : <Ref[Tensor(F32)], (120, 400)>  :  <kTypeUnknownxDefaultFormat[const vector][120, 400]>  :  IsWeight:true
%para7_conv2.weight : <Ref[Tensor(F32)], (16, 6, 5, 5)>  :  <kTypeUnknownxDefaultFormat[const vector][16, 6, 5, 5]>  :  IsWeight:true
%para8_conv1.weight : <Ref[Tensor(F32)], (6, 1, 5, 5)>  :  <kTypeUnknownxDefaultFormat[const vector][6, 1, 5, 5]>  :  IsWeight:true
%para9_inputs0 : <Tensor[Float32], (32, 1, 32, 32)>  :  <Float32xDefaultFormat[const vector][32, 1, 32, 32]>  :  IsWeight:false
%para10_inputs1 : <Tensor[Int32], (32)>  :  <Int32xDefaultFormat[const vector][32]>  :  IsWeight:false
%para11_moments.fc3.bias : <Ref[Tensor(F32)], (10)>  :  <kTypeUnknownxDefaultFormat[const vector][10]>  :  IsWeight:true
%para12_learning_rate : <Ref[Tensor(F32)], ()>  :  <kTypeUnknownxDefaultFormat[const vector][]>  :  IsWeight:true
%para13_momentum : <Ref[Tensor(F32)], ()>  :  <kTypeUnknownxDefaultFormat[const vector][]>  :  IsWeight:true
%para14_moments.fc3.weight : <Ref[Tensor(F32)], (10, 84)>  :  <kTypeUnknownxDefaultFormat[const vector][10, 84]>  :  IsWeight:true
%para15_moments.fc2.bias : <Ref[Tensor(F32)], (84)>  :  <kTypeUnknownxDefaultFormat[const vector][84]>  :  IsWeight:true
%para16_moments.fc2.weight : <Ref[Tensor(F32)], (84, 120)>  :  <kTypeUnknownxDefaultFormat[const vector][84, 120]>  :  IsWeight:true
%para17_moments.fc1.bias : <Ref[Tensor(F32)], (120)>  :  <kTypeUnknownxDefaultFormat[const vector][120]>  :  IsWeight:true
%para18_moments.fc1.weight : <Ref[Tensor(F32)], (120, 400)>  :  <kTypeUnknownxDefaultFormat[const vector][120, 400]>  :  IsWeight:true
%para19_moments.conv2.weight : <Ref[Tensor(F32)], (16, 6, 5, 5)>  :  <kTypeUnknownxDefaultFormat[const vector][16, 6, 5, 5]>  :  IsWeight:true
%para20_moments.conv1.weight : <Ref[Tensor(F32)], (6, 1, 5, 5)>  :  <kTypeUnknownxDefaultFormat[const vector][6, 1, 5, 5]>  :  IsWeight:true

#Total subgraph : 1

subgraph attr:
subgraph @kernel_graph_0() {
  %0(equiv[CNode]843) = Load(%para8_conv1.weight, U)
      : (<Ref[Tensor(F32)], (6, 1, 5, 5)>, <UMonad>) -> (<Tensor[Float32], (6, 1, 5, 5)>)
  %1(equivoutput) = Conv2D(%para9_inputs0, %0) {instance name: conv2d} primitive_attrs: {IsFeatureMapInputList: (0), kernel_size: (5, 5), mode: 1, out_channel: 6, input_names: [x, w], pad: (0, 0, 0, 0), pad_mode: 2, format: NCHW, pad_list: (0, 0, 0, 0), groups: 1, stride: (1, 1, 1, 1), group: 1, dilation: (1, 1, 1, 1), output_names: [output], IsFeatureMapOutput: true}
      : (<Tensor[Float32], (32, 1, 32, 32)>, <Tensor[Float32], (6, 1, 5, 5)>) -> (<Tensor[Float32], (32, 6, 28, 28)>)
  %2(equiv[CNode]148) = ReLU(%1) {instance name: relu} primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0), input_names: [x]}
      : (<Tensor[Float32], (32, 6, 28, 28)>) -> (<Tensor[Float32], (32, 6, 28, 28)>)
  %3(equivout) = MaxPool(%2) {instance name: max_pool} primitive_attrs: {IsFeatureMapInputList: (0), kernel_size: (1, 1, 2, 2), strides: (1, 1, 2, 2), input_names: [x], pad_mode: 2, output_names: [output], IsFeatureMapOutput: true, format: NCHW}
      : (<Tensor[Float32], (32, 6, 28, 28)>) -> (<Tensor[Float32], (32, 6, 14, 14)>)
  %4(equiv[CNode]840) = Load(%para7_conv2.weight, U)
      : (<Ref[Tensor(F32)], (16, 6, 5, 5)>, <UMonad>) -> (<Tensor[Float32], (16, 6, 5, 5)>)
  %5(equivoutput) = Conv2D(%3, %4) {instance name: conv2d} primitive_attrs: {IsFeatureMapInputList: (0), kernel_size: (5, 5), mode: 1, out_channel: 16, input_names: [x, w], pad: (0, 0, 0, 0), pad_mode: 2, format: NCHW, pad_list: (0, 0, 0, 0), groups: 1, stride: (1, 1, 1, 1), group: 1, dilation: (1, 1, 1, 1), output_names: [output], IsFeatureMapOutput: true}
      : (<Tensor[Float32], (32, 6, 14, 14)>, <Tensor[Float32], (16, 6, 5, 5)>) -> (<Tensor[Float32], (32, 16, 10, 10)>)
  %6(equiv[CNode]148) = ReLU(%5) {instance name: relu} primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0), input_names: [x]}
      : (<Tensor[Float32], (32, 16, 10, 10)>) -> (<Tensor[Float32], (32, 16, 10, 10)>)
  %7(equivout) = MaxPool(%6) {instance name: max_pool} primitive_attrs: {IsFeatureMapInputList: (0), kernel_size: (1, 1, 2, 2), strides: (1, 1, 2, 2), input_names: [x], pad_mode: 2, output_names: [output], IsFeatureMapOutput: true, format: NCHW}
      : (<Tensor[Float32], (32, 16, 10, 10)>) -> (<Tensor[Float32], (32, 16, 5, 5)>)
  %8(equiv[CNode]251) = Reshape(%7, (32, -1)) primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0), input_names: [tensor, shape]}
      : (<Tensor[Float32], (32, 16, 5, 5)>, <Tuple[Int64*2], sequence_nodes={node={<freed node>}, node={ValueNode<ValueTuple> (32, -1), elements_use_flags: {ptr: 0x159961d2220, value: [const vector][1, 1]}}, node={<freed node>}, node={ValueNode<ValueTuple> (32, -1), elements_use_flags: {ptr: 0x159961d2220, value: [const vector][1, 1]}}, node={ValueNode<ValueTuple> (32, -1), elements_use_flags: {ptr: 0x159961d2220, value: [const vector][1, 1]}}}>) -> (<Tensor[Float32], (32, 400)>)
  %9(equiv[CNode]834) = Load(%para6_fc1.weight, U)
      : (<Ref[Tensor(F32)], (120, 400)>, <UMonad>) -> (<Tensor[Float32], (120, 400)>)
  %10(equivx) = MatMul(%8, %9) {instance name: matmul} primitive_attrs: {IsFeatureMapInputList: (0), input_names: [x1, x2], transpose_x2: true, transpose_b: true, output_names: [output], transpose_a: false, IsFeatureMapOutput: true, transpose_x1: false}
      : (<Tensor[Float32], (32, 400)>, <Tensor[Float32], (120, 400)>) -> (<Tensor[Float32], (32, 120)>)
  %11(equiv[CNode]835) = Load(%para5_fc1.bias, U)
      : (<Ref[Tensor(F32)], (120)>, <UMonad>) -> (<Tensor[Float32], (120)>)
  %12(equivx) = BiasAdd(%10, %11) {instance name: bias_add} primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0), format: NCHW, input_names: [x, b]}
      : (<Tensor[Float32], (32, 120)>, <Tensor[Float32], (120)>) -> (<Tensor[Float32], (32, 120)>)
  %13(equiv[CNode]148) = ReLU(%12) {instance name: relu} primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0), input_names: [x]}
      : (<Tensor[Float32], (32, 120)>) -> (<Tensor[Float32], (32, 120)>)
  %14(equiv[CNode]828) = Load(%para4_fc2.weight, U)
      : (<Ref[Tensor(F32)], (84, 120)>, <UMonad>) -> (<Tensor[Float32], (84, 120)>)
  %15(equivx) = MatMul(%13, %14) {instance name: matmul} primitive_attrs: {IsFeatureMapInputList: (0), input_names: [x1, x2], transpose_x2: true, transpose_b: true, output_names: [output], transpose_a: false, IsFeatureMapOutput: true, transpose_x1: false}
      : (<Tensor[Float32], (32, 120)>, <Tensor[Float32], (84, 120)>) -> (<Tensor[Float32], (32, 84)>)
  %16(equiv[CNode]829) = Load(%para3_fc2.bias, U)
      : (<Ref[Tensor(F32)], (84)>, <UMonad>) -> (<Tensor[Float32], (84)>)
  %17(equivx) = BiasAdd(%15, %16) {instance name: bias_add} primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0), format: NCHW, input_names: [x, b]}
      : (<Tensor[Float32], (32, 84)>, <Tensor[Float32], (84)>) -> (<Tensor[Float32], (32, 84)>)
  %18(equiv[CNode]148) = ReLU(%17) {instance name: relu} primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0), input_names: [x]}
      : (<Tensor[Float32], (32, 84)>) -> (<Tensor[Float32], (32, 84)>)
  %19(equiv[CNode]822) = Load(%para2_fc3.weight, U)
      : (<Ref[Tensor(F32)], (10, 84)>, <UMonad>) -> (<Tensor[Float32], (10, 84)>)
  %20(equivx) = MatMul(%18, %19) {instance name: matmul} primitive_attrs: {IsFeatureMapInputList: (0), input_names: [x1, x2], transpose_x2: true, transpose_b: true, output_names: [output], transpose_a: false, IsFeatureMapOutput: true, transpose_x1: false}
      : (<Tensor[Float32], (32, 84)>, <Tensor[Float32], (10, 84)>) -> (<Tensor[Float32], (32, 10)>)
  %21(equiv[CNode]823) = Load(%para1_fc3.bias, U)
      : (<Ref[Tensor(F32)], (10)>, <UMonad>) -> (<Tensor[Float32], (10)>)
  %22(equivx) = BiasAdd(%20, %21) {instance name: bias_add} primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0), format: NCHW, input_names: [x, b]}
      : (<Tensor[Float32], (32, 10)>, <Tensor[Float32], (10)>) -> (<Tensor[Float32], (32, 10)>)
  %23(equivx) = SparseSoftmaxCrossEntropyWithLogits(%22, %para10_inputs1) {instance name: sparse_softmax_cross_entropy} primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0, 1), input_names: [features, labels], sens: 1.000000, is_grad: false}
      : (<Tensor[Float32], (32, 10)>, <Tensor[Int32], (32)>) -> (<Tensor[Float32], ()>)
  %24(grad) = SparseSoftmaxCrossEntropyWithLogits(%22, %para10_inputs1) primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0, 1), input_names: [features, labels], sens: 1.000000, is_grad: true} cnode_primal_attrs: {forward_node_name: SparseSoftmaxCrossEntropyWithLogits_7690}
      : (<Tensor[Float32], (32, 10)>, <Tensor[Int32], (32)>) -> (<Tensor[Float32], (32, 10)>)
  %25(grad) = Depend(%24, %23) primitive_attrs: {side_effect_propagate: 1} cnode_primal_attrs: {forward_node_name: SparseSoftmaxCrossEntropyWithLogits_7690}
      : (<Tensor[Float32], (32, 10)>, <Tensor[Float32], ()>) -> (<Tensor[Float32], (32, 10)>)
  %26(dx) = MatMul(%25, %19) primitive_attrs: {IsFeatureMapInputList: (0), input_names: [x1, x2], transpose_x2: false, transpose_b: false, output_names: [output], transpose_a: false, IsFeatureMapOutput: true, transpose_x1: false} cnode_primal_attrs: {forward_node_name: MatMul_7787}
      : (<Tensor[Float32], (32, 10)>, <Tensor[Float32], (10, 84)>) -> (<Tensor[Float32], (32, 84)>)
  %27(dx) = ReluGrad(%26, %18) primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0, 1), input_names: [y_backprop, x]} cnode_primal_attrs: {forward_node_name: ReLU_7857}
      : (<Tensor[Float32], (32, 84)>, <Tensor[Float32], (32, 84)>) -> (<Tensor[Float32], (32, 84)>)
  %28(dx) = MatMul(%27, %14) primitive_attrs: {IsFeatureMapInputList: (0), input_names: [x1, x2], transpose_x2: false, transpose_b: false, output_names: [output], transpose_a: false, IsFeatureMapOutput: true, transpose_x1: false} cnode_primal_attrs: {forward_node_name: MatMul_7921}
      : (<Tensor[Float32], (32, 84)>, <Tensor[Float32], (84, 120)>) -> (<Tensor[Float32], (32, 120)>)
  %29(dx) = ReluGrad(%28, %13) primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0, 1), input_names: [y_backprop, x]} cnode_primal_attrs: {forward_node_name: ReLU_7991}
      : (<Tensor[Float32], (32, 120)>, <Tensor[Float32], (32, 120)>) -> (<Tensor[Float32], (32, 120)>)
  %30(dx) = MatMul(%29, %9) primitive_attrs: {IsFeatureMapInputList: (0), input_names: [x1, x2], transpose_x2: false, transpose_b: false, output_names: [output], transpose_a: false, IsFeatureMapOutput: true, transpose_x1: false} cnode_primal_attrs: {forward_node_name: MatMul_8055}
      : (<Tensor[Float32], (32, 120)>, <Tensor[Float32], (120, 400)>) -> (<Tensor[Float32], (32, 400)>)
  %31([CNode]906) = Reshape(%30, (32, 16, 5, 5)) primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0), input_names: [tensor, shape]} cnode_primal_attrs: {forward_node_name: Reshape_8126}
      : (<Tensor[Float32], (32, 400)>, <Tuple[Int64*4]>) -> (<Tensor[Float32], (32, 16, 5, 5)>)
  %32(dx) = MaxPoolGrad(%6, %7, %31) primitive_attrs: {IsFeatureMapInputList: (0, 1, 2), kernel_size: (1, 1, 2, 2), strides: (1, 1, 2, 2), input_names: [x_origin, out_origin, grad], pad_mode: 2, output_names: [output], IsFeatureMapOutput: true, format: NCHW} cnode_primal_attrs: {forward_node_name: MaxPool_8137}
      : (<Tensor[Float32], (32, 16, 10, 10)>, <Tensor[Float32], (32, 16, 5, 5)>, <Tensor[Float32], (32, 16, 5, 5)>) -> (<Tensor[Float32], (32, 16, 10, 10)>)
  %33(dx) = ReluGrad(%32, %6) primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0, 1), input_names: [y_backprop, x]} cnode_primal_attrs: {forward_node_name: ReLU_8149}
      : (<Tensor[Float32], (32, 16, 10, 10)>, <Tensor[Float32], (32, 16, 10, 10)>) -> (<Tensor[Float32], (32, 16, 10, 10)>)
  %34(dx) = Conv2DBackpropInput(%33, %4, (32, 6, 14, 14)) primitive_attrs: {IsFeatureMapInputList: (0), kernel_size: (5, 5), mode: 1, out_channel: 16, input_names: [out_backprop, filter, input_sizes], pad: (0, 0, 0, 0), pad_mode: 2, format: NCHW, pad_list: (0, 0, 0, 0), groups: 1, stride: (1, 1, 1, 1), group: 1, dilation: (1, 1, 1, 1), output_names: [output], IsFeatureMapOutput: true} cnode_primal_attrs: {forward_node_name: Conv2D_8172}
      : (<Tensor[Float32], (32, 16, 10, 10)>, <Tensor[Float32], (16, 6, 5, 5)>, <Tuple[Int64*4]>) -> (<Tensor[Float32], (32, 6, 14, 14)>)
  %35(dx) = MaxPoolGrad(%2, %3, %34) primitive_attrs: {IsFeatureMapInputList: (0, 1, 2), kernel_size: (1, 1, 2, 2), strides: (1, 1, 2, 2), input_names: [x_origin, out_origin, grad], pad_mode: 2, output_names: [output], IsFeatureMapOutput: true, format: NCHW} cnode_primal_attrs: {forward_node_name: MaxPool_8190}
      : (<Tensor[Float32], (32, 6, 28, 28)>, <Tensor[Float32], (32, 6, 14, 14)>, <Tensor[Float32], (32, 6, 14, 14)>) -> (<Tensor[Float32], (32, 6, 28, 28)>)
  %36(dx) = ReluGrad(%35, %2) primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0, 1), input_names: [y_backprop, x]} cnode_primal_attrs: {forward_node_name: ReLU_8202}
      : (<Tensor[Float32], (32, 6, 28, 28)>, <Tensor[Float32], (32, 6, 28, 28)>) -> (<Tensor[Float32], (32, 6, 28, 28)>)
  %37(dw) = Conv2DBackpropFilter(%36, %para9_inputs0, (6, 1, 5, 5)) primitive_attrs: {IsFeatureMapInputList: (0, 1), kernel_size: (5, 5), mode: 1, out_channel: 6, input_names: [out_backprop, input, filter_sizes], pad: (0, 0, 0, 0), pad_mode: 2, format: NCHW, pad_list: (0, 0, 0, 0), groups: 1, stride: (1, 1), group: 1, dilation: (1, 1, 1, 1), output_names: [output], IsFeatureMapOutput: true} cnode_primal_attrs: {forward_node_name: Conv2D_8225}
      : (<Tensor[Float32], (32, 6, 28, 28)>, <Tensor[Float32], (32, 1, 32, 32)>, <Tuple[Int64*4]>) -> (<Tensor[Float32], (6, 1, 5, 5)>)
  %38([CNode]907) = MakeTuple(%21, %16, %11, %4, %0, %9, %14, %19)
      : (<Tensor[Float32], (10)>, <Tensor[Float32], (84)>, <Tensor[Float32], (120)>, <Tensor[Float32], (16, 6, 5, 5)>, <Tensor[Float32], (6, 1, 5, 5)>, <Tensor[Float32], (120, 400)>, <Tensor[Float32], (84, 120)>, <Tensor[Float32], (10, 84)>) -> (<Tuple[Tensor[Float32]*8], sequence_nodes={node={254_129_1_construct_wrapper.905:[CNode]907{[0]: ValueNode<Primitive> MakeTuple, [1]: equiv[CNode]823, [2]: equiv[CNode]829, [3]: equiv[CNode]835, [4]: equiv[CNode]840, [5]: equiv[CNode]843, [6]: equiv[CNode]834, [7]: equiv[CNode]828, [8]: equiv[CNode]822}, elements_use_flags: {ptr: 0x1599709d4c0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
  %39([CNode]908) = UpdateState(U, %38, %22)
      : (<UMonad>, <Tuple[Tensor[Float32]*8], sequence_nodes={node={254_129_1_construct_wrapper.905:[CNode]907{[0]: ValueNode<Primitive> MakeTuple, [1]: equiv[CNode]823, [2]: equiv[CNode]829, [3]: equiv[CNode]835, [4]: equiv[CNode]840, [5]: equiv[CNode]843, [6]: equiv[CNode]834, [7]: equiv[CNode]828, [8]: equiv[CNode]822}, elements_use_flags: {ptr: 0x1599709d4c0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>, <Tensor[Float32], (32, 10)>) -> (<UMonad>)
  %40([CNode]909) = BiasAddGrad(%25) primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0), format: NCHW, input_names: [dout]} cnode_primal_attrs: {forward_node_name: BiasAdd_7785}
      : (<Tensor[Float32], (32, 10)>) -> (<Tensor[Float32], (10)>)
  %41([CNode]602) = ApplyMomentum(%para1_fc3.bias, %para11_moments.fc3.bias, %para12_learning_rate, %40, %para13_momentum, %39) {instance name: opt} primitive_attrs: {IsFeatureMapInputList: (3), side_effect_mem: true, input_names: [variable, accumulation, learning_rate, gradient, momentum], output_names: [output], IsFeatureMapOutput: true, use_nesterov: false, use_locking: false, gradient_scale: 1.000000}
      : (<Ref[Tensor(F32)], (10)>, <Ref[Tensor(F32)], (10)>, <Ref[Tensor(F32)], ()>, <Tensor[Float32], (10)>, <Ref[Tensor(F32)], ()>, <UMonad>) -> (<Tensor[Float32], (10)>)
  %42([CNode]853) = UpdateState(%39, %41, %20, %26)
      : (<UMonad>, <Tensor[Float32], (10)>, <Tensor[Float32], (32, 10)>, <Tensor[Float32], (32, 84)>) -> (<UMonad>)
  %43(dw) = MatMul(%25, %18) primitive_attrs: {IsFeatureMapInputList: (0, 1), input_names: [x1, x2], transpose_x2: false, transpose_b: false, output_names: [output], transpose_a: true, IsFeatureMapOutput: true, transpose_x1: true} cnode_primal_attrs: {forward_node_name: MatMul_7787}
      : (<Tensor[Float32], (32, 10)>, <Tensor[Float32], (32, 84)>) -> (<Tensor[Float32], (10, 84)>)
  %44([CNode]602) = ApplyMomentum(%para2_fc3.weight, %para14_moments.fc3.weight, %para12_learning_rate, %43, %para13_momentum, %42) {instance name: opt} primitive_attrs: {IsFeatureMapInputList: (3), side_effect_mem: true, input_names: [variable, accumulation, learning_rate, gradient, momentum], output_names: [output], IsFeatureMapOutput: true, use_nesterov: false, use_locking: false, gradient_scale: 1.000000}
      : (<Ref[Tensor(F32)], (10, 84)>, <Ref[Tensor(F32)], (10, 84)>, <Ref[Tensor(F32)], ()>, <Tensor[Float32], (10, 84)>, <Ref[Tensor(F32)], ()>, <UMonad>) -> (<Tensor[Float32], (10, 84)>)
  %45([CNode]855) = UpdateState(%42, %44, %17)
      : (<UMonad>, <Tensor[Float32], (10, 84)>, <Tensor[Float32], (32, 84)>) -> (<UMonad>)
  %46([CNode]909) = BiasAddGrad(%27) primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0), format: NCHW, input_names: [dout]} cnode_primal_attrs: {forward_node_name: BiasAdd_7919}
      : (<Tensor[Float32], (32, 84)>) -> (<Tensor[Float32], (84)>)
  %47([CNode]602) = ApplyMomentum(%para3_fc2.bias, %para15_moments.fc2.bias, %para12_learning_rate, %46, %para13_momentum, %45) {instance name: opt} primitive_attrs: {IsFeatureMapInputList: (3), side_effect_mem: true, input_names: [variable, accumulation, learning_rate, gradient, momentum], output_names: [output], IsFeatureMapOutput: true, use_nesterov: false, use_locking: false, gradient_scale: 1.000000}
      : (<Ref[Tensor(F32)], (84)>, <Ref[Tensor(F32)], (84)>, <Ref[Tensor(F32)], ()>, <Tensor[Float32], (84)>, <Ref[Tensor(F32)], ()>, <UMonad>) -> (<Tensor[Float32], (84)>)
  %48([CNode]857) = UpdateState(%45, %47, %15, %28)
      : (<UMonad>, <Tensor[Float32], (84)>, <Tensor[Float32], (32, 84)>, <Tensor[Float32], (32, 120)>) -> (<UMonad>)
  %49(dw) = MatMul(%27, %13) primitive_attrs: {IsFeatureMapInputList: (0, 1), input_names: [x1, x2], transpose_x2: false, transpose_b: false, output_names: [output], transpose_a: true, IsFeatureMapOutput: true, transpose_x1: true} cnode_primal_attrs: {forward_node_name: MatMul_7921}
      : (<Tensor[Float32], (32, 84)>, <Tensor[Float32], (32, 120)>) -> (<Tensor[Float32], (84, 120)>)
  %50([CNode]602) = ApplyMomentum(%para4_fc2.weight, %para16_moments.fc2.weight, %para12_learning_rate, %49, %para13_momentum, %48) {instance name: opt} primitive_attrs: {IsFeatureMapInputList: (3), side_effect_mem: true, input_names: [variable, accumulation, learning_rate, gradient, momentum], output_names: [output], IsFeatureMapOutput: true, use_nesterov: false, use_locking: false, gradient_scale: 1.000000}
      : (<Ref[Tensor(F32)], (84, 120)>, <Ref[Tensor(F32)], (84, 120)>, <Ref[Tensor(F32)], ()>, <Tensor[Float32], (84, 120)>, <Ref[Tensor(F32)], ()>, <UMonad>) -> (<Tensor[Float32], (84, 120)>)
  %51([CNode]859) = UpdateState(%48, %50, %12)
      : (<UMonad>, <Tensor[Float32], (84, 120)>, <Tensor[Float32], (32, 120)>) -> (<UMonad>)
  %52([CNode]909) = BiasAddGrad(%29) primitive_attrs: {output_names: [output], IsFeatureMapOutput: true, IsFeatureMapInputList: (0), format: NCHW, input_names: [dout]} cnode_primal_attrs: {forward_node_name: BiasAdd_8053}
      : (<Tensor[Float32], (32, 120)>) -> (<Tensor[Float32], (120)>)
  %53([CNode]602) = ApplyMomentum(%para5_fc1.bias, %para17_moments.fc1.bias, %para12_learning_rate, %52, %para13_momentum, %51) {instance name: opt} primitive_attrs: {IsFeatureMapInputList: (3), side_effect_mem: true, input_names: [variable, accumulation, learning_rate, gradient, momentum], output_names: [output], IsFeatureMapOutput: true, use_nesterov: false, use_locking: false, gradient_scale: 1.000000}
      : (<Ref[Tensor(F32)], (120)>, <Ref[Tensor(F32)], (120)>, <Ref[Tensor(F32)], ()>, <Tensor[Float32], (120)>, <Ref[Tensor(F32)], ()>, <UMonad>) -> (<Tensor[Float32], (120)>)
  %54([CNode]861) = UpdateState(%51, %53, %10, %30)
      : (<UMonad>, <Tensor[Float32], (120)>, <Tensor[Float32], (32, 120)>, <Tensor[Float32], (32, 400)>) -> (<UMonad>)
  %55(dw) = MatMul(%29, %8) primitive_attrs: {IsFeatureMapInputList: (0, 1), input_names: [x1, x2], transpose_x2: false, transpose_b: false, output_names: [output], transpose_a: true, IsFeatureMapOutput: true, transpose_x1: true} cnode_primal_attrs: {forward_node_name: MatMul_8055}
      : (<Tensor[Float32], (32, 120)>, <Tensor[Float32], (32, 400)>) -> (<Tensor[Float32], (120, 400)>)
  %56([CNode]602) = ApplyMomentum(%para6_fc1.weight, %para18_moments.fc1.weight, %para12_learning_rate, %55, %para13_momentum, %54) {instance name: opt} primitive_attrs: {IsFeatureMapInputList: (3), side_effect_mem: true, input_names: [variable, accumulation, learning_rate, gradient, momentum], output_names: [output], IsFeatureMapOutput: true, use_nesterov: false, use_locking: false, gradient_scale: 1.000000}
      : (<Ref[Tensor(F32)], (120, 400)>, <Ref[Tensor(F32)], (120, 400)>, <Ref[Tensor(F32)], ()>, <Tensor[Float32], (120, 400)>, <Ref[Tensor(F32)], ()>, <UMonad>) -> (<Tensor[Float32], (120, 400)>)
  %57([CNode]863) = UpdateState(%54, %56, %5, %34)
      : (<UMonad>, <Tensor[Float32], (120, 400)>, <Tensor[Float32], (32, 16, 10, 10)>, <Tensor[Float32], (32, 6, 14, 14)>) -> (<UMonad>)
  %58(dw) = Conv2DBackpropFilter(%33, %3, (16, 6, 5, 5)) primitive_attrs: {IsFeatureMapInputList: (0, 1), kernel_size: (5, 5), mode: 1, out_channel: 16, input_names: [out_backprop, input, filter_sizes], pad: (0, 0, 0, 0), pad_mode: 2, format: NCHW, pad_list: (0, 0, 0, 0), groups: 1, stride: (1, 1), group: 1, dilation: (1, 1, 1, 1), output_names: [output], IsFeatureMapOutput: true} cnode_primal_attrs: {forward_node_name: Conv2D_8172}
      : (<Tensor[Float32], (32, 16, 10, 10)>, <Tensor[Float32], (32, 6, 14, 14)>, <Tuple[Int64*4]>) -> (<Tensor[Float32], (16, 6, 5, 5)>)
  %59([CNode]602) = ApplyMomentum(%para7_conv2.weight, %para19_moments.conv2.weight, %para12_learning_rate, %58, %para13_momentum, %57) {instance name: opt} primitive_attrs: {IsFeatureMapInputList: (3), side_effect_mem: true, input_names: [variable, accumulation, learning_rate, gradient, momentum], output_names: [output], IsFeatureMapOutput: true, use_nesterov: false, use_locking: false, gradient_scale: 1.000000}
      : (<Ref[Tensor(F32)], (16, 6, 5, 5)>, <Ref[Tensor(F32)], (16, 6, 5, 5)>, <Ref[Tensor(F32)], ()>, <Tensor[Float32], (16, 6, 5, 5)>, <Ref[Tensor(F32)], ()>, <UMonad>) -> (<Tensor[Float32], (16, 6, 5, 5)>)
  %60([CNode]865) = UpdateState(%57, %59, %1)
      : (<UMonad>, <Tensor[Float32], (16, 6, 5, 5)>, <Tensor[Float32], (32, 6, 28, 28)>) -> (<UMonad>)
  %61([CNode]602) = ApplyMomentum(%para8_conv1.weight, %para20_moments.conv1.weight, %para12_learning_rate, %37, %para13_momentum, %60) {instance name: opt} primitive_attrs: {IsFeatureMapInputList: (3), side_effect_mem: true, input_names: [variable, accumulation, learning_rate, gradient, momentum], output_names: [output], IsFeatureMapOutput: true, use_nesterov: false, use_locking: false, gradient_scale: 1.000000}
      : (<Ref[Tensor(F32)], (6, 1, 5, 5)>, <Ref[Tensor(F32)], (6, 1, 5, 5)>, <Ref[Tensor(F32)], ()>, <Tensor[Float32], (6, 1, 5, 5)>, <Ref[Tensor(F32)], ()>, <UMonad>) -> (<Tensor[Float32], (6, 1, 5, 5)>)
  %62(success) = Depend(true, %61) primitive_attrs: {side_effect_propagate: 1}
      : (<Bool>, <Tensor[Float32], (6, 1, 5, 5)>) -> (<Bool>)
  %63(success) = Depend(true, %59) primitive_attrs: {side_effect_propagate: 1}
      : (<Bool>, <Tensor[Float32], (16, 6, 5, 5)>) -> (<Bool>)
  %64(success) = Depend(true, %56) primitive_attrs: {side_effect_propagate: 1}
      : (<Bool>, <Tensor[Float32], (120, 400)>) -> (<Bool>)
  %65(success) = Depend(true, %53) primitive_attrs: {side_effect_propagate: 1}
      : (<Bool>, <Tensor[Float32], (120)>) -> (<Bool>)
  %66(success) = Depend(true, %50) primitive_attrs: {side_effect_propagate: 1}
      : (<Bool>, <Tensor[Float32], (84, 120)>) -> (<Bool>)
  %67(success) = Depend(true, %47) primitive_attrs: {side_effect_propagate: 1}
      : (<Bool>, <Tensor[Float32], (84)>) -> (<Bool>)
  %68(success) = Depend(true, %44) primitive_attrs: {side_effect_propagate: 1}
      : (<Bool>, <Tensor[Float32], (10, 84)>) -> (<Bool>)
  %69(success) = Depend(true, %41) primitive_attrs: {side_effect_propagate: 1}
      : (<Bool>, <Tensor[Float32], (10)>) -> (<Bool>)
  %70(success) = MakeTuple(%62, %63, %64, %65, %66, %67, %68, %69)
      : (<Bool>, <Bool>, <Bool>, <Bool>, <Bool>, <Bool>, <Bool>, <Bool>) -> (<Tuple[Bool*8], sequence_nodes={node={254_129_1_construct_wrapper.905:success{[0]: ValueNode<Primitive> MakeTuple, [1]: success, [2]: success, [3]: success, [4]: success, [5]: success, [6]: success, [7]: success, [8]: success}, elements_use_flags: {ptr: 0x159970a04c0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>)
  %71(loss) = Depend(%23, %70) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], ()>, <Tuple[Bool*8], sequence_nodes={node={254_129_1_construct_wrapper.905:success{[0]: ValueNode<Primitive> MakeTuple, [1]: success, [2]: success, [3]: success, [4]: success, [5]: success, [6]: success, [7]: success, [8]: success}, elements_use_flags: {ptr: 0x159970a04c0, value: [const vector][1, 1, 1, 1, 1, 1, 1, 1]}}}>) -> (<Tensor[Float32], ()>)
  %72([CNode]852) = UpdateState(%60, %61)
      : (<UMonad>, <Tensor[Float32], (6, 1, 5, 5)>) -> (<UMonad>)
  %73(loss) = Depend(%71, %72) primitive_attrs: {side_effect_propagate: 1}
      : (<Tensor[Float32], ()>, <UMonad>) -> (<Tensor[Float32], ()>)
  %74([CNode]910) = MakeTuple(%73)
      : (<Tensor[Float32], ()>) -> (<kMetaTypeNone>)
  Return(%74)
      : (<kMetaTypeNone>)
}

